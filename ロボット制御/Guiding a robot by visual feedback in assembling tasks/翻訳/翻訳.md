# Abst
ロボットがブロックを箱に入れる際に、視覚的なフィードバックを利用するシステムについて説明します。この実験では，物体の希望位置と実際の位置の差を視覚的に認識し，マニピュレータを動かすことで修正する。実験の結果、このような視覚的フィードバックは、正確な位置決めを行うのに有効であることがわかった。

# Intro

視覚情報を利用して物体を操作する知能ロボットが研究されており，すでに各研究室で実験モデルが開発されている(1-3). 一般に知能ロボットは，視覚システム，ハンドリングシステム，およびこれらのシステムをつなぐ監視システムから構成されています。

ビジュアルシステムとハンドリングシステムは、通常、オープンループシステムとして一緒に組み合わされます。 視覚情報が処理され、パラメータが得られると、視覚システムはハンドリングシステムから完全に分離され、対象物を扱っている間は視覚システムは使用されません。 このオープンループシステムでは、操作の精度は、視覚入力デバイスと視覚システムのデジタル化の両方の誤差、ハンドリングシステムの位置決めの誤差、座標変換の誤差に直接依存します。

これらの誤差を補正するために、視覚フィードバックループは、マニピュレータの実際の位置と希望の位置の差を検出することができます。 視覚フィードバックループによってマニピュレータの位置が希望の位置に調整されれば、タスクの精度は視覚システムとハンドリングシステムの両方の解像度の点で向上する。

本論文では，視覚フィードバックループを用いた操作の例として，四角いプリズムブロックを四角い箱に入れるという組立タスクを説明する．この操作では、認識問題は容易であるが、位置と姿勢を正確に制御することが必要である。

# 2. OUTLINE OF THE EXPERIMENT

この実験の処理は、以下の5つの連続したステージで構成されています。 フロー図を図1に示す。

(A)箱の位置を視覚的に認識する。 この段階では、ロボットは目で箱の位置を認識します。 この認識結果をもとに，次の段階で基準となる位置を決定する。

(B) ブロックを相手の箱の上に運ぶための操作。 ロボットはブロックを把持し、前の段階で決定された目的の位置に向かってブロックを運ぼうとします。

(C) 視覚的フィードバックのための認識。 この段階では、マニピュレータによって動かされたブロックの、希望の位置と実際の位置との差を示す。

(D) 誤差を減らすための動作。 この段階では、前の段階で認識した誤差を解消するために、ロボットが手を動かします。 (C)と(D)の手順を組み合わせて、視覚的なフィードバックループを構成します。

(E) 箱にブロックを挿入する操作。 ビジュアルフィードバックによって正確な位置決めが行われた後、ロボットはタスクを完了し、初期位置に戻ります。

# 3. 視覚情報処理

図1では、視覚情報処理がステージAとCに対応しており、どちらのステージにも対象物の認識と位置の測定が含まれています。処理の方法は両ステージに共通しており、以下の3.1～3.3節で説明する。

# 3.1. 視覚からの入力

市販のビデコンTVカメラを映像入力デバイスとして採用しました。ビデオ信号はプリプロセッサによって6ビットのデジタル信号に変換され、コンピュータに転送されます。 プリプロセッサでは、全画面を256×256の絵素材に分割し、1走査間隔で64×64の絵素材をサンプリングする。 サンプリングする範囲（ウィンドウ）はソフトウェアで変更することができる。今回の実験では，画像全体の面積の1/4または～のいずれか（1/4モードまたは～モード）をサンプリング領域として選択しています。 1/4モードは、物体のおおよその位置を検出するために選択されます。このモードでは、画像の1/4の領域にある2×2要素の各セクションから1つずつ、4番目の要素がサンプリングされます。このようにして得られたデジタル画像は解像度が低い。一方、物体の位置を正確に把握したい場合には、$\frac{1}{16}$ モードが選択される。このモードでは、画像の$\frac{1}{16}$の領域のすべての画像要素をサンプリングします。

# 6. 結言

ビジュアル・フィードバック・システムによって，知能ロボットが高い精度で組立作業を行うことができることが実験で示された。与えられた課題は，正方形のプリズム・ブロックを，5mmのクリアランスを持つ正方形の箱に入れることである。 まず，箱を認識してブロックの希望する位置を求め，ブロックを指示された位置に運びます。 次に、ブロックを認識して、目的の位置からのずれを計算します。 この偏差を補うためにブロックが移動される。 このような視覚的フィードバックのループを、偏差が所定の範囲内に収まるまで繰り返し、ブロックを箱に挿入していく。挿入時にブロックが傾いていても、3mmのクリアランスを確保するという課題は達成されています。

今回の実験では、3次元空間における物体の位置を得るために、テレビカメラを1台だけ使用しています。 3次元の位置を入力装置で直接検出できれば、可能なタスクの幅が広がるかもしれません。 また、視覚的な情報だけでなく、触覚的な情報もロボットの能力を高めるのに有効です。さらに、バイラテラルマニピュレータを採用することで、より複雑で精密な作業を行うことができるようになるかもしれません。