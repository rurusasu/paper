# CNN-Based Model for Pose Detection of Industrial PCB

# 備考

## 著者
Li Haochen, Zheng Bin, Sun Xiaoyong, Zhao Yongting

## 掲載
``CNN-Based Model for Pose Detection of Industrial PCB,'' {\it International Conference on Intelligent Computation Technology and Automation (ICICTA)}, Vol. 1, pp. 390--393, 2017.

# Abstract

ロボットがオブジェクトを操作するアプリケーションでは、オブジェクトのポーズを取得することがコントローラのその後の操作にとって非常に重要であり、特にプリント基板の供給やブランキングの分野では、ロボットが最終的なマニピュレータからの相対的なオブジェクトの正確なポーズを取得できれば、把持の成功率が向上すると考えられます。 そこで本論文では、CNNモデルを利用して、物体認識、位置検出、ポーズ検出の3つのタスクのためのニューラルネットワークを構築した。 このモデルでは、ポーズ検出を分類問題として扱い、認識と位置情報を同じレベルで結合することを試みている。  マルチタスク検出モデルの性能を検証するために、リアルタイムのPCB検出テストによる実験と性能分析を行った。 実験では，自分で作成した異なるポーズを含む3種類のPCBデータセットを訓練/テストサンプルとして使用しました．ポーズの検出精度に応じて，オブジェクトポーズのカテゴリ数を8bins，12bins，36binsに分割した．不均一なデータセットが学習プロセスに与える影響を分析し，最終的な検出結果は，このCNNベースの検出モデルがPCBポーズ検出において高精度を達成できることを示している．

# Introduction

深層学習の概念は2006年にHintonによって提案された[1]。 この作品では、彼は、ディープビリーフネットワーク上で高速なニューラルネットワークのトレーニングアルゴリズムを使用して、良好な効果を得る。 これは、高性能な計算機とアルゴリズムの最適化の助けを借りて、従来のニューラルネットワークの不十分さを克服し、深層学習モデルの一般化能力を様々な分野で活用できることを意味します。  研究が進むにつれ，画像処理で最もよく使われるCNN(Convolution Neural Network)や，時系列データを扱う能力を持つRNN(Recurrent Neural Network)など，様々な分野の深層学習モデルが開発されてきている[2]．

LeCunら[3]は，CNNを用いた手書き文字認識システムを開発し，実用化した． CNNが特徴抽出や分類の性能を示したのは初めてである。現在までに，顔認識，マルチターゲット検出，音声認識などの複雑なアプリケーション分野では，異なる深層学習モデルが強力な性能を発揮している[4]．

画像処理の発展の中で，物体の検出と分類は現在の研究のホットスポットとなっており，人間の活動認識，産業用ロボットの把持や操作全般など，多くのアプリケーションで物体のポーズや種類，位置を同時に認識する必要がある中で，様々な物体認識モデルが提示されてきている[5]．  多次元の物体情報を利用することで，学者は高度な意味論的分析を行うことができる． 従来の方法では，物体のキーポイントを見つけたり，DPM(Deformable Part Model)の一部としてポーズを追加したりすることでポーズを検出していましたが，本研究では，物体情報を用いた3次元物体情報と同様の方法でポーズを検出しています[6]．我々の手法は，Jincheng Yu et al [7]が提案した3次元物体検出モデルと似ており，ニューラルネットワークを用いて物体のマルチタスク検出を実現し，ロボット操作にも適用したいと考えているが，マルチタスクフレームワークを利用しており，前景と背景を区別する性能は我々の方が優れている．   Joseph Redmonら[8]はロボットの把持検出のためのリアルタイムCNNモデルを発表しており，AlexNetからモデルを構築し，把持箱検出に拡張している．

本論文では，産業用PCBの検出のためのCNN検出モデルを提案する．実験とPCBデータセットを用いて、この検出モデルの性能を確認し、リアルタイムのPCB供給とブランキングプロセスのための新しいソリューションを提供し、産業用検出分野におけるマルチタスク(>2)モデルの実現可能性を検証した。

# 2. POSE DETECTION MODEL

ロボットのビジュアルサーボ制御の第一歩は物体検出です。 物体を検出した後、ロボットは手と目のキャリブレーションを行い、ロボットと物体の座標を確認することで、ロボットに搭載されたエンドエフェクタで把持、移動、配置の操作を行うことができます。 しかし、ロボットは物体の姿勢に合わせてエンドエフェクタの回転角度を調整することができないため、把持の成功率が高くないことがあります。

CNNは現在、特徴抽出において強力な能力を発揮している。  自動抽出された特徴の質と量は、従来の人工的に設計されたものよりも優れている。多くの学者がCNNを利用して物体認識やマシンビジョンの問題解決を行っている。 そこで我々は、マルチタスクCNNの広範な能力を利用して、大域的な物体ポーズ検出を行っている。 我々の検出モデルは、5つの畳み込み層、2つの完全に接続された層、3つの出力層で構成されており、これらはボックス座標回帰値、各タイプクラスの確率、ポーズクラスを出力する。出力行列を解析した後，現在の物体の検出情報を得ることができる．

モデル・アーキテクチャの全体図を図2に示す． 我々のシンプルなモデルは、Zeiler and Fergus [9]によって発表され、ILSVRC 2013で優勝した強力なCNNから派生しています。

特に、出力タスク層を拡大してポーズ検出を行い、適切な損失関数(large-margin-softmax-loss)を利用してポーズ検出タスクに対応した逆伝播計算を行うなど、ZF-Netのアーキテクチャを微調整することで、ネットワークの機能を強化しました。

# 3. EXPERIMENTS RESULTS AND PERFORMANCE ANALYSIS OF MODEL

## A. Description of Datasets and Detection System

この実験の主な目的は、我々のCNNモデルの性能を、物体認識、物体の位置、物体のポーズの検出という3つの側面からテストすることである。

実験では、自作のPCBデータセットを使用していますが、その中には、2次元平面上で異なるポーズを持つ3種類のPCBが含まれており、その中には、トレーニング用/テスト用のフリップなしの731枚の画像が含まれています。

各PBCオブジェクトは、ポーズ検出精度に対応する複数のラベル付きポーズクラスを有していてもよい。

カメラにはBasler-acA 1600-20gmを使用しています。 検出システムを図3に示す。 Basler-acA 1600-20gmは基板とレンズが平行になるようにブラケットに取り付けられています。モデルがデータセットで訓練された後、我々は実験の過程で我々のモデルの結果を観察し、記録するために、異なるポーズとしてPCBを回転させる。

## B The Experiment Result: Pose Detection Output

学習段階では、ポーズ空間を無相関の複数のビンに離散化し、ビンの種類を8、12、36の3つのケースに分けて、ポーズ検出問題を分類タスクとして定式化しました。ラベリングされた画像の中には、3つのケースの下で、それぞれのpcbオブジェクトに対応する複数の異なるポーズクラスが存在します。図4に36ビンのsクラスのpcb検出結果を可視化したものを示す． バウンディングボックスの上下のアノテーションは、現在のオブジェクトの回転角度の種類と範囲を信頼度とともに示しています。信頼度が高いほど、正しい検出結果が得られる確率が高いことを示している。ポーズの方向を表すために、2つの端点を持つ線を使用しました（図4から図6の各バウンディングボックス内の線として描かれています）。ポーズが変化したときのネットワークの出力に対応して、数度回転します。図5に36ビンの物体認識結果を、図6にmクラスとbクラスのポーズ検出結果を示す。いずれも信頼度が高いことがわかります。