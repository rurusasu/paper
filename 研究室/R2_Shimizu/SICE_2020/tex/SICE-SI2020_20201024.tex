\documentclass[a4paper]{jarticle}
\usepackage{sice-si}
\usepackage{amsmath} 
\usepackage{graphicx}
\usepackage{here}
\usepackage{bm}
\usepackage{slashbox}
%
\def\mbf#1{\mbox{\boldmath $#1$}}
\def\rup#1{{^#1}\hspace{-0.5mm}}
\def\bm#1{\mbox{\boldmath $#1$}} 
%
\begin{document}
%
% タイトルと著者名
\title{サポートベクタマシンを用いたラップフィルムの不良品検出\\\large{ー畳み込みニューラルネットワークを特徴抽出器として用いた場合ー}} % 和文タイトル
\name{○清水 竜樹（山口東京理科大学工学部機械工学科），中島 健斗，三木 康平\\永田 寅臣（山口東京理科大学大学院工学研究科），渡辺 桂吾（岡山大学大学院自然科学研究科）\\} 
\etitle{Defect Detection System Using Support Vector Machine for Wrap Film Products\\\large{-In Case of Convolutional Neural Network Based Feature Extractor-}}
% 英文タイトル
%\etitle{Defect Detection of Wrap Film Using Support Vector Machine} % 英文タイトル
\ename{○Tatsuki SHIMIZU, Department of Mechanical Engineering, Sanyo-Onoda City University \\Kento NAKASHIMA, Kohei MIKI, Fusaomi NAGATA (Graduate School of Engineering, Sanyo-Onoda City University)\\Keigo WATANABE (Graduate School of Natural Science and Technology, Okayama University)}	%著者名（英）
%
% アブストラクト
\abst{
This paper proposes a system processed by two-class support vector machine (TCSVM) which can detect defective products occurring in the wrap film manufacturing process. The TCSVM has a feature vector extractor based on pre-trained CNN models such as AlexNet and VGG19. The TCSVM is trained using collected images of normal and defective wrap film products. In training, CNN model as AlexNet or VGG19, Kernel function as Gaussian or polynomial, and regularization parameter C are used for tuning conditions to obtain superior classification performance. Through several comparative experiments based on confusion matrix, the most desirable CNN model is considered.   
} 
%In addition to the difference between the two CNNs used in the feature extractor, using a Gaussian function or a polynomial function as a kernel function. Furthermore, we examine the effctivensss of chaging the regularization parameter C and search for TCSVM that can obtain more accurate results.

% タイトルの出力
\maketitle

%本文
\section{緒言}
様々な工業製品の検査工程においては一部で自動化が進んでいるものの，それぞれの製品の品質管理に精通した検査員の目視検査に頼るところが大きい状況である．最近は，画像認識に特化した人工知能を製品の欠陥検出に応用しようとする試みがなされており，その中にはサポートベクタマシン（SVM）も含まれている．

これまでにもSVMを製品の欠陥検出に応用した研究がある．
例えば，西村らはHOG特徴量を用いて，SVMを電子部品の欠陥検出に使用した場合の課題について研究を行っている~\cite{Nishimura}．また，YangらはSIFT特徴量を用いたSVMにより，輸送用パッケージの欠陥検出を試みている~\cite{YANG}．
%筆者らは，CNNを応用した欠陥を含む不良品検出の基礎研究，カスケードタイプCNNの設計と欠陥検出への応用研究に取り組んでいる．

本研究では，ラップフィルム品の欠陥検出を行うことができるSVMについて検討する．SVMでは特徴抽出器から取得した特徴ベクトルを用いて学習を行い，不良品と良品を判別する境界面の作成に必要なサポートベクトルを決定する．ベクトルデータの高次元化のためにカーネル法を用いること分類性能を向上できるため，実験では特徴抽出器のほか，カーネル関数と最適化関数に現れる正則化係数を変更し，より精度の高い分類が可能となるSVMを探索する．特徴抽出器にはAlexNetあるいはVGG19を用い，カーネル関数にはガウス関数と多項式関数の二通りをそれぞれ組み合わせて2クラス分類を行うSVM (TCSVM) を設計する．

図~\ref{fig:sample}のような良品と不良品からなるラップフィルム品の訓練用データセットを用意し，それぞれの画像から要素数4096の特徴ベクトルを抽出し，SVMの学習を行う．その後，学習後のSVMが未学習のデータセットをどの程度正しく分類できるかを評価する．
%--------------------------
% 不良品の画像
%--------------------------
%%%%%%%%%%%%%%%%%%%%%%
 \begin{figure}[t]
 \begin{center}
 \includegraphics[width=70mm,clip]{./fig/rapp_sample.eps}
 \caption{Samples of training images without and with defects (marked with orange rectangle).}
 \label{fig:sample}
 \end{center}
 \end{figure}
 %%%%%%%%%%%

\section{テンプレートマッチングによる目標領域の抽出}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
本章では，治具を含むラップフィルム品の全体画像に対してテンプレートマッチングを適用し，ラップフィルム部分のみを抽出する画像処理を行う．様々な課題に対する画像処理で広く利用されているテンプレートマッチングは，撮影されたワークの中で欠陥が含まれやすい目標領域を抽出するためにも非常に有効である．これから設計するCNNへの入力画像のサイズを大幅に減らすことができ，計算コスト，メモリ占有コストを軽減することができる．このため，開発したメイン，オプション及びオーギュメンテーションのダイアログの中ではテンプレートマッチング機能を利用できるようにしている \cite{Nagata-2019}．

テンプレートマッチングの処理では，$(M, N)$ のサイズのテンプレートをターゲット画像内でラスタースキャンさせて相関係数の高い位置を検出する場合，周辺領域でもマッチング評価ができるようにパッディング処理を行う．テンプレートとパッディングにより拡張されたターゲット画像内の同面積の領域との相関係数$\alpha(u,v)$は，次式から計算される．
\begin{eqnarray}
\alpha(u,v) = \frac{s_{it}(u,v)}{s_{i}(u,v)s_{t}(u,v)}
\label{eq:10}
\end{eqnarray}
\begin{eqnarray}
s_{it}(u,v)=  \nonumber \\
\sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) - \bar{f}_{u,v} \Big\}
\Big\{ t(x-u,y-v) - \bar{t}\Big\}
\end{eqnarray}
\begin{eqnarray}
s_{i}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) -
\bar{f}_{u,v} \Big\}^2}
\end{eqnarray}
\begin{eqnarray}
s_{t}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ t(x-u,y-v)
- \bar{t}\Big\}^2}
\end{eqnarray}
% Figure extracted
%-------------------------------
\begin{figure}[t]
\begin{center}
\includegraphics[width=80mm ,clip]{./fig/template_matching2.eps}
\vspace{-2mm}
\caption{An example of extracted image using the template matching technique.}
\label{fig:templateimage}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
\\
ここで，$(u,v)$はターゲット画像内におけるテンプレート左上コーナーの座標である．$s_{t}(u,v)$と$s_{i}(u,v)$はそれぞれ，テンプレート内とターゲット内比較領域の標準偏差であり，$s_{it}(u,v)$は共分散である．$f(x,y)$は拡張された画像内の$(x,y)$におけるグレースケール256諧調値を正規化した値である．$t(x-u,y-v)$はテンプレート内の$(x-u,y-v)$における同様の値である．$M$と$N$はそれぞれ，テンプレートの幅と高さである．$\bar{t}$と$\bar{f}(u,v)$はそれぞれ，テンプレート内のグレースケール値の平均値と，ターゲット画像内のテンプレート真下の領域のそれである．
式~(\ref{eq:10})で与えられる相関係数$\alpha(u,v)$は，テンプレートをターゲット画像内の左上から右下までラスタースキャンさせることで計算される．ラスタースキャン後，テンプレートと最もマッチする領域，すなわち最も大きな値$\alpha(u,v)$を持つ領域が抽出される．図~\ref{fig:templateimage}には，テンプレートで抽出されたラップフィルム品の画像の例を示している．今回の実験では，テンプレートマッチングによりラップフィルム品の画像解像度を特徴抽出器として用いるCNNの入力層に適合させやすいように$640 \times 480$から正方形の$347 \times 347$にダウンサイジングして用いた\cite{fss2020}．
%%%%%%%%%%%%%%%
 
\section{SVMによる欠陥検出}
\subsection{SVMの設計と学習}
筆者らは，C++やPythonなどのプログラミングの知識がなくとも容易にSVMを設計できるようにアプリケーションを開発している\cite{Robomech}．図\ref{fig:applicationUI}には，アプリケーションのUIの一部を示す．本研究では，このアプリケーションを用いてSVMを設計し，分類評価の実験を行う．前章で抽出した良品と不良品からなるラップフィルムの画像をもとに訓練用データセットを作成した．AlexNetとVGG19を特徴抽出器として用いたSVMはそれぞれ，図\ref{fig:alex}, \ref{fig:vgg19}のような構造になる．

%--------------------------
% アプリのメニュー
%--------------------------
%%%%%%%%%%%%%%%%%%%%%%
 \begin{figure}[b]
 \begin{center}
 \includegraphics[width=85mm,clip]{./fig/matlabsetting.eps}
 \caption{The application interface for two class SVM.}
 \label{fig:applicationUI}
 \end{center}
 \end{figure}
 %%%%%%%%%%%
 %--------------------------
% SVMの構造
%--------------------------
%%%%%%%%%%%%%%%%%%%%%%
 \begin{figure*}[t]
 \begin{center}
 \includegraphics[width=120mm,clip]{./fig/alex_svm.eps}
 \caption{Architecture of TCSVM based on AlexNet.}
 \label{fig:alex}
 \end{center}
 \end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
 \begin{figure*}[!t]
 \begin{center}
 \includegraphics[width=150mm,clip]{./fig/vgg19_svm.eps}
 \caption{Architecture of TCSVM based on VGG19.}
 \label{fig:vgg19}
 \end{center}
 \end{figure*}
 %%%%%%%%%%%%%%%%%%%%%%%
 
SVMでは，特徴抽出器を使用し各入力画像から多次元特徴ベクトル$\bm{x}=[x_1,x_2,\cdots, x_{4096}]^T$を抽出する．この特徴ベクトルがSVMの学習に使用され，学習によって$f(\bm{x})=0$で与えられる超平面と呼ばれる決定境界が得られる．$f(\bm{x})$は，これから分類される特徴ベクトル$\bm{x}$から超平面までの符号付き距離であり，次式で与えられる．
\begin{eqnarray}%sssNetの第？層から得られる特徴ベクトル
f(\bm{x}) = \sum^N_{i=1}\alpha_i y_i G(\bm{x}_i^*,\bm{x}) + b
%f(\bm{x}) = \sum^N_{i=1}\alpha_i \mbox{exp}{\left(-\left\| \frac{\bm{x}_i^* - \bm{x}_s}{k} \right\|^2 \right)} + b
%f(\bm{x}) = \sum^N_{i=1}\alpha_i e^{(-|| \bm{x}_i - \bm{x}||^2 )} + b
\label{eq:1}
\end{eqnarray}
ここで，$G(\bm{x}_i^*,\bm{x})$はカーネル関数，$\bm{x}_i^* \in \Re^{1 \times N} \ (i=1,2, \cdots, N)$は学習により決定されたサポートベクトル，$N$はサポートベクトルの数，$\alpha_i \ (i=1,2, \cdots, N)$と$b$はそれぞれラグランジュ乗数とバイアスであり，これらは逐次最小最適化 (SMO) を用いた学習によって推定されたSVMパラメータである．また，$y_i$は2クラス学習の場合，$\bm{x}_i^*$の陽性あるいは陰性に応じて$-$1または1に設定されたラベルである．分類はスコア$f(\bm{x})$の符号によって行われ，$f(\bm{x})>0$の場合は陰性，$f(\bm{x})<0$の場合は陽性であるといったように判断される．例えば，カーネル関数$G(\bm{x}_i^*,\bm{x})$にガウシアン関数が適用される場合は次式となる．

%K(\bm{x}_i^*,\bm{x})=\mbox{exp}{\left(-\gamma\left\| {\bm{x}_i^* -  \bm{x}_s} \right\|^2 \right)}
\begin{eqnarray}
G(\bm{x}_i^*,\bm{x}) =  \mbox{exp}{\left(-\left\| \frac{\bm{x}_i^* - \bm{x}_s}{k} \right\|^2 \right)} 
%f(\bm{x}) = \sum^N_{i=1}\alpha_i e^{(-|| \bm{x}_i - \bm{x}||^2 )} + b
\label{eq:11}
\end{eqnarray}
ここで，$k$と$\bm{x}_s$はそれぞれのカーネルスケールと，式(\ref{eq:2}), 式(\ref{eq:3})および式(\ref{eq:4})を使って得られる標準化された入力ベクトルである．
\begin{eqnarray}
%\bm{x}_s = \bm{x} -\frac{\sum^{5100}_{j=1} \bm{x}_j}{5100}
\bm{x}_s = (\bm{x} -\bm{x}_{\mu}) \oslash \bm{x}_{\sigma}
\label{eq:2}
\end{eqnarray}
\begin{eqnarray}
\bm{x}_{\mu} = \frac{\sum^{36715}_{j=1} \bm{x}_j}{36715} 
\label{eq:3}
\end{eqnarray}
\begin{eqnarray}
\bm{x}_{\sigma}=\left [ \frac{1}{36715}\sum^{36715}_{j=1} (\bm{x}_j-\bm{x}_{\mu})^{\circ 2} \right ]^{\circ\frac{1}{2}}
\label{eq:4}
\end{eqnarray}
ここで，36715は訓練画像の総数であり，$\oslash$, $\circ 2$, $\circ \frac{1}{2}$はそれぞれ，要素単位の除算，べき乗および平方根を求めるアダマール演算子である．また，カーネル関数に多項式関数が適用される場合，次式のようになる．
\begin{eqnarray}
%G(\bm{x}_i^*,\bm{x})=\left[ 1+\frac{\bm{x}_i^*\mathsf{T}\bm{x}_s}{k} \right]^n　\\
G(\mbf{x}_i^*,\mbf{x}) =  \left[1 + \frac{(\mbf{x}_i^*)^T}{k} \frac{\mbf{x}_s}{k} \right]^n
%G(\bm{x}_i^*,\bm{x}) =  \mbox{exp}{\left(-\left\| \frac{\bm{x}_i^* - \bm{x}_s}{k} \right\|^2 \right)} 
%f(\bm{x}) = \sum^N_{i=1}\alpha_i e^{(-|| \bm{x}_i - \bm{x}||^2 )} + b
\label{eq:poly}
\end{eqnarray}

訓練するデータが式(\ref{eq:1})の境界面で分離可能である場合，SVMの学習はデータを完全に2クラスに分類できるハードマージンによる最適化が可能である．しかし，現実の問題が必ずしも完全に分離可能であるとは限らない．そのため，SVMには完全にデータを分離しないことを許容するソフトマージンによる最適化が適用される．ソフトマージンの最適化問題は最終的に次式のような双対問題として得られることが知られている \cite{MATLAB,Takeuchi}．
\begin{eqnarray}
\begin{split}
\underset{\alpha}{max} -\frac{1}{2}&\underset{i,j\in[n]}{\sum}\alpha_i\alpha_j y_i y_j G(\bm{x}_i^*,\bm{x})+\underset{i\in[n]}{\sum}\alpha_i\\
&s.t.\underset{i\in[n]}{\sum}\alpha_i y_i=0\\
&0\leq \alpha_i \leq C, i\in[n]
\label{eq:margin}
\end{split}
\end{eqnarray}
ここで，$C$はボックス制約と呼ばれる正則化係数である．式~(\ref{eq:margin})で与えられる最適化問題を解くことにより，式~(\ref{eq:1})を構成するSVMパラメータが決定される．実験では特徴抽出器として用いるCNN，カーネル関数，及び$C$の値を変化させてより優れた分類性能を持つSVMの設計を試みた．

\subsection{分類実験}
評価実験を行うにあたり，AlexNetを特徴抽出器とし，カーネル関数にガウス関数を用いたSVMと多項式関数を用いたSVMをそれぞれAG, AP，VGG19を特徴抽出器とし，カーネル関数にガウス関数を用いたSVMと多項式関数を用いたSVMをそれぞれVG, VPとする．ラップフィルムの良品画像34482枚と不良品画像2233枚を訓練データとしてこれらのSVMの訓練を行った．さらに，正則化係数$C$の値を変更しながら，より汎化性能の高いSVMの探索を行った．汎化性能を評価するために，良品4035枚と不良品21枚の未学習の画像を用意し，学習終了後のSVMに分類させた．表\ref{table:AG confusion matrix}, \ref{table:AP confusion matrix}, \ref{table:VG confusion matrix}, および\ref{table:VP confusion matrix}には，AG, AP, VG, およびVPそれぞれの分類結果の混合行列を示す．なお，表内のActual
とPredictedはそれぞれ，実際のラベルと予測されたラベルを表す．AG, AP, VG, およびVP全てに関して，分類実験に使用した画像の枚数が4056であることを考えると誤認識の枚数が最大6というのは分類性能の高い結果であると言える．

\section{評価結果および考察}
一般に，学習を行ったSVMの性能を検討する際には次式のような評価指標を用いる\cite{Tokyo}．
\begin{eqnarray}
Ac = \frac{TP+TN}{TP+FN+FP+TN}  
 \label{eq:acc}
 \end{eqnarray}
\begin{eqnarray}
Pr = \frac{TP}{TP+FP}  
 \label{eq:pr}
 \end{eqnarray}
\begin{eqnarray}
Re = \frac{TP}{TP+FN}  
 \label{eq:re}
 \end{eqnarray}
 \begin{eqnarray}
F = \frac{2\cdot Re\cdot Pr}{Re+Pr}  
 \label{eq:f}
 \end{eqnarray}
ここでは不良品を陽性，良品を陰性とし，全体のデータの中で不良品を不良品として分類したものを$TP$，良品を良品として分類したものを$TN$，不良品を良品として分類したものを$FN$，さらに良品を不良品として分類したものを$FP$として値を決定した．これらの値から式(\ref{eq:acc}), (\ref{eq:pr}), (\ref{eq:re}), および(\ref{eq:f})で与えられるAccuracy(\textit{Ac}), Precision(\textit{Pr}), Recall(\textit{Re}), およびF値(\textit {F})をそれぞれ算出する．
%%%%%%%%%%%%%%%
%Table 
%%%%%%%%%%%%%%%
\begin{table}[t]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Confusion matrix of AG ($C$=0.5).}
 \vspace{1mm}
\label{table:AG confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pred.} & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 2 & 4033 \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[t]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Confusion matrix of AP ($C$=0.5).}
 \vspace{1mm}
\label{table:AP confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pred.}  & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 0 & 4035 \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!t]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Confusion matrix of VG ($C$=0.5).}
 \vspace{1mm}
\label{table:VG confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pred.}  & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 5 & 4030 \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[!t]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Confusion matrix of VP ($C$=1).}
 \vspace{1mm}
\label{table:VP confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pred.}  & NG & OK \\
\hline
 NG & 21 & 0 \\
 OK & 4 & 4031 \\
\hline
\end{tabular}
\end{table}



今回の実験結果をもとにまとめた各評価指標を表\ref{table:comparison}に示す．
\begin{table}[!b]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Comparison of result.}
 \vspace{1mm}
\label{table:comparison}
\centering
\begin{tabular}{c|cccc} 
\hline
   & AG & AP & VG & VP\\
\hline
\textit {Ac} & 0.999 & 0.999 & 0.999 & 0.999\\
\textit {Pr} & 0.909 & 1 & 0.8 & 0.84\\
\textit {Re} & 0.952 & 0.952 & 0.952 & 1\\
\textit {F } & 0.930 & 0.976 & 0.870 & 0.913\\
\hline
\end{tabular}
\end{table}
指標のAccuracyは，全ての予測のうち正しく予測できたものはどれだけかを表す指標である．Precisionは，陽性と判断した画像が実際に陽性であった割合を示すため，この値が高い場合は不良品を正しく見分けることができているということになる．Recallは，陽性の画像を陽性と判断できた割合を表す指標である．さらにF値は，PrecisionとRecallのバランスを示す指標である．

従来，画像認識を応用したラップフィルムの欠陥検出は難しい課題とされてきたが，表\ref{table:AG confusion matrix}, \ref{table:AP confusion matrix}, \ref{table:VG confusion matrix}, \ref{table:VP confusion matrix}に示したSVMの分類結果はどれも性能が高く，これは表\ref{table:comparison}のAccuracyの値に表れている．また，Precisionに着目すると0.9以上のAGとAPの値に対し，VG, VPは0.9未満であり，本実験の条件においてはAlexNetを特徴抽出器としたSVMの方が良品を不良品と誤判断することが少なかったということになる．さらに，Recallに関しては，未学習の画像として分類にかけることが可能な不良品のテスト画像が少なかったために，Recallの値は変動が起きやすく，VP以外のSVMでも誤認識は1枚であるが指標に大きな差が生じた．

特徴抽出器ごとに指標を比較すると，PrecisionとF値という2点でAGよりAPの方が優れており，VPはVGにPrecision, Recall, F値の3点で優れていることがわかる．さらにAPとVPを比較すると，APはRecallでは劣るものの，PrecisionとF値ではVPより優れているという点からAPの方がより良い性能を有していると推測できる．本実験の条件下ではPrecisionおよびF値から，特徴抽出器としてはVGG19よりAlexNetの方が適しており，カーネル関数としてはガウス関数より多項式関数の方が適していたと考えられる．また，ある不良品画像は3つのSVMで良品と誤認識されており，訓練のデータセットに類似する不良品が含まれていなかった可能性がある．今後，さらに不良品の画像を収集可能になれば，その不良品画像を使った追加学習を行うことでより分類性能の高いSVMを構築できるものと期待される．

\section{結言}
本研究では，ラップフィルム品の欠陥検出を行うことができるSVMについて検討した．実験では，特徴抽出器として用いるCNN，カーネル関数，分離平面のマージン内のデータに与えるペナルティの程度である正則化係数の値を変更しながら，より分類性能の高いSVMの設計を目指した．特徴抽出器にはAlexNetあるいはVGG19を，カーネル関数にはガウス関数と多項式関数をそれぞれ組み合わせて2クラス分類を行うSVM (TCSVM)を設計した．評価実験の結果，今回の条件下では特徴抽出器にはAlexNetを，カーネル関数には多項式関数を使用し，正則化係数を1以下にすることでより高い分類性能を持つSVMを設計できた．

実際の製造ラインにおいて不良品が良品と誤認識されることはリコールなど重大な事態につながりかねない．一方，良品が不良品と誤認識されることは生産工程における大きな損失につながる．学習済みのCNNを特徴抽出器としたSVMの設計が可能となっている提案アプリケーションは，不良品検出用のAI構築に関して有効なツールであることが確認できたため，今後はラップフィルム以外の製品の欠陥検出用AIの構築にも適用できるのかの検証を行いたい．
%同様のパラメータ設定で
\begin{thebibliography}{99}
\bibitem{Nishimura}
西村 晃紀，柳部 正樹，青戸 勇太，長谷 智紘，森山 健，前田 俊二，``HOG特徴量を電子部品検査に適用した場合の課題検討，"2017年度精密工学会秋季大会学術講演会講演論文集，pp. 219--220, 2017.

\bibitem{YANG}
X. Yang, M. Han, H. Tang, Q. Li, X. Luo, ``Detecting Defects With Support Vector Machine in Logistics Packaging Boxes for Edge Computing," IEEE Access, Vol. 8, pp. 64002--64010, 2020.

\bibitem{Nagata-2019}
F. Nagata, K. Tokuno, K. Mitarai, A. Otsuka, T. Ikeda, H. Ochi, K. Watanabe, M.K. Habib, ``Defect detection method using deep convolutional neural network, support vector machine and template matching techniques," {\it Artificial Life and Robotics}, Vol. 24, No. 4, pp. 512--519, 2019.

\bibitem{fss2020}
中島 健斗，永田 寅臣，渡辺 桂吾，``畳み込みニューラルネットワークを用いたラップロール製品の不良品検出," 第36回ファジィシステムシンポジウム 論文集, MC2-4, 5 pages, 2020.

\bibitem{Robomech}
中島 健斗, 永田 寅臣,  渡辺 桂吾,``畳み込みニューラルネットワーク(CNN)とサポートベクターマシン(SVM)を用いた微小な欠陥を持つ不良品検出の基礎研究," ロボティクス・メカトロニクス講演会 2019 講演論文集, 2A1-Q05, 4 pages, 広島国際会議場, 2019.

\bibitem{MATLAB}
MATLAB, ``https://jp.mathworks.com/"

\bibitem{Takeuchi}
竹内 一郎，鳥山 昌幸，``サポートベクトルマシン," 講談社, 2015.

\bibitem{Tokyo}
中川 裕志, ``東京大学工学教程 情報工学 機械学習," 丸善出版, 2015

% \bibitem{AlexNet}
% Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ``ImageNet Classification with Deep Convolutional Neural Networks," {\it Neural Information Processing Systems Conference}, 2012.

% \bibitem{Arobo}
% Kento Nakashima, Fusaomi Nagata, Hiroaki Ochi, Akimasa Otsuka, Takeshi Ikeda, Keigo Watanabe, Maki K. Habib, “Detection of Minute Defects Using Transfer Learning-Based CNN Models,” Procs.
% of 25th International Symposium on Artificial Life
% and Robotics, pp. 871?875, 2020.
%\bibitem{SMO}

\end{thebibliography}
%
\end{document}