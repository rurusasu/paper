\documentclass{suribt}
\def\mbf#1{\mbox{\boldmath $#1$}} 
\def\rup#1{{^#1}\hspace{-0.5mm}}
%\documentclass[oneside]{suribt}% 本文が * ページ以下のときに (掲示に注意)
\usepackage{amsmath}
\usepackage[dvips]{graphicx}
\usepackage{cite}
\usepackage{slashbox}
\usepackage{here}
\usepackage{bm}
\usepackage{subfigure}

%\title{CLデータに基づく微小摺動制御法を用いたデスクトップ型NC工作機械}
\title{サポートベクタマシンを用いたラップフィルムの不良品検出\\\large{-畳み込みニューラルネットワークを特徴抽出器として用いた場合-}}
%\titlewidth{}% タイトル幅 (指定するときは単位つきで)
\author{清水　竜樹}
\eauthor{Tatsuki Shimizu}% Copyright 表示で使われる
\studentid{F117031}
\supervisor{永田寅臣　教授}% 1 つ引数をとる (役職まで含めて書く)
%\supervisor{指導教員名 役職 \and 指導教員名 役職}% 複数教員の場合，\and でつなげる
\handin{2021}{03}% 提出月. 2 つ (年, 月) 引数をとる
%\keywords{キーワード1, キーワード2} % 概要の下に表示される
\begin{document}
\maketitle %%%%%%%%%%%%%%%%%%% タイトル %%%%
\frontmatter %ここから前文
\begin{abstract}%%%%%%%%%%%%% 概要 %%%%%%%%%%%%%%%%%%%%%
筆者らは畳み込みニューラルネットワーク(CNN)やサポートベクタマシン(SVM)を簡単に設計できるツールを開発している．本研究ではこのツールを用いて，ラップフィルムの製造工程で発生する不良品の検出を試みる．まず，ラップフィルムの全体画像に対してテンプレートマッチングを適用し，フィルム部分のみを抽出する．特徴抽出器として学習済みのCNNであるAlexNetとVGG19を用いたSVMを使用し，汎化性を高めるため多数の良品と不良品の画像を用いて学習を行う．実験では，特徴抽出器とするCNNのほか，それぞれについてカーネル関数をgaussianとpolynomialとした場合について訓練及びテストを行った．次に，各カーネル関数のコストパラメータCを変更し，より精度の高い結果を得られるパラメータを探求した．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{abstract}
\tableofcontents %%%%%%%%%%%%% 目次 %%%%%%%%
\mainmatter % ここから本文 %%% 本文 %%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第1章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{緒言}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
様々な工業製品の検査工程においては一部で自動化が進んでいるものの，それぞれの製品の品質管理に精通した検査員の目視検査に頼るところが大きい状況である．最近は，画像認識に特化した人工知能を製品の欠陥検出に応用しようとする試みがなされており，その中にはサポートベクタマシンも含まれる．

これまでにもサポートベクターマシン（SVM）を製品の欠陥検出に応用した研究がある．
例えば，西村らはHOG特徴量を用いて，SVMを電子部品の欠陥検出に使用した場合の課題についての研究を行っている \cite{Nishimura}．また，YangらはSIFT特徴量を用いたサポートベクタマシンによる輸送用パッケージの欠陥検出を試みている\cite{YANG}．
%筆者らは，CNNを応用した欠陥を含む不良品検出の基礎研究，カスケードタイプCNNの設計と欠陥検出への応用研究に取り組んでいる．

本研究では，ラップフィルム品の欠陥検出を行うことができるSVMを提案する．SVMでは特徴抽出器から取得した特徴ベクトルを用いて学習を行い，不良品と良品を判別する境界面の作成に必要なサポートベクトルを決定する．ベクトルデータの高次元化のためにカーネル法を用いている．実験では，特徴抽出器のほか，カーネル関数と正則化係数を変更し，より精度の高い分類が可能となるSVMを探索する．特徴抽出器にはAlexNetあるいはVGG19を用い，カーネル関数にはガウス関数と多項式関数の二通りをそれぞれ組み合わせて2クラス分類を行うSVM (TCSVM) を設計する．

図~\ref{fig:sample}のような良品と不良品からなるラップフィルム品の訓練用データセットを用意し，それぞれの画像から4096次元の特徴ベクトルを抽出し，SVMの学習を行う．その後，学習後のSVMが未学習のデータセットをどの程度正しく分類することができるかを評価する．
%--------------------------
% 不良品の画像
%--------------------------
%%%%%%%%%%%%%%%%%%%%%%
 \begin{figure}[b]
 \begin{center}
 \includegraphics[width=70mm,clip]{./fig/rapp_sample.eps}
 \caption{Samples of training images without and with defects (marked with orange rectangle).}
 \label{fig:sample}
 \end{center}
 \end{figure}
 %%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第2章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{人工知能}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
人工知能とは、人工的に作られた知能である。この時、知能という言葉が含む意味は様々である。

機械が知能を持つことがあるのかという議論は、1950 年にアラン・チューリングが発表した論文が始まりであるといわれており、チューリングの提唱によれば、人間が質問者となりコンピュータが回答者となる「模倣ゲーム」において、質問者が回答者を人間であると誤認識する回答をできるコンピュータは知能を持っているということになる。この「模倣ゲーム」は、現在では「チューリング・テスト」として人工知能の一つの指標ともされている。

現在使用されている人工知能（AI）という言葉は、1956 年にダートマス大学で行われたダートマス会議で作られたといわれている。このダートマス会議後から 1980 年頃まで、人工知能の研究は盛んになる。

2000 年代に入ると、コンピュータの処理能力の向上や、インターネットの発達などの要因により情報収集や情報交換が簡単になった。また、画像認識や音声認識、自然言語処理などの技術へも関心が高まり、身近なものになった。これらやセンサなどの普及により、実世界のデータを大量に計測することなども可能となったため大量のデータ（ビッグデータ）に基づく機械学習が可能となった。2010 年代には画像認識や音声認識、自然言語処理の分野においても機械学習が必須の技術と考えられるようになり、現在の人工知能の研究においては、機械学習は欠かせないものとなっている。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{機械学習}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
機械学習の中には教師あり学習と教師なし学習という2つの学習方法がある．教師あり学習とは，ある入力に対して特定の出力を予測したい場合で，入力出力のペアの例が入手できる際に有効な機械学習の手法である．教師データは，入力に対し出力が何になるかという正解となるデータを必要とする．このデータを学習した機械に対し未知のデータを入力し，学習をもとに正解を予測することが教師あり学習である．教師あり学習は訓練セットを作るために人手が必要になるものの，学習を終えることができれば人手がかかる作業を省略することなども可能になる．

教師あり学習はさらにクラス分類と回帰に大別される．この二つのどちらを適用するかは，予測結果に関わる．回帰は予測結果が連続性を持つ場合に有効な手法であり，数値の予測などに用いられる．一方クラス分類は，あらかじめ定められた選択肢の中からクラスラベルを予測することが目的であり，データがどの集合に属するかの予測に用いられる．

教師なし学習は教師あり学習と違い学習に教師情報を用いない全ての種類の機械学習が含まれる．教師なし学習では，アルゴリズムには入力データだけが与えられ，データから
知識を抽出することが要求される．そのため の手法で代表的なものが，入力データを人間や機械にとってわかりやすい新しいデータを作る教師なし変換と，似ているデータ同士を同じグループに分けるクラスタリングである．

教師なし変換の利用法として挙げられるものの一つが次元削減である．次元削減は，多数の特徴量で構成されるデータを入力として，本質的な特徴を表す特徴量でそのデータを表す要約方法を見つけることである．一方，クラスタリングは，データを似たような要素から構成されるグループに分ける手法である．クラス分類との相違点は，クラスタリングには正解となるデータが与えられないという点である．そのため，クラスタリングの結果が必ずしも予測に使えるとは限らない．

教師なし学習のアルゴリズムに与えられるデータは正解となるデータが含まれていない．そのため，アルゴリズムの出力結果が正しいのか，ユーザが求める結果を出力しているのかを確実に評価する方法は人間が確かめるしかないため ，教師なし学習は教師あり学習用にデータを次元削減するなどの目的に用いられることが多くある．

教師なし学習のクラスタリングでは，正解となるデータなどは必要ないものの，クラス分類のような結果が出るとは限らなかった．しかし，クラス分類の学習には教師データが必要となるという点でコストがかかる．それを解決するための手法に半教師あり学習がある．半教師あり学習1つの方法としては，少量の正解ラベルのついたデータを用意する．そのデータをもとに，ラベルの付いていないデータの正解を予測し，予測されたデータの中から正解である確率が高いものを正解ラベルの付いたデータに加え再度同じ学習を繰り返すというものである．

機械学習の中にはさらに強化学習というものが存在する．強化学習は，一連の行動の最後に報酬として評価値を得て，その評価値を得るに至るまでの過程の行動それぞれについて報酬を分配して与えるという学習方法である．

今回の研究で用いているものは教師あり学習によるクラス分類である．




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{深層学習}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第3章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{サポートベクタマシン}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
サポートベクタマシン (SVM) は2クラス分類問題の代表的手法であり，未知データに対して高い予測精度を持つ分類器が構築可能であることが知られている\cite{Takeuchi}．本章では，SVM の基本的な仕組みである分類境界となる超平面の決定方法，非線形の分類を可能とするカーネル法，さらに分離可能でないデータをSVMで分類する際に適用されるソフトマージンとハードマージンの差異について述べる．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{サポートベクタマシンの仕組み}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
一般に，訓練集合を分離できる分類境界は複数存在し得るため，様々な分類境界の作成方法が考えられるが，SVMではそれぞれのクラスのデータと分類境界の距離（マージン）が最も離れるように分類境界を決定するマージン最大化と呼ばれる方法で境界を決定している．この時，マージン最大化は分類境界と分類境界から最も近くに存在するデータとの距離を最大化することで実現可能である．また，分類境界の決定に使用されるデータをサポートベクタと呼び，サポートベクタは少なくとも1つ存在する．

SVMでは，特徴抽出器を使用し各入力画像から多次元特徴ベクトル$\bm{x}=[x_1,x_2,\cdots, x_{n}]^T$を抽出する．この特徴ベクトルがSVMの学習に使用され，学習によって$f(\bm{x})=0$で与えられる超平面と呼ばれる決定境界が得られる．$f(\bm{x})$は，これから分類される特徴ベクトル$\bm{x}$から超平面までの符号付き距離であり，次式で与えられる．
\begin{eqnarray}%sssNetの第？層から得られる特徴ベクトル
f(\bm{x}) = \sum^N_{i=1}\alpha_i y_i G(\bm{x}_i^*,\bm{x}) + b
%f(\bm{x}) = \sum^N_{i=1}\alpha_i \mbox{exp}{\left(-\left\| \frac{\bm{x}_i^* - \bm{x}_s}{k} \right\|^2 \right)} + b
%f(\bm{x}) = \sum^N_{i=1}\alpha_i e^{(-|| \bm{x}_i - \bm{x}||^2 )} + b
\label{eq:1}
\end{eqnarray}
ここで，$G(\bm{x}_i^*,\bm{x})$はカーネル関数，$\bm{x}_i^* \in \Re^{1 \times N} \ (i=1,2, \cdots, N)$は学習により決定されたサポートベクトル，$N$はサポートベクトルの数，$\alpha_i \ (i=1,2, \cdots, N)$と$b$はそれぞれラグランジュ乗数とバイアスであり，これらは逐次最小最適化 (SMO) を用いた学習によって推定されたSVMパラメータである．また，$y_i$は2クラス学習の場合，$\bm{x}_i^*$の陽性あるいは陰性に応じて$-$1または1に設定されたラベルである．分類はスコア$f(\bm{x})$の符号によって行われ，$f(\bm{x})>0$の場合は陰性，$f(\bm{x})<0$の場合は陽性であるといったように判断される．



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{カーネル法とカーネル関数}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
SVMに与えられるデータは必ずしも線形分離可能とは限らず，問題によっては非線形分離を行う必要がある場合も発生する．このような問題を解決するにあたり，データを入力した際に作られた入力空間を高次元の特徴空間と呼ばれる空間に写像し，特徴空間上でマージンが最大となるように超平面を決定する方法がとられる．

式 \ref{eq:1}にあるように，超平面を決定する際にカーネル関数と呼ばれる関数を使用する．このカーネル関数を使用することにより入力空間から特徴空間に写像し，非線形分離を可能とする．また，カーネル関数を使用するこれらの方法をカーネル法と呼ぶ．




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{ソフトマージンとハードマージン}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第4章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{画像処理}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
本研究では画像を対象とする．機械学習において，収集した画像をそのまま扱うことは稀であり，何らかの処理を施してCNNなどで処理が可能となるように変換する．本章では，ターゲットとする画像の中から必要となる一部分を抽出するテンプレートマッチングと，機械学習を行う際に過学習を防ぐことを目的としてデータを加工する画像オーギュメンテーションについて述べる．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{テンプレートマッチング}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
本節では，治具を含むラップフィルム品の全体画像に対してテンプレートマッチングを適用し，ラップフィルム部分のみを抽出する画像処理を行う．様々な課題に対する画像処理で広く利用されているテンプレートマッチングは，撮影されたワークの中で欠陥が含まれやすい目標領域を抽出するためにも非常に有効である．これを使用して製品の欠陥と関係しない治具等を取り除き，欠陥があらわれる製品部分のみを抽出する \cite{Nagata-2019}．

テンプレートマッチングの処理では，$(M, N)$ のサイズのテンプレートをターゲット画像内でラスタースキャンさせて相関係数の高い位置を検出する場合，周辺領域でもマッチング評価ができるようにパディング処理を行う．テンプレートとパディングにより拡張されたターゲット画像内の同面積の領域との相関係数$\alpha(u,v)$は，次式から計算される．
\begin{eqnarray}
\alpha(u,v) = \frac{s_{it}(u,v)}{s_{i}(u,v)s_{t}(u,v)}
\label{eq:10}
\end{eqnarray}
\begin{eqnarray}
s_{it}(u,v)=  \nonumber \\
\sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) - \bar{f}_{u,v} \Big\}
\Big\{ t(x-u,y-v) - \bar{t}\Big\}
\end{eqnarray}
\begin{eqnarray}
s_{i}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) -
\bar{f}_{u,v} \Big\}^2}
\end{eqnarray}
\begin{eqnarray}
s_{t}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ t(x-u,y-v)
- \bar{t}\Big\}^2}
\end{eqnarray}
% Figure extracted
%-------------------------------
\begin{figure}[t]
\begin{center}
\includegraphics[width=80mm ,clip]{./fig/template_matching2.eps}
\vspace{-2mm}
\caption{An example of extracted image using the template matching technique.}
\label{fig:templateimage}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
\\
ここで，$(u,v)$はターゲット画像内におけるテンプレート左上コーナーの座標である．$s_{t}(u,v)$と$s_{i}(u,v)$はそれぞれ，テンプレート内とターゲット内比較領域の標準偏差であり，$s_{it}(u,v)$は共分散である．$f(x,y)$は拡張された画像内の$(x,y)$におけるグレースケール256階調値を正規化した値である．$t(x-u,y-v)$はテンプレート内の$(x-u,y-v)$における同様の値である．$M$と$N$はそれぞれ，テンプレートの幅と高さである．$\bar{t}$と$\bar{f}(u,v)$はそれぞれ，テンプレート内のグレースケール値の平均値と，ターゲット画像内のテンプレート真下の領域のそれである．
式~(\ref{eq:10})で与えられる相関係数$\alpha(u,v)$は，テンプレートをターゲット画像内の左上から右下までラスタースキャンさせることで計算される．ラスタースキャン後，テンプレートと最もマッチする領域，すなわち最も大きな値$\alpha(u,v)$を持つ領域が抽出される．図~\ref{fig:templateimage}には，テンプレートで抽出されたラップフィルム品の画像の例を示している．今回の実験では，テンプレートマッチングによりラップフィルム品の画像解像度を特徴抽出器として用いるCNNの入力層に適合させやすいように$640 \times 480$から正方形の$347 \times 347$にダウンサイジングして用いた\cite{fss2020}．





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{画像オーギュメンテーション}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第5章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{実験}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{使用器具}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{方法}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{結果}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
汎化性能を評価するために，良品4035枚と不良品21枚の未学習の画像を用意し，学習終了後のSVMに分類させた．表\ref{table:AG confusion matrix}, \ref{table:AP confusion matrix}, \ref{table:VG confusion matrix}, および\ref{table:VP confusion matrix}には，AG, AP, VG, およびVPそれぞれの分類結果の混合行列を示す．なお，表内のActualとPredictedはそれぞれ，実際のラベルと予測されたラベルを表す．AG, AP, VG, およびVP全てに関して，分類実験に使用した画像の枚数が4056であることを考えると誤認識の枚数が最大6というのは分類性能の高い結果であると言える．

%%%%%%%%%%%%%%%
%Table 
%%%%%%%%%%%%%%%
% \begin{table}[t]
% \renewcommand{\arraystretch}{1.1}
% \small
% \vspace{-2mm}
% \caption{Confusion matrix of AG ($C$=0.5).}
%  \vspace{1mm}
% \label{table:AG confusion matrix}
% \centering
% \begin{tabular}{|c|cc|} 
% \hline
% \backslashbox{Act.}{Pred.} & NG & OK \\
% \hline
%  NG & 20 & 1 \\
%  OK & 2 & 4033 \\
% \hline
% \end{tabular}
% \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{table}[t]
% \renewcommand{\arraystretch}{1.1}
% \small
% \vspace{-2mm}
% \caption{Confusion matrix of AP ($C$=0.5).}
%  \vspace{1mm}
% \label{table:AP confusion matrix}
% \centering
% \begin{tabular}{|c|cc|} 
% \hline
% \backslashbox{Act.}{Pred.}  & NG & OK \\
% \hline
%  NG & 20 & 1 \\
%  OK & 0 & 4035 \\
% \hline
% \end{tabular}
% \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{table}[!t]
% \renewcommand{\arraystretch}{1.1}
% \small
% \vspace{-2mm}
% \caption{Confusion matrix of VG ($C$=0.5).}
%  \vspace{1mm}
% \label{table:VG confusion matrix}
% \centering
% \begin{tabular}{|c|cc|} 
% \hline
% \backslashbox{Act.}{Pred.}  & NG & OK \\
% \hline
%  NG & 20 & 1 \\
%  OK & 5 & 4030 \\
% \hline
% \end{tabular}
% \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{table}[!t]
% \renewcommand{\arraystretch}{1.1}
% \small
% \vspace{-2mm}
% \caption{Confusion matrix of VP ($C$=1).}
%  \vspace{1mm}
% \label{table:VP confusion matrix}
% \centering
% \begin{tabular}{|c|cc|} 
% \hline
% \backslashbox{Act.}{Pred.}  & NG & OK \\
% \hline
%  NG & 21 & 0 \\
%  OK & 4 & 4031 \\
% \hline
% \end{tabular}
% \end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
  \begin{center}
    \begin{tabular}{c}

      % 1
      \begin{minipage}{0.5\hsize}
\caption{Confusion matrix of AG ($C$=0.5).}
\label{table:AG confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pre.} & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 2 & 4033 \\
\hline
          \end{tabular}
      \end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      % 2
      \begin{minipage}{0.5\hsize}
        \begin{center}
\caption{Confusion matrix of AP ($C$=0.5).}
 \vspace{1mm}
\label{table:AP confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pre.}  & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 0 & 4035 \\
\hline
          \end{tabular}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}[htbp]
  \begin{center}
    \begin{tabular}{c}

      % 1
      \begin{minipage}{0.5\hsize}
        \begin{center}
\caption{Confusion matrix of VG ($C$=0.5).}
\label{table:VG confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pre.}  & NG & OK \\
\hline
 NG & 20 & 1 \\
 OK & 5 & 4030 \\
\hline
          \end{tabular}
        \end{center}
      \end{minipage}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\hfill
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
      % 2
      \begin{minipage}{0.5\hsize}
        \begin{center}
\caption{Confusion matrix of VP ($C$=1).}
 \vspace{1mm}
\label{table:VP confusion matrix}
\centering
\begin{tabular}{|c|cc|} 
\hline
\backslashbox{Act.}{Pre.}  & NG & OK \\
\hline
 NG & 21 & 0 \\
 OK & 4 & 4031 \\
\hline
          \end{tabular}
        \end{center}
      \end{minipage}

    \end{tabular}
  \end{center}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第6章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{考察}
%%%%%%%%%%%%%%%%%%%%%%%%
一般に，学習を行ったSVMの性能を検討する際には次式のような評価指標を用いる\cite{Tokyo}．
\begin{eqnarray}
Ac = \frac{TP+TN}{TP+FN+FP+TN}  
 \label{eq:acc}
 \end{eqnarray}
\begin{eqnarray}
Pr = \frac{TP}{TP+FP}  
 \label{eq:pr}
 \end{eqnarray}
\begin{eqnarray}
Re = \frac{TP}{TP+FN}  
 \label{eq:re}
 \end{eqnarray}
 \begin{eqnarray}
F = \frac{2\cdot Re\cdot Pr}{Re+Pr}  
 \label{eq:f}
 \end{eqnarray}
ここでは不良品を陽性，良品を陰性とし，全体のデータの中で不良品を不良品として分類したものを$TP$，良品を良品として分類したものを$TN$，不良品を良品として分類したものを$FN$，さらに良品を不良品として分類したものを$FP$として値を決定した．これらの値から式(\ref{eq:acc}), (\ref{eq:pr}), (\ref{eq:re}), および(\ref{eq:f})で与えられるAccuracy(\textit{Ac}), Precision(\textit{Pr}), Recall(\textit{Re}), およびF値(\textit {F})をそれぞれ算出する．
今回の分類結果をもとに算出した各評価指標を表\ref{table:comparison}に示す．

\begin{table}[!b]
\renewcommand{\arraystretch}{1.1}
\small
\vspace{-2mm}
\caption{Comparison of result.}
 \vspace{1mm}
\label{table:comparison}
\centering
\begin{tabular}{c|cccc} 
\hline
   & AG & AP & VG & VP\\
\hline
\textit {Ac} & 0.999 & 0.999 & 0.999 & 0.999\\
\textit {Pr} & 0.909 & 1 & 0.8 & 0.84\\
\textit {Re} & 0.952 & 0.952 & 0.952 & 1\\
\textit {F } & 0.930 & 0.976 & 0.870 & 0.913\\
\hline
\end{tabular}
\end{table}
これら4つの指標のうちAccuracyは，全ての予測のうち正しく分類できたものはどれだけかを表す指標である．Precisionは，陽性と予測した画像が実際に陽性であった割合を示しており，Recallは，陽性の画像を陽性と予測できた割合を表す指標である．さらにF値は，PrecisionとRecallのバランスを示す指標である．

従来，画像認識を応用したラップフィルムの欠陥検出は難しい課題とされてきたが，表\ref{table:comparison}のAccuracyの値より今回設計したSVMの分類性能は優れているといえる．次に，Precisionに着目するとAG, APは0.9以上を記録しているのに対し，VG, VPは0.9未満であり，本実験の条件においてはAlexNetを特徴抽出器としたSVMの方が良品を不良品と誤認識することが少なかったということになる．さらに，Recallに関しては，分類実験用のデータセットに含まれる不良品の画像が少なかったことに起因して値が変動しやすく，VP以外のSVMでも誤認識枚数は1枚であるが，指標に大きな差が生じた．よって，Recallの値のみに着目すればVPが優れているように思えるが，表\ref{table:AG confusion matrix}, \ref{table:AP confusion matrix}, \ref{table:VG confusion matrix}, \ref{table:VP confusion matrix}から，大きな差はないと言える．

特徴抽出器ごとに指標を比較すると，PrecisionとF値の2点でAGよりAPの方が優れており，VPはVGにPrecision, Recall, F値の3点で優れていることがわかる．さらにAPとVPを比較すると，APはRecallでは劣るものの，PrecisionとF値ではVPより優れているという点からAPの方がより良い性能を有していると考えられる．よって，本実験の条件下ではPrecisionおよびF値から，特徴抽出器としてはVGG19よりAlexNetの方が適しており，カーネル関数としてはガウス関数より多項式関数の方が適していたと推測できる．今後，さらに不良品の画像を収集可能になれば，その不良品画像を使った追加学習を行うことで，より分類性能の高いSVMを構築できるものと期待される．
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%				第7章					%%%%%%%%%%%%
%%%%%%%%%%%%										%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結言}
%%%%%%%%%%%%%%%%%%%%%%%%
本研究では，ラップフィルム品の欠陥検出を行うことができるSVMについて検討した．実験では，特徴抽出器として用いるCNN，カーネル関数，分離平面のマージン内のデータに与えるペナルティの程度である正則化係数の値を変更しながら，より分類性能の高いSVMの設計を目指した．特徴抽出器にはAlexNetあるいはVGG19を，カーネル関数にはガウス関数と多項式関数をそれぞれ組み合わせて2クラス分類を行うSVM (TCSVM)を設計した．評価実験の結果，今回の条件下では特徴抽出器にはAlexNetを，カーネル関数には多項式関数を使用し，正則化係数を1以下にして設計したSVMが最も性能が高かった．

実際の製造ラインにおいて不良品が良品と誤認識されることはリコールなど重大な事態につながりかねない．一方，良品が不良品と誤認識されることは生産工程における大きな損失につながる．本研究で使用したアプリケーションは，不良品検出用のSVM構築に関して有効なツールであることが確認できたため，今後はラップフィルム以外の製品の欠陥検出用SVMの構築にも適用できるのかの検証を行いたい．



\backmatter% ここから後付
\chapter{謝辞}%%%%%%%%%%%%%%% 謝辞 %%%%%%%
本研究は，山口東京理科大学大学院基礎工学研究科基礎工学専攻で行われたものである．
\begin{thebibliography}{}%%%参考文献%%%%%%

\bibitem{Nishimura}
西村 晃紀，柳部 正樹，青戸 勇太，長谷 智紘，森山 健，前田 俊二，``HOG特徴量を電子部品検査に適用した場合の課題検討，"2017年度精密工学会秋季大会学術講演会講演論文集，pp. 219--220, 2017.

\bibitem{YANG}
X. Yang, M. Han, H. Tang, Q. Li, X. Luo, ``Detecting Defects With Support Vector Machine in Logistics Packaging Boxes for Edge Computing," IEEE Access, Vol. 8, pp. 64002--64010, 2020.

\bibitem{Nagata-2019}
F. Nagata, K. Tokuno, K. Mitarai, A. Otsuka, T. Ikeda, H. Ochi, K. Watanabe, M.K. Habib, ``Defect detection method using deep convolutional neural network, support vector machine and template matching techniques," {\it Artificial Life and Robotics}, Vol. 24, No. 4, pp. 512--519, 2019.

\bibitem{fss2020}
中島 健斗，永田 寅臣，渡辺 桂吾，``畳み込みニューラルネットワークを用いたラップロール製品の不良品検出," 第36回ファジィシステムシンポジウム 論文集, MC2-4, 5 pages, 2020.

\bibitem{Robomech}
中島 健斗, 永田 寅臣,  渡辺 桂吾,``畳み込みニューラルネットワーク(CNN)とサポートベクターマシン(SVM)を用いた微小な欠陥を持つ不良品検出の基礎研究," ロボティクス・メカトロニクス講演会 2019 講演論文集, 2A1-Q05, 4 pages, 広島国際会議場, 2019.

\bibitem{MATLAB}
MATLAB, ``https://jp.mathworks.com/"

\bibitem{Takeuchi}
竹内 一郎，鳥山 昌幸，``サポートベクトルマシン," 講談社, 2015.

\bibitem{Tokyo}
中川 裕志, ``東京大学工学教程 情報工学 機械学習," 丸善出版, 2015

% \bibitem{AlexNet}
% Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton, ``ImageNet Classification with Deep Convolutional Neural Networks," {\it Neural Information Processing Systems Conference}, 2012.

% \bibitem{Arobo}
% Kento Nakashima, Fusaomi Nagata, Hiroaki Ochi, Akimasa Otsuka, Takeshi Ikeda, Keigo Watanabe, Maki K. Habib, “Detection of Minute Defects Using Transfer Learning-Based CNN Models,” Procs.
% of 25th International Symposium on Artificial Life
% and Robotics, pp. 871?875, 2020.
%\bibitem{SMO}


\end{thebibliography}


\end{document}


