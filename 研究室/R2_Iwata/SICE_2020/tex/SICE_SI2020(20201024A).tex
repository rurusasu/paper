\documentclass[a4paper]{jarticle}
\usepackage{sice-si}
\usepackage{amsmath} 
\usepackage{graphicx}


\begin{document}
%
% タイトルと著者名
\title{畳み込みニューラルネットワーク(CNN)の転移学習を用いた\\ラップフィルムの不良品検出\\\large{ーVGG19の転移学習によるCNNの設計と評価ー}} % 和文タイトル
\name{○岩田 賢洸（山口東京理科大学工学部機械工学科），中島 健斗，三木 康平\\永田 寅臣（山口東京理科大学大学院工学研究科），渡辺 桂吾（岡山大学大学院自然科学研究科）\\} % 著者名
\etitle{Detection of Defective Wrap Film Using Transfer Learning of Trained Convolutional Neural Network (CNN)\\\large{ー Design and evaluation of CNN model obtained by transfer learning of VGG19 ー}} % 英文タイトル
\ename{○Takahiro IWATA (Department of Mechanical Engineering, Sanyo-Onoda City University)\\Kento NAKASHIMA, Kohei MIKI, Fusaomi NAGATA (Graduate School of Engineering, Sanyo-Onoda City University)\\Keigo WATANABE (Graduate School of Natural Science and Technology, Okayama University)}	%著者名（英）
%
% アブストラクト
\abst{The authors have developed an application that can carry out transfer learning of Convolutional Neural Networks (CNNs). In this paper, we design two kinds of CNN models transferred from VGG19, i.e., with and without weights freezing in convolutional layers. The CNN models are trained using a large number of two categorized images of wrap film products, i.e., with and without defects. Before training process, our implemented template matching is applied to all images to extract only the film portion, so that the load regarding image processing can be largely reduced. The performance of the two kinds of CNN models are quantitatively evaluated and compared.
}
% タイトルの出力
\maketitle
%
% 本文
%%%%%%%%%%%%%%%%%
\section{緒言}
%%%%%%%%%%%%%%%%%
これまでにも畳み込みニューラルネットワーク(CNN) を製品や構造物の欠陥検出に応用した研究がある．例えば，浅田らは道路舗装の路面画像に対してCNNを適用し，ひび割れとパッチングを検出する研究を行っている\cite{Asada}．

本研究では学習済みのCNNモデルの転移学習により，ラップフィルムの製造工程において発生する欠陥を持つ不良品の検出を行うことができるシステムを提案する．学習済みのCNNにはVGG19を用いる．図~\ref{fig:wrapfilm}には今回の不良品検出で対象とするラップフィルムの良品と不良品の画像の例を示す．

本研究ではまず，治具を含んだラップフィルムの画像に対してテンプレートマッチングを適用し，不良品検出のターゲットとなるフィルム部分のみを抽出する画像処理を行う．次に，VGG19の全結合層部を2クラス分類用に置き換えて新たなCNNを設計する．画像オーギュメンテーションを施した多数の訓練画像を用いて追加学習（ファインチューニング）を行う．この場合，畳み込み層の重み更新を軽微に行いながら訓練したCNNと重み更新を行わずに訓練したCNNを準備する．不良品が含まれたテスト画像の分類実験によって設計した2種類のCNNの性能を評価し，比較する．


%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%
\section{VGG19の転移学習によるCNNを用いた不良品検出}
%%%%%%%%%%%%%%%%%％％％％％％％
\subsection{相関係数に基づくマッチング領域の抽出}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
様々な課題に対する画像処理で広く利用されているテンプレートマッチングは，撮影されたワークの中で欠陥が含まれやすい領域を抽出するためにも非常に有効である．これから設計するCNNへの入力画像のサイズを大幅に減らすことができ，計算コスト，メモリ占有コストを軽減することができる．このため，開発したメインオプション及びオーギュメンテーションのダイアログの中ではテンプレートマッチング機能を利用できるようにしている．

図~\ref{fig:template}に示すように$(M, N)$ のサイズのテンプレートをターゲット画像内でラスタースキャンさせて相関係数の高い位置を検出する場合，周辺領域でもマッチング評価ができるようにパッディング処理を行う．テンプレートとパッディングにより拡張されたターゲット画像内の同面積の領域との相関係数$\alpha(u,v)$は，次式から計算される．
\begin{eqnarray}
\alpha(u,v) = \frac{s_{it}(u,v)}{s_{i}(u,v)s_{t}(u,v)}
\label{eq:10}
\end{eqnarray}
\begin{eqnarray}
s_{it}(u,v)=  \nonumber \\
\sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) - \bar{f}_{u,v} \Big\}
\Big\{ t(x-u,y-v) - \bar{t}\Big\}
\end{eqnarray}
\begin{eqnarray}
s_{i}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ f(x,y) -
\bar{f}_{u,v} \Big\}^2}
\end{eqnarray}
\begin{eqnarray}
s_{t}(u,v)= \sqrt{ \sum_{y=v}^{v+N-1}\sum_{x=u}^{u+M-1}\Big\{ t(x-u,y-v)
- \bar{t}\Big\}^2}
\end{eqnarray}
%%%%%%%%%%%%%%%%%
% 使用画像
%%%%%%%%%%%%%%%%%
 \begin{figure}[t]
 \begin{center}
 %\vspace{1mm}
 \includegraphics[width=80
mm,clip]{./figure/image.eps}
\vspace{-2mm}
 \caption{Image samples of wrap films with and without several kinds of defects.}
 \label{fig:wrapfilm}
 \end{center}
 \end{figure}
%%%%%%%%%%%%%%%%%
% Figure template
%%%%%%%%%%%%%%%%%
\begin{figure}[t]
\begin{center}
\includegraphics[width=70mm ,clip]{./figure/template.eps}
\vspace{-2mm}
\caption{Configuration among a target image, padding area and template
image whose size is  $(M,N)$.}
\label{fig:template}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
\\
ここで，$(u,v)$はターゲット画像内におけるテンプレート左上コーナーの座標である．$s_{t}(u,v)$と$s_{i}(u,v)$はそれぞれ，テンプレート内とターゲット内比較領域の標準偏差であり，$s_{it}(u,v)$は共分散である．$f(x,y)$は拡張された画像内の$(x,y)$におけるグレースケール256諧調値を正規化した値である．$t(x-u,y-v)$はテンプレート内の$(x-u,y-v)$における同様の値である．$M$と$N$はそれぞれ，テンプレートの幅と高さである．$\bar{t}$と$\bar{f}(u,v)$はそれぞれ，テンプレート内のグレースケール値の平均値と，ターゲット画像内のテンプレート真下の領域のそれである．
式~(\ref{eq:10})で与えられる相関係数$\alpha(u,v)$は，テンプレートをターゲット画像内の左上から右下までラスタースキャンさせることで計算される．ラスタースキャン後，テンプレートと最もマッチする領域，すなわち最も大きな値$\alpha(u,v)$を持つ領域が抽出される．図~\ref{fig:template_matching}には，テンプレートで抽出されたラップフィルムの画像の例を示している．今回の実験では，テンプレートマッチングによりラップフィルムの画像解像度を$640 \times 480$から$347 \times 347$にダウンサイジングした．
%%%%%%%%%%%%%%%%%
% Figure extracted
%-------------------------------
\begin{figure}[t]
\begin{center}
\includegraphics[width=80mm ,clip]{./figure/template_matching.eps}
\vspace{-2mm}
\caption{An example of extracted image using the implemented template matching
technique.}
\label{fig:template_matching}
\end{center}
\end{figure}
%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%
\subsection{VGG19の転移学習による新たなCNNの設計}
%%%%%%%%%%%％％％％％％

%%%%%%%%%%%%%%%%%
%Original VGG19の構造
%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
\begin{center}
%\vspace{1mm}
\includegraphics[width=180
mm,clip]{./figure/O_VGG19.eps}
\vspace{-8mm}
\caption{Architecture of original VGG19.}
\label{fig:O_VGG19}
\end{center}
\end{figure*}
%%%%%%%%%%%%
 
%%%%%%%%%%%%%%%%%
 %設計したCNNのアプリケーション
%%%%%%%%%%%%%%%%%
\begin{figure*}[t]
 \begin{center}
 %\vspace{1mm}
 \includegraphics[width=160
mm,clip]{./figure/soft.eps}
\vspace{-2mm}
 \caption{A part of main dialog developed on MATLAB system to user-friendly design original CNNs.}
 \label{fig:main dialog}
 \end{center}
 \end{figure*}
 %%%%%%%%%%%
 
%%%%%%%%%%%%%%%%%
%VGG19_2の構造
%%%%%%%%%%%%%%%%%
 \begin{figure*}
\begin{center}
%\vspace{1mm}
\includegraphics[width=180
mm,clip]{./figure/T_VGG19.eps}
\vspace{-10mm}
\caption{Architecture of newly designed CNN obtained by transferring the original VGG19.}
\label{fig:T_VGG19}
\end{center}
\end{figure*}
%%%%%%%%%%%%%%%%%
 

転移学習には学習済みのCNNのモデルの重みを初期値として用い，目的のタスクに応じた学習データセットに合うように全結合層を置き換え，追加学習を行うファインチューニングという手法がある．本研究ではVGG19の転移学習により設計したCNNに対してファインチューニングを行う．図~\ref{fig:O_VGG19}に示すようにVGG19は16の畳み込み層と3つの全結合層を含む合計47層から構成されている．最初の畳み込み層は，224$\times$224$\times$3のサイズの入力画像に対して，縦横サイズとチャネル数が3$\times$3$\times$3の64枚のフィルタにより64枚の特徴マップを生成する．第2の畳み込み層は最初の畳み込み層の出力を受け取り，3$\times$3$\times$64の特徴マップを64枚，第3の畳み込み層は
，3$\times$3$\times$64のサイズのフィルタを128枚，第4の畳み込み層は，3$\times$3$\times$128サイズのフィルタを128枚，第5の畳み込み層は3$\times$3$\times$128サイズのフィルタを256枚，第6から第8の畳み込み層は3$\times$3$\times$256サイズのフィルタを256枚，第9の畳み込み層は3$\times$3$\times$256サイズのフィルタを512枚生成する．第10から第16の畳み込み層は3$\times$3$\times$512サイズのフィルタを512枚有し，フィルタと同数の特徴マップを生成する．全結合層は，4,096$\times$4,096$\times$1,000個の重みを有する．オリジナルのVGG19は，ImageNetデータベースの130万枚の画像を用いて訓練されており，入力画像をキーボード，マウス，鉛筆，多くの種類の動物などを含む1,000種類のオブジェクトクラスに分類できる\cite{VGG}．
%%%%%%%%%%%%%%%%%
\subsection{分類実験}
%%%%%%%%%%%%%%%%%
図~\ref{fig:main dialog}にはMATLAB上で開発したCNNの設計及び転移学習のためのソフトウェアを示す~\cite{Application}．本研究ではこのソフトウェアの転移学習機能を用いて2クラス分類用のVGG19\_2を設計した．図~\ref{fig:T_VGG19}には設計したVGG19\_2の構造を示す．訓練用データセットとして良品34,482枚と，不良品2,233枚，計36,715枚を用いた．共通の学習条件として，最大エポックを2，ミニバッチサイズを30，全結合層の学習率を0.001に設定した上で，畳み込み層の学習率を0.0001とした場合と0（畳み込み層の重み更新，すなわち学習を行わない）とした場合の2つの条件で訓練を行った．ここで, 学習率を0.0001とすることで畳み込み層の重み更新を軽微に行いながら訓練したCNNをVGG19\_2A, 学習率を0とすることで畳み込み層の重み更新を行わずに訓練したCNNをVGG19\_2Bとする．

次に訓練したVGG19\_2A, VGG19\_2Bの汎化性能を評価するために未学習のテスト画像として良品4,035枚と，不良品21枚用意し，分類実験を行った．表~\ref{table:VGG19_2Aconfusion}と表~\ref{table:VGG19_2Bconfusion}にはそれぞれVGG19\_2A, VGG19\_2Bの全体的な認識結果を表す混合行列(縦軸：実際のクラス，横軸：予測クラス)を示す．
テスト画像に対して誤認識した画像枚数は，表~\ref{table:VGG19_2Aconfusion}によりVGG19\_2Aを用いた場合は6枚，表~\ref{table:VGG19_2Bconfusion}によりVGG19\_2Bを用いた場合は4枚となった．
%%%%%%%%%%%%%%%%%
%Confusion matrix classified by VGG19_2A 
%%%%%%%%%%%%%%%%%
\begin{table}[h]
\renewcommand{\arraystretch}{1.3}
\small
\caption{Confusion matrix classified by VGG19\_2A (row: true labels, column: predicted labels).}
\vspace{1mm}
\label{table:VGG19_2Aconfusion}
\centering
\begin{tabular}{c|cccccc}
\hline
 & Normal & Anomaly \\
\hline
Normal & 4033 & 4\\
Anomaly & 2 & 17 \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%
%Confusion matrix classified by VGG19_2B 
%%%%%%%%%%%%%%%%%
\begin{table}[h]
\renewcommand{\arraystretch}{1.3}
\small
\caption{Confusion matrix classified by VGG19\_2B (row: true labels, column: predicted labels).}
\vspace{1mm}
\label{table:VGG19_2Bconfusion}
\centering
\begin{tabular}{c|cccccc}
\hline
 & Normal & Anomaly \\
\hline
Normal & 4031 & 0\\
Anomaly & 4 & 21 \\
\hline
\end{tabular}
\end{table}
%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%
\section{比較結果}
%%%%%%%%%%%%%%%%%
VGG19\_2AとVGG19\_2Bの性能を比較するために，前章までの分類結果をもとに認識率，精度，再現性およびF値の4つの基準で評価を行った．

認識率はテスト画像の全データのうち正しく分類された割合を，精度は不良品と分類された画像のうち実際に不良品である割合を，再現性は実際の不良品データのうち正しく不良品と分類された割合を，さらにF値は精度と再現性の調和平均をそれぞれ表している．全体のデータの中で不良品を不良品として分類したものを$T_P$，良品を良品として分類したものを$T_N$，不良品を良品として分類したものを$F_N$，さらに良品を不良品として分類したものを$F_P$としたとき，認識率$A_c$，精度$P_r$，再現性$R_e$，F値$F$はそれぞれ次式で与えられる．
\begin{eqnarray}
A_c = \frac{T_P+T_N}{T_P+T_N+F_P+F_N}  
 \label{eq:Accuracy}
 \end{eqnarray}

\begin{eqnarray}
P_r = \frac{T_P}{T_P+F_P}  
 \label{eq:Recall}
 \end{eqnarray}
 
 \begin{eqnarray}
R_e = \frac{T_P}{T_P+F_N}  
 \label{eq:Recall}
 \end{eqnarray}
 
 \begin{eqnarray}
F = \frac{2\times P_r\times R_e}{P_r+R_e}  
 \label{eq:Recall}
 \end{eqnarray}

表~\ref{table:Comparison}には表~\ref{table:VGG19_2Aconfusion},~\ref{table:VGG19_2Bconfusion}をもとにしたこれら4つの評価結果を示す．表~\ref{table:Comparison}より，認識率につてはVGG19\_2AとVGG19\_2B共に0.999であった．Kandelらの研究では，畳み込み層の重みを全結合層のそれより軽微に更新させることでより優れた認識率が得られていたようであるが，今回の実験ではそのような優位性は見受けられなかった\cite{VGG_FT}．また，再現性はVGG19\_2A が0.810，VGG19\_2B が1.000とVGG19\_2Bの方が高い結果となった．VGG19\_2Bの再現性が1.000であるということは，不良品を全て検出することができているということになる．これらの結果から，不良品検出のためのシステムとしてはVGG19\_2Bの方が優れていると言える．

%%%%%%%%%%%%%%%%%
%CNN Result
%%%%%%%%%%%%%%%%%
\begin{table}[t]
\renewcommand{\arraystretch}{1.3}
\small
\caption{Statistical evaluation results.}
\vspace{1mm}
\label{table:Comparison}
\centering
\begin{tabular}{c|cccccc} 
\hline
CNN & Accuracy & Precision & Recall & F \\
\hline
VGG19\_2A & 0.999 & 0.894 & 0.810 & 0.850 \\
VGG19\_2B & 0.999 & 0.840 & 1.000 & 0.913 \\
\hline
\end{tabular}
\end{table}	
%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%
\section{結言}
%%%%%%%%%%%%%%%%%高い精度で
本研究では学習済みのCNNモデルの転移学習により，ラップフィルムの不良品検出を行うことができるシステムを提案した．学習済みのCNNにはVGG19を用い，クラス分類の数に応じて全結合層部を置き換えた．まず，治具を含んだラップフィルムの全体画像に対してテンプレートマッチングを適用し，不良品検出のターゲットとなるフィルム部分のみを抽出する画像処理を行った．次に，VGG19の全結合層部を 2 クラス分類用に置き換えた新たな CNNを設計し，画像オーギュメンテーションを施した多数の訓練画像を用いて追加（ファインチューニング）学習を行った．追加学習では畳み込み層の重み更新を軽微に行いながら訓練したCNNと，畳み込み層の重み更新を行わずに訓練したCNNを設計し，不良品が含まれたテスト画像の分類実験によってそれぞれの性能を評価し，比較した．Kandelらによる研究では，認識率については畳み込み層の重み更新を軽微に行いながら訓練したCNNを用いた場合に高い性能が得られていたが，本研究では2つCNNの認識率に優位性は見受けられなかった．また，別途行った再現性の評価では，畳み込み層の重み更新を行わずに転移学習を行ったCNNを用いた場合により優れた結果が得られた．

%%%%%%%%%%%%%%%%%	
%参考文献
%%%%%%%%%%%%%%%%%
\begin{thebibliography}{99}
\bibitem{Asada}
浅田 拓海, 川村 和将, 石田 篤徳, 亀山 修一, ``Convolutional Neural Networkを用いたひび割れ・パッチングの高精度検出手法の開発," 土木学会論文集E1 (舗装工学), Vol. 74, No. 3, pp. I\_131-I\_139, 2018.
\bibitem{VGG}
K. Simonyan, A. Zisserman, ``Very deep convolutional networks for large-scale image recognition," Procs. of ICLR2015, pp. 1--14, 2015.
\bibitem{Application}
永田 寅臣, 渡辺 桂吾, ``不良品検出のための畳み込みニューラルネットワークとサポートベクターマシン設計支援ツール,"  ファジィ，ニューロ，確率手法が実際の制御で役立つのか, システム/制御/情報, VOl. 64, No. 8, pp. 304-309, 2020.
\bibitem{VGG_FT}
I. Kandel, M. Castelli, ``How deeply to fine-tune a convolutional neural network: A case study using a histopathology dataset," Applied Science, vol.10, no.10, pp. 1--20, 2020.

\end{thebibliography}
%
%
%
\end{document}

