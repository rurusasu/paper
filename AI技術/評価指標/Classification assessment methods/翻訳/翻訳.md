# Classification assessment methods

# 備考
## 著者
Alaa Tharwat

## 掲載
''Classification assessment methods," {\itApplied Computing and Informatics}, Vol. 16, No. 2, 25 pages, 2020.

# Abstract

分類技術は、様々な科学分野で多くの応用がなされています。分類アルゴリズムの評価にはいくつかの方法があります。このような指標の分析とその重要性は、異なる学習アルゴリズムを評価するために正しく解釈されなければならない。これらの尺度の多くはスカラーメトリクスであり、その中にはグラフィカルな手法を用いたものもある。本論文では、この分野に関心のある研究者のための総合的な資料となることを目的として、分類評価指標の詳細な概要を紹介します。この概説は、まず、2値分類問題や多クラス分類問題における混同行列の定義を強調することから始まります。また、多くの分類尺度についても詳細に説明し、各尺度におけるバランスのとれたデータと不均衡なデータの影響を示す。例示的な例が紹介され、(1)2値分類問題や多値分類問題におけるこれらの尺度の計算方法、(2)バランスのとれたデータや不均衡なデータに対するいくつかの尺度のロバスト性を示しています。さらに、受信機動作特性(ROC)、精度-リコール、検出誤差トレードオフ(DET)曲線のようないくつかのグラフィカルな測定値が詳細に示されています。さらに、ROC,PR,DET曲線をプロットする前処理の手順を説明するために、ステップバイステップのアプローチで、異なる数値例を示している。

# 2. Classification

評価方法は、分類器の性能を評価し、分類器のモデル化を導く上で重要な要素です。分類プロセスには大きく分けて、訓練段階、検証段階、テスト段階の3つの段階があります。モデルは入力パターンを用いて訓練され、このフェーズを訓練フェーズと呼ぶ。これらの入力パターンは、モデルを訓練するために使用される訓練データと呼ばれます。この段階では、分類モデルのパラメータが調整されます。訓練誤差は、訓練されたモデルが訓練データにどれだけ適合するかを測定します。しかし、訓練されたモデルが訓練段階で使用される同じデータに適合するため、訓練誤差は常にテスト誤差や検証誤差よりも小さくなります。学習アルゴリズムの目標は、学習データから学習して、目に見えないデータのクラスラベルを予測することです。しかし、テストサンプルのクラスラベルや出力が未知であるため、テスト誤差やサンプル外誤差を推定することはできません。これが，検証フェーズが訓練されたモデルの性能を評価するために使用される理由です．検証段階では，検証データは，モデルのハイパーパラメタを調整しながら，訓練されたモデルの偏りのない評価を提供する．

クラスの数に応じて、クラスが2つしかない2クラス分類と、クラスの数が2つより多い多クラス分類の2種類の分類問題があります。2つのクラス、すなわち、正のクラスを$P$、負のクラスを$N$とする2値分類があるとします。未知のサンプルは、$P$または$N$に分類され、学習段階で学習された分類モデルは、未知のサンプルの真のクラスを予測するために使用されます。この分類モデルは、連続または離散の出力を生成します。分類モデルから生成される離散出力は、未知/テストサンプルの予測された離散クラス・ラベルを表し、連続出力はサンプルのクラス・メンバーシップ確率の推定を表します。

図1:2x2混同行列の例を示します。2つの真のクラスPとNがあり，予測されたクラスの出力は真か偽かである．

図1は、2x2混同行列または分割表の要素を表す4つの可能な出力があることを示しています。緑の対角線は正しい予測値を、ピンクの対角線は正しくない予測値を表しています。サンプルが陽性であり，陽性に分類された場合，すなわち正しく分類された陽性サンプルは，真の陽性(TP)としてカウントされ，陰性に分類された場合は，偽陰性(FN)またはタイプIIエラーとみなされます．サンプルが陰性であり、陰性に分類された場合は真陰性(TN)とみなされ、陽性に分類された場合は偽陽性(FP)、誤報、またはタイプIエラーとみなされます。次のセクションで紹介するように、混同行列は、多くの一般的な分類メトリックを計算するために使用されます。

図2は、3つのクラス（A,B,C）を持つマルチクラス分類問題の混同行列を示している。このように、TPAはクラスAの真の陽性サンプル数、すなわちクラスAから正しく分類されたサンプル数であり、EABはクラスAからクラスBとして誤って分類されたサンプル数、すなわち誤分類されたサンプル数である。したがって、Aクラスの偽陰性（FNA）はEABとEACの和（FNA¼EABþEAC）であり、これはクラスBまたはCとして誤って分類されたすべてのクラスAのサンプルの和を示している。一方、行に位置する予測されたクラスの偽陽性は、その行のすべてのエラーの合計を表します。例えば、クラスA（FPA）の偽陽性は次のように計算されます。3mの混同行列では、正しい分類と2つの可能性のある誤差がある [22]。

# 2.1. Classification metrics with imbalanced data.

あるデータセットのあるクラスのサンプル数が他のクラスのサンプル数を上回っている場合には，異なる評価方法が不均衡なデータに敏感に反応します[25]．これを説明するために，図1の混同行列を考えてみましょう．クラス分布は、正のサンプルと負のサンプルの間の比率$\frac{P}{N}$で、左列と右列の間の関係を表します。両方の列からの値を使用する評価メトリックは、[8]で報告されているように、不均衡なデータに敏感になります。例えば，精度や精度1 のような評価指標の中には，混同行列の両列の値を使用しているものがあります．したがって，このようなメトリクスでは，異なるクラスからの修正ラベルの数を区別することはできません[11]．幾何平均(GM)やYou den's index(YI)2のように、両列の値を使用するメトリクスがあり、セメト リックはバランスの取れたデータと不均衡なデータで使用できるので、この事実は部分的には正しいと言えます。これは、片方の列の値を用いるメトリクスは、クラス分布の変化を打ち消すと解釈することができる。しかし、両カラムの値を用いるメトリクスの中には、クラス分布の変化が相殺されてしまうため、不均衡データの影響を受けないものもある。例えば、精度は$Acc=\frac{TP+TN}{TP+TN+FP+FN}$、$GM$は以下のように定義される。

$$
GM = \sqrt{TPR \times TNR} = \sqrt{\frac{TP}{TP+FN} \times \frac{TN}{TN+FP}}
$$

したがって，両方のメトリクスは混同行列の両列からの値を使用します．クラス分布の変更は，ネガティブクラス/ポジティブクラスのサンプル数を増減させることで得ることができる．同じ分類性能で、負のクラスのサンプル数を$\alpha$ 倍に増やしたと仮定すると、$TN$と$FP$の値はそれぞれ$\alpha TN$と$\alpha FP$になり、精度は次のようになります。

$$
ACC = \frac{TP+\alpha TN}{TP +\alpha TN + \alpha FP +FN}
\neq
\frac{TP +TN}{TP+TN+FP+FN}
$$

つまり、クラス分布の変化によって精度が左右されることになります。一方、$ＧＭ$ メトリックは

$$
GM = \sqrt{\frac{TP}{TP+FN} \times \frac{\alpha TN}{\alpha TN +\alpha FP}}
=
\sqrt{\frac{TP}{TP+FN}\times \frac{TN}{TN+FP}}
$$

となり、負のクラスの変化は互いに打ち消し合うことになります。これが$GM$メトリックが不均衡データに適している理由です。同様に、どのようなメトリックでも、それが不均衡なデータに対して敏感かどうかを調べることができます。

# 2.2. Accuracy and error rate
