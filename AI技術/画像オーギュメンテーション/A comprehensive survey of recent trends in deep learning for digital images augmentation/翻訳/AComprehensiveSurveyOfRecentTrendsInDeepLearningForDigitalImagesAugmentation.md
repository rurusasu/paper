# A comprehensive survey of recent trends in deep learning for digital images augmentation

# Abstract

深層学習は、コンピュータビジョン、画像分類、物体認識、画像セグメンテーションなど、コンピュータサイエンスの多くの分野でその効率性が実証されています。深層学習モデルは、主に大規模なデータセットの利用可能性に依存します。データセットに多くの画像が存在しないと、様々な深層学習モデルが学習できず、正確なモデルを構築できない。残念ながら、医療用画像など、大量のデータにアクセスできない分野もあります。例を挙げます。世界ではCOVID-19ウイルスのデータセットの不足に悩まされており、2020年初頭のベンチマークデータセットがありません。このパンデミックが本調査の主な動機となり、画像データを増やすために使用できる現在の画像データ強化技術を提供し、議論することになりました。本論文では、Deep Learningにおけるデジタル画像のデータ増強の概要を紹介します。一般的にデータ増強の重要性を反映した導入部から始まります。第2章では、画像データ増強とフォトメトリック変換の古典的な分類法を紹介する。第3章では、Deep Learningを用いた画像データ増強を説明します。最後に、第4セクションでは、様々なDeep Learningの研究と応用分野における画像データ増強技術の使用に関する技術の状態をレビューします。

# Intro

データ・オーグメンテーション(Dyk and Meng 2001)は、データ・サンプル、特に画像データ・セットの限界を克服するために非常に重要である。データはすべての機械学習アルゴリズムの原材料であり、図1に示すように、アルゴリズムに供給するために使用される手段でもあるため、データやそのラベルが不足すると、機械学習で提案されたモデルの精度に影響を与える可能性があります(Baştanlar and Özuysal 2014)。**画像の増強は、追加の画像を含まないニューラルネットワークモデルのために画像のコレクションを成長させるための効果的なトレーニング戦略の1つ**です。画像データの増強は、以下の理由で非常に必要とされています。

    1. ラベルアノテーションを伴う通常のデータ収集と比較して、安価な方法である。
    2. 元々、自然界のグランドトゥルースデータから生成されているため、非常に正確である。
    3. 制御可能であり、バランスの取れたデータを生成するのに役立つ。
    4. オーバーフィッティング問題の解決に貢献する（Subramanian and Simon 2013）。
    5. テスト精度の向上に役立つ。

**深層学習(DL)は、機械学習のサブカテゴリであり(Baştanlar and Özuysal 2014)、結果的に人工知能のサブセットとなる(Nilsson 1981)** DLは、アルゴリズムに模倣による学習を指示します。DLは、人間の脳の働き、特にデータやトレンドに接するときの働きをシミュレートし、意思決定に役立てることを目的としています。DLは、コンピュータビジョン（Ponce and Forsyth 2012）、画像分類、物体認識（Papageorgiou et al. 1998）、画像セグメンテーション（Pal and Pal 1993）などの秘訣です。深層学習では、データが学習の主な源であり、十分なデータ（特に画像）がなければ、DLモデルは学習して正確なモデルを生成することができません。**深層学習戦略を用いたモデルは、オーバーフィッティングの可能性が低いが、有効なトレーニングデータがない場合が多い。** 今回の調査対象であるデータ増強は、オーバーフィッティングを最小限に抑えるためのアプローチの一つです。以下では、深層学習モデルのオーバーフィットを防ぐための他の手法について説明します。本調査の結果は、データ増強を用いて画像データのクラスのオーバーサンプリングをどのように行うことができるかを示すものである。本調査の主な貢献は、(1)一般的なデータ補強の重要性を強調すること、(2)研究者がより強固で正確な深層学習モデルを設計するのに役立つ画像のデータ補強の最先端の方法と技術を示すこと、(3)画像補強をうまく利用している最先端の研究をリストアップすることである。

本調査は以下のように構成されています。セクション2では、古典的な画像データ増強技術に関する調査を紹介しています。セクション3では、DLモデルに基づいた画像データ拡張技術を紹介します。セクション4では、深層学習における画像データ拡張技術の使用に関する技術の現状を示し、セクション5では本論文をまとめる。

# 2. Classical image data augmentation.

古典的な画像データ拡張は、他の科学的研究では「基本データ拡張」とも呼ばれています。古典的な画像データ拡張は、幾何学的変換とフォトメトリック・シフティングで構成されています。これには、原始的なデータ操作技術が含まれる。幾何学的変換には、反転、回転、剪断、切り取り、平行移動などがあり、フォトメトリックシフトには、色空間の移動、異なる画像フィルタの適用、ノイズの付加などの原始的な色変換技術が含まれる。図2は、古典的な画像データ拡張の分類法を表しています。

![fig2](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig2.webp)

図2 古典的な画像データ拡張分類法．

## 2.1. Flipping

反転（Vyas et al.2018）は、画像をその垂直軸または水平軸、あるいは垂直軸と水平軸の両方の周りに反映させます。これは、**ユーザーが人工的な処理を必要とせずに、データセット内の画像の数を最大化するのに役立ちます。**図3では、さまざまな反転技術を紹介しています。

![fig3](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig3.webp)

図3 反転技術 a原画像、 b縦反転、 c水平反転、及び d垂直方向と水平方向の反転。

*垂直反転* y軸が上，x軸が下になるように画像を上下反転させる．$f_x$値と$f_y$値は、式(1)で示されるように、垂直軸に沿って反転した後の各ピクセルの現在の座標を示します。

$$$$

*水平反転* 画像を左右に水平に回転させる必要があります。$f_x$成分と$f_y$成分は、式(2)に示すように、水平方向のy軸に沿って反射した後のピクセルの現在の位置です。

$$$$

*垂直・水平方向の反転* 画像を水平・垂直方向に回転させ、水平方向と垂直方向の両方の列を保持する。$f_y$座標と$f_x$座標は、式(3)で示されるように、縦軸と横軸に沿って反射した後の各ピクセルの現在の座標です。

$$$$

## 2.2. Rotation

![fig4](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig4.webp)

図4 回転した画像のサンプル

回転(Sifre and Mallat 2013)は、古典的な幾何学的画像データ増強のもう一つのタイプであり、回転プロセスは、右方向または左方向の軸の周りに、1から359までの角度で画像を回転させることによって行われます。回転は、ある角度度の画像に加算的に適用することができる。例えば、画像を約30度の角度で回転させる。30,60,90,120,150,180,210,240,270,300,330の角度で回転させると11枚の画像ができます。回転式は式(4)のようになります。$f_x$と$f_y$は回転処理後の各画素の新しい位置で、$x$と$y$の座標の組が生の画像である。図4は、回転角度($\varphi$)を変えた場合の画像の一例である。

$$$$

## 2.3. Shearing

![fig5](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig5.webp)

図5 画像のための剪断操作 a原画像、 b X軸の方向に画像を剪断、及び c Y軸の方向に画像を剪断．

シャーリング（Vyas et al.2018）は、元の画像をx方向だけでなくy方向にも変化させることです。これは、画像内の既存のオブジェクトの形状を変更するための理想的な手法です。シャーリングには2つのタイプがあります。第1のタイプはx軸方向の成分、第2のタイプはy軸方向の成分です。式(5)はx軸方向の剪断を表し、式(6)はy軸方向の剪断を表す。(6)はY軸方向の剪断を表しています。$f_x$、$f_y$は、シャーリング後の各画素の新しい位置であり、画像座標の$x$、$y$である。図5は、シャーリングの種類の一例を示したものである。

$$$$

## 2.4. Cropping

クロッピング（Sifre and Mallat 2013）は、他の科学研究では「ズーミング」や「スケーリング」と呼ばれることもあります。クロッピングとは、元の画像を拡大するプロセスです。このタイプの古典的な幾何学的画像データの増強は、2つの異なる方法から構成されています。第1の操作は、画像を開始点のX、Yの位置から別のX、Yの位置に切り取ることである。例えば、画像サイズが200×200ピクセルの場合、（0,0）から（150,150）の位置でカットしたり、（50,50）から（200,200）の位置でカットしたりします。2つ目の操作は、画像を元のサイズにスケーリングすることです。上記の例では、カット操作の後、画像は200*200ピクセルに再スケーリングされるべきである。式(7)は、スケーリング方程式を示しています。fxとfyは、スケーリング操作後の各ピクセルの新しい座標であり、xとyは画像上の元の位置の座標を表している。図6は、切り抜きの例を示したものである。

$$$$

![fig6](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig6.webp)

図6 サンプル画像のさまざまなトリミング結果

## 2.5. Translation

並進（Vyas et al.2018）は、画像内のある位置から別の位置にオブジェクトを移動させるプロセスです。並進では、幾何学的な画像データの増強は、画像データを保存するために、並進後の画像の一部を白または黒にする、または、ランダム化されている、または、ガウスノイズが含まれていることが好ましい。並進は、X方向、Y方向、あるいはX方向とY方向を同時に操作することができる。左、右、上、下方向の画像変換は、データの位置的な偏りを避けるために非常に有効であると考えられる。式(8)は平行移動の方程式である。fxとfyは平行移動後の各ピクセルの新しい座標で、xとyは画像上の元の位置の座標を表している。図7は、さまざまな平行移動の例を示している。

![fig7](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig7.webp)

図7 並進移動の例 a原画像、 b X軸方向に平行移動、 c Y軸方向に平行移動、及び d XおよびY軸方向に平行移動

> 古典的な画像データ拡張、特に幾何学的変換を使用すると、追加のメモリ消費、追加の計算処理能力、およびより多くのトレーニング時間などのいくつかのデメリットがあります。また、従来の幾何学的な画像データ拡張（クロッピング、トランスレーションなど）は、画像から重要な特徴を取り除く可能性があるため、自動でランダムにクロッピングやトランスレーションを行うのではなく、手動で操作する必要があります。また、医用画像処理などの特定のアプリケーションでは、古典的な画像データ補強アルゴリズムが想定しているほど、トレーニングデータはテストデータと似ていません。そのため、古典的な画像データ増強法をいつ、どこで使用すれば実用的なのか、その範囲はかなり不十分です。

## 2.6. Color space shifting

色空間（Winkler 2013）シフトは、古典的な測光データ増強のファミリーに属します。色平面とは、色を使って絵を描くための数学的な道具である。人間は、明るさや色相などの色の特性によって色合いを識別します。色は、蛍光体パネルで生成される赤、緑、青の光の量を使って表現することができます（Winkler 2013）。古典的な測光データ増強において、色空間シフトは、画像数を増やすための重要な技術の1つと考えられており、特定の色空間の下で隠されていた画像の重要な特徴を明らかにすることができるかもしれない。最も有名な色空間があります（Winkler 2013）。

* CMY(K) {Cyan—Magenta -Yellow – Black}.
* YIQ, YUV, YCbCr, YCC {Luminance / Chrominance}.
* HSL {Hue—Saturation—Lightness}.
* RGB {Red—Green – Blue}.

これらの色空間間の変換は、色空間シフト方程式を使用して行われます。最も一般的な色空間はRGBであり、式(9)はRGBからCMYへの変換を示し、式(10)はRGBからHSLへの変換を示す。最後に式(11)は、RGBからYIQへの変換を示している。図8は、サンプル画像における色空間の移行の違いを示したものである。

![fig8](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig8.webp)

図8 色空間 a RGB、 b CMY、c HSL、及び d YIQ．

色空間の移動は、知的好奇心の塊のようなものです。明るい写真や暗い写真は、ピクセル値を一定値だけ上げることで見やすくなるという問題があります。また、通常のRGBカラーマトリクスを独立して処理できるのも、色空間操作の優れた機能です。また、各画素の値を最小値や最大値に制限するという方法もあります。高度なツールを必要とせず、光学写真の色を進化させることができる。

## 2.7. Image filters

ヒストグラムの均等化、明るさの増加、シャープネス、ぼかし、フィルターなどの一般的な画像処理技術は、非常に広く普及している技術です。(Galdran, et al. 2017)を参照してください。これらの技術やフィルターは、画像全体に$n\times m$の行列をスライドさせることで動作します。ヒストグラムイコライゼーション（Premaladha and Ravichandran 2016）は、コントラストを高めるために画像の強度を調整する技術であり、ホワイトバランス（Lam and Fung 2008）は、ニュートラルな光源で照らされるように画像を変化させることで動作します。特別な操作は、通常、信号の異なるスペクトル領域で別々に行われます。シャープ化（Reichenbach et al. 1990）空間フィルタは、画像の細かいディテールを強調したり、ぼやけてしまったディテールを強調するために使用され、一方、ぼかしは、統合のプロセスとして、ピクセルを隣のピクセルで平均化するプロセスである。シャープネスフィルターとブラーリングフィルター（Reichenbach et al. 1990）を使用すると、歪んだ画像になったり、水平または垂直のエッジがハイコントラストになったりして、画像の詳細を認識するのに役立ちます（Shorten and Khoshgoftaar 2019）。

上述のフィルタは、原画像とフィルタ行列の行列乗算を用いて操作されます。図9は、異なるフィルタを使用した画像フィルタ出力を示しており、それらは、ヒストグラムイコライゼーション(Premaladha and Ravichandran 2016)、ホワイトバランス(Lam and Fung 2008)、明るさの強化、シャープネス(Reichenbach et al 1990)などです。

![fig9](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig9.webp)

図9 さまざまなフィルターの適用による出力画像 、a 元の画像、 b ヒストグラム均等化、 c ホワイトバランス、 d 明るさの向上、 e シャープニング

## 2.8. Noise

画像にノイズを加えるには、規則的な分布から作られたノイズマトリクスを挿入する必要があります。画像データの拡張に使用できるノイズとしては、ガウスノイズ、ポアソンノイズ、ソルト＆ペッパーノイズ、スペックルノイズの4種類が有名です。この他にも様々なノイズが存在しますが、本研究では、上記の4種類のノイズを選択して調査しました。

まず最初に調査するノイズの形態は、加法性と呼ばれることから加法性ノイズです。ガウスノイズは、写真を構成する色の値を変化させ続けます。この式(12)に基づいて、本稿では確率密度関数を与えています(Boyat and Joshi Apr. 2015)。

$$$$

ここで、$g_c$はグレーカラーの意味、$\sigma$と$\mu$はそれぞれ標準偏差と平均値です。平均値はゼロ、スペクトルはゼロから1の間、標準偏差は0.1、256となっていることが図10からわかる。

![fig10](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig10.webp)

図10 ガウスノイズの確率密度関数

2つ目のノイズは、人間が遭遇する電磁周波数に通常存在するポアソンノイズです。このX線・ガンマ線装置は、さまざまな光子を連続的に放出していました。情熱分布は以下のグラフで示されています(13) (Boyat and Joshi Apr. 2015)。

$$$$

ここで，$e=2.718282$，$\lambda$は区間ごとのイベントの平均数，$fX =$ は，ある区間におけるイベントの数である。

3つ目のノイズは，画像中の特定のピクセルの値が変更されるソルト＆ペッパーノイズと呼ばれるものです．ノイズの多い画像では，ソルト＆ペッパーノイズを示す式（14）のように，一部の隣り合う画素が移動しません（Boyat and Joshi Apr.2015）．

$$$$

ノイズの最後の形態はスペックルノイズで、よく書かれているのは乗算・加算型のノイズです。その出現は、レーザー、レーダー、ソナーなどの光学機器に関連しています。スペックルノイズは、ガウスノイズと同じように発生することがあります。PDFは式(15)によりスペックルノイズを反映したガンマ分布の尾を持つ(Boyat and Joshi Apr. 2015)。

$$$$

観測画像において、$g(n,m)$はスペックルノイズの加法成分、$u(n,m)$は乗法関数である。図11では、原画に多数のノイズが加えられていることがわかる。ノイズは、ガウスノイズ、ポアソンノイズ、ソルト＆ペッパーノイズ、スペックルノイズの順に並んでいる。

![fig11](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig11.webp)

図11 さまざまなノイズの例 a ガウスノイズ、 b ポアソン ノイズ、 c ソルト＆ペッパーノイズ、 d スペックルノイズ．

従来のフォトメトリック画像データ増強法を使用すると、メモリ消費量の増加、計算処理能力の増加、トレーニング時間の増加など、いくつかのデメリットがあります。さらに、フォトメトリック画像データ増強は、画像の特徴を削除する可能性があるが、これらの特徴は重要であり、特にデータセット内の異なるクラスを区別するために使用される可能性のある色の特徴である場合はなおさらである。
> ここでの推奨事項は、元のデータセットの特徴を最初に調べた後に、フォトメトリック画像データ増強を慎重に使用することである。

(Khalifa et al. 2019a, 2019b, 2019c, 2018a; Khalifa et al. xxxx)のような多くの研究では、古典的な画像データ増強の混合物を一緒に使用しています。その混合物は、2つまたは3つのタイプの幾何学的変換を含むかもしれないし、1つのタイプのフォトメトリック変換とともに幾何学的変換から1つまたは2つの混合物を含むかもしれない。それらの混合物は、その効率性を証明するために、テスト精度とともにテストされます。元のデータセットの特性に依存するため、古典的な画像データ増強が最も適切なものであるという明白なルールはありません。

## 2.9. Random erasing

ランダム消去技術は、Zhong et al.(2017)で紹介された画像データ増強技術の一つです。これはジオメトリ変換の一部ではありません。ランダム消去の基本原理は、画像の四角い領域の中で、ランダムに1つの四角を消去することです。
>これは、Zhong et al. (2017)に示されているように、効果的であることが証明されました。

図12は、元の画像からランダムな四角形を削除するサンプルを示しています。

![fig12](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig12.webp)

図12 ランダム消去画像データ拡張さまざまなサンプル．

# 3. Deep learning data augmentation

深層学習(LeCun et al. 2015)は、過去10年間で顕著なブレークスルー研究を達成しました。これは、世界中の研究者が深層学習アーキテクチャを通じて継続的に貢献してきた結果です。深層学習は、コンピュータビジョン、画像分類、物体検出、画像セグメンテーションなどの分野でその効率性を証明しました。画像データオーグメンテーションのための深層学習は、この分野で再びその効率性を証明することが期待されています。深層学習による画像データ増強は、大きく3つのカテゴリで構成されており、第1カテゴリはGenerative Adversarial Networks (GAN)(Goodfellow, et al. 2014)、第2カテゴリはNeural Style Transfer (Jing et al. 2019)、第3カテゴリはmeta metric learning (Frans et al. 2018)となっています。第3カテゴリーは3つのモデルで構成されています。モデルは、Neural Augmentation、Auto Augment、Smart Augmentationである。図13は、深層学習のデータオーグメンテーションの構造を示したものである。

![fig13](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig13.webp)

図13 深層学習画像データ拡張構造

## 3.1. Generative adversarial networks

深層学習による人工知能の画像データ強化技術の一つに、生成的モデリングがあります。生成的モデリングには、初期データセットから人工的な画像を生成し、それを活用して画像の特徴を予測することが含まれます。生成的ネットワークの例として、敵対的生成ネットワーク（GAN）がある（Yi et al.2019）。GANは、2つの異なる種類のネットワークでできている。ネットワークは同時進行で教育される。ネットワークは室内のシーンを予測するように教育され、ネットワークは室内のシーンを区別するように教育される。GANは、Deep Learningモデルの具体的な形態と呼ばれる。

GANは、ラベル付きのデータセットを必要としないデータから表現を学習することがある。これは、一対のニューラルネットワークを含む競合学習メカニズムから抽出される（Yi et al.2019）。学術やビジネスの分野では、敵対的な準備は、そのシンプルさと新しい絵を生み出す有用性から、データ駆動型の操作戦略として受け入れられている。GANはかなりの進歩を遂げており、多くのアプリケーションに大きな変化をもたらしている。これらのアプリケーションには、画像合成、スタイル変換、セマンティック画像編集、画像超解像、画像分類などがあります。

## 3.2. GAN architecture

この論文で取り上げられている重要な問題は、2人のプレイヤーによるゼロサム・シナリオです。ゲームで勝った方が、もう一方のチームと同じ金額を得るというものです。このネットワークは、識別器ネットワークと生成器ネットワークと名付けられたGANのクラスにつながります。識別器は、サンプルが真のサンプルなのか合成サンプルなのかを判断するために開発されました。(Alqahtani et al. 2019)。一方、ジェネレータは、識別器を混乱させるために画像の偽サンプルを作成します。

識別器は、与えられたサンプルが本物のサンプルのコレクションに由来する可能性を生成します。本物のサンプルは，真である可能性が高い．偽のサンプルの可能性は、その低い可能性によって示唆されます。識別器のエラーレートが0.5に近い場合、識別器が真のサンプルと偽のサンプルを区別する可能性がほとんどない最適解を生成することができる(Alqahtani et al. 2019)。GANの構造を図14に示す。データとしてランダムなサンプルが集められ、これをGeneratorが使って出力を出す（Alqahtani et al.2019）。

![fig14](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig14.webp)

図14 敵対的生成ネットワークのグラフィック表現

ジェネレーターとは、写真のノイズを学習して絵を生成するニューラルネットワークのことです。ジェネレーターから発生するノイズは、G（z）を通して記録されます。ガウスノイズは、潜在的な空間にあるデバイスへの入力です。学習段階では、各ニューロンのGとDの値が反復的に変更されます。

識別器は、記憶した画像が現実の証拠を示しているかどうかを識別する機能を持つニューラルネットワークです。XはDに入力され、出力（x）となる（Goodfellow, et al.2014）。2人用のミニマックスゲームのゴール関数は、方程式形式で記述されていました。(16).

$$$$

GANの人気は、これらのモデルをどのようにデータ増強に適用できるかという新しい好奇心を生み出しました。これらのネットワークは、新しいトレーニングデータの生成を可能にし、その結果、改良された分類法をもたらします。図15は、元の画像に対するGANの出力の例を示している。

![fig15](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig15.webp)

図15 GANのトレーニング中の出力画像のサンプル

## 3.3. Neural style transfer

Neural Style Transfer (NST) (Gatys et al. 2016)は、深層学習のデータ増強における画像生成のための別の手法です。これは、ディープニューラルネットワーク、特にディープコンボリューショナルネットワークを用いて開発された人工モデルです。このモデルは、素材とスタイルのニューラル表現を用いて写真を分離・再結合し、創造的な画像を計算で構築する方法を示しています（Gatys et al.2016）。これはおそらく、芸術的な領域での応用で最もよく知られています。NSTは、超解像画像のリアルタイムスタイル転送（Johnson et al.2016）（Hayat 2018）などのアプリケーションで、芸術的な作品を作るためのベースワークとなった。ニューラル・スタイル・トランスファーの数学的基礎とされる方程式群がGatysら（2016）に掲載されています。

神経スタイル転送には、1889年のVincent Van Goghによる星降る夜、1935年のPablo Picassoによるミューズ、1913年のWassily Kandinskyによるコンポジションvii、1829-1832年の葛飾北斎による大波オフ、スケッチスタイル、シンプソンズスタイルなど、多くの芸術スタイルがあります（Johnson et al. 図16は、異なるNSTサンプル画像を提示している。

![fig16](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E7%94%BB%E5%83%8F%E3%82%AA%E3%83%BC%E3%82%AE%E3%83%A5%E3%83%A1%E3%83%B3%E3%83%86%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3/A%20comprehensive%20survey%20of%20recent%20trends%20in%20deep%20learning%20for%20digital%20images%20augmentation/%E7%94%BB%E5%83%8F/fig16.webp)

図16 ニューラルスタイル転送画像のサンプル．

どのトレンドを選ぶかは、特に専門家にとっては非常に難しいことかもしれません。自動運転車のような例では、昼から夜、夏から冬、晴れから雨の日のデータを考えるのが普通です。とはいえ、他のタイプのアプリケーションでは、転送する従来のスタイルはそれほど明確ではありません（Shorten and Khoshgoftaar 2019）。ニューラルスタイルの転送の選択は、元のデータセットの特性に再び依存する。画像データ増強の方法には、様々な画像データセットに転送するタイプの画像を慎重に収集することが含まれる。サンプルの範囲が非常に小さい場合、結果によっては、結果が歪んでしまう危険性があります。(Shorten and Khoshgoftaar 2019)。

## 3.4. Meta metric learning

メタ・メトリック学習（Zoph and Le 2019）のコンセプトは、ニューラルネットワークを最適化するためにニューラルネットワークを使用することです。この概念は、Zoph and Le (2019)のBarretzoph and et al.によって最初に適用されました。彼らは、可能な限り高い精度を達成するためにリカレントネットワークを使用するメタ学習アーキテクチャのための新しいモデルを持っています（Zoph and Le 2019）。この分野では多くの研究裁判が行われています。本作品では、3つの研究試行を選んで研究しました。その3つのモデルとは、ニューラルオーグメンテーション、オートオーグメンテーション、スマートオーグメンテーションです。これらのモデルでは、フォトメトリック変換、ジオメトリック変換、NST、GANなどの異なる技術を混合して使用した。

### 3.4.1. Neural augmentation

Neural Augmentation（NA）は、もともとWangとPerezが発表したものです（Perez and Wang 2017）。彼らは、ニューラルネットワークが完全な精度に達することができるように、最適な補強戦略でニューラルネットワークを訓練するべきだと提案している。著者は、データ増強のための2つの異なるアプローチを提案した。著者はまず、分類器をトレーニングする前に、識別を最大化するためにデータを操作した。研究者はGANと単純な変換を実装し、より広範なデータセットを構築した。2つ目の解決策は、入力に前置されたニューラルネットからの学習を必要とした。図17に示すように、学習時には、このニューラルネットは、2つのランダムな画像を取り込み、学習した指定の画像とスタイルや文脈が一致する1つの画像を生成する。畳み込みネットワークを学習するための勾配は、ネットワークの次の層に転送される。学習の際には、検証コレクションの写真が分類器の学習に使用される（Perez and Wang 2017）。彼らは顕著な精度を達成し、その結果は非常に有望であった。

![fig17]()