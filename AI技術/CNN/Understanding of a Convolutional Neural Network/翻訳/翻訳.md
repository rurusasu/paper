# Understanding of a Convolutional Neural Network

# 備考

## 著者
Saad ALBAWI, Tareq Abed MOHAMMED, Saad AL-ZAWI

# Abstract

ディープラーニングまたはディープニューラルネットワークという用語は、マルチレイヤーを持つ人工ニューラルネットワーク（ANN）を指します。 ここ数十年の間に，それは最も強力なツールの一つと考えられており，膨大な量のデータを扱うことができるため，文献では非常に人気があります． 深い隠れ層を持つことへの関心は最近、さまざまな分野で古典的な手法の性能を凌駕するようになってきました。 最も人気のあるディープニューラルネットワークの1つは、畳み込みニューラルネットワーク(CNN)です。 この名前は、畳み込みと呼ばれる行列間の数学的線形演算に由来しています。CNNには、畳み込み層、非線形層、プーリング層、完全接続層などの複数の層があります。 畳み込み層と完全接続層にはパラメータがあるが，プーリング層と非線形性層にはパラメータがない． ＣＮＮは機械学習問題において優れた性能を発揮する。  特に最大の画像分類データセット(Image Net)やコンピュータビジョン、自然言語処理(NLP)などの画像データを扱うアプリケーションでは非常に優れた性能を発揮し、その結果は驚くべきものであった。 本論文では、CNNに関連するすべての要素と重要な問題点、およびそれらの要素がどのように機能するのかを説明し、定義する。 また，CNNの効率に影響を与えるパラメータについても述べる． この論文は，読者が機械学習と人工ニューラルネットワークの両方について十分な知識を持っていることを前提としている．

# 1. Introduction

畳み込みニューラルネットワークは、画像処理から音声認識まで、パターン認識に関連するさまざまな分野で、過去10年間に画期的な成果を上げてきました。 CNNの最も有益な点は、ANNのパラメータ数を減らすことです。 この成果により、研究者や開発者は、従来のANNでは不可能であった複雑なタスクを解決するために、より大きなモデルにアプローチするようになりました。CNNによって解決される問題についての最も重要な前提は，空間的に依存する特徴を持つべきではないということである． 言い換えれば，例えば，顔検出アプリケーションでは，画像中のどこに顔があるかに注意を払う必要はない． 重要なのは，与えられた画像の中での位置に関係なく顔を検出することだけである． CNNのもう一つの重要な側面は，入力が深層に向かって伝播するときに抽象的な特徴を得ることである． 例えば，画像分類では，[図１]に示すように，[1,3,5,15]のように，最初の層でエッジを検出し，次に単純な形状を検出し，次の層で顔のような高次の特徴を検出することがある．

---
![図1](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/Understanding%20of%20a%20Convolutional%20Neural%20Network/%E7%94%BB%E5%83%8F/%E5%9B%B31.png)

図1：畳み込みニューラルネットワークから学習された特徴量

---


# 2. CONVOLUTIONAL NEURAL NETWORK ELEMENTS

CNNをよく理解するために、まずはその基本的な要素から始めます。

## A. Convolution

---
![図2]

図2
---

ニューラルネットワークの入力が[図2]のような形をしているとすると、画像（例えば、CIFAR-10データセットのカラー画像で、幅と高さが32×32ピクセル、奥行きが3のRGBチャンネル）や、ビデオ（グレースケールビデオで、高さと幅が解像度、奥行きがフレーム）であってもよいし、[2,10,15]のように、幅と高さが(L×L)のセンサ値を持ち、奥行きが異なる時間フレームに関連付けられている実験用ビデオであってもよい。

隠れ層にもう1つニューロンを追加すると、さらに32×32×3の重み接続が必要になり、合計で32×32×3×2パラメータになります。より明確にするために、入力をわずか2つのノードに接続するために6000以上の重みパラメータが使用されています。画像分類アプリケーションで有用な処理を行うには、2つのニューロンでは足りないのではないかと思われるかもしれません。 そこで、より効率的な処理を行うために、入力画像と次の層のニューロンを高さと幅を全く同じ値にして接続します。 このネットワークは、画像中のエッジのような処理に適用されると考えられます。 しかし、このネットワークでは、[4,5,14]のように32×32×3×32の重みの接続が必要となり、(3,145,728)となります。

そこで、より効率的な方法を探すためには、完全な接続ではなく、画像全体ではなく、画像内の局所的な領域を探すのが良い方法であることがわかりました。 図3は、次の層の地域的な接続を示しています。つまり、次の層の隠れニューロンは、前の層の対応する部分からのみ入力を得る。  例えば、５×５のニューロンにしか接続できない。したがって、次の層に３２×３２個のニューロンを持たせたい場合、［１，９，１３，１４，１７］のように、５×５×３×３×３２個の接続があり、これは７６，８００個の接続（完全接続の場合は３，１４５，７２８個と比較して）となる。