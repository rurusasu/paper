# Going Deeper with Convolutions

# 備考
# 著者

Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich

# 掲載

"Going Deeper with Convolutions", Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)，pp.1--9, 2015．

# Abstract
ImageNet大規模視覚認識チャレンジ2014（ILSVRC14）で分類と検出を行うための新しい最先端の技術を実現する、コードネームInceptionと呼ばれる深い畳み込みニューラルネットワークアーキテクチャを提案します。 このアーキテクチャの主な特徴は、ネットワーク内のコンピューティングリソースの利用率が向上することです。 慎重に作成された設計により、計算量を一定に保ちながら、ネットワークの深さと幅を増やしました。 品質を最適化するために、アーキテクチャの決定はヘブの原則とマルチスケール処理の直感に基づいていました。 ILSVRC14の提出で使用される1つの特定の化身は、GoogLeNetと呼ばれ、22層のディープネットワークであり、その品質は分類と検出のコンテキストで評価されます。

# 1.Introduction

過去3年間で、ディープラーニングとたたみ込みネットワークの進歩により、オブジェクトの分類と検出機能が劇的に向上しました[10]。励みになるニュースの1つは、この進歩のほとんどは、より強力なハードウェア、より大きなデータセット、およびより大きなモデルの結果だけではなく、主に新しいアイデア、アルゴリズム、および改善されたネットワークアーキテクチャの結果です。たとえば、検出のために同じ競争の分類データセットを除いて、ILSVRC 2014競争のトップエントリでは、新しいデータソースは使用されませんでした。 ILSVRC 2014へのGoogLeNetの提出は、実際には2年前のKrizhevsky et al [9]の優勝アーキテクチャよりも12倍少ないパラメーターを使用していますが、はるかに正確です。オブジェクト検出の面で、最大の利益は、ますます大きくなる深いネットワークの単純なアプリケーションからではなく、Girshick et al [6]によるR-CNNアルゴリズムのような、深いアーキテクチャと古典的なコンピュータービジョンの相乗効果から得られました。

もう一つの注目すべき要因は、モバイルコンピューティングや組込みコンピューティングの普及に伴い、我々のアルゴリズムの効率性、特に電力とメモリ使用量が重要になってきていることです。この論文で紹介するディープ・アーキテクチャの設計に至るまでの考慮事項には、精度の数値に固執するのではなく、この要素が含まれていたことは注目に値します。ほとんどの実験において、モデルは推論時に15億回の乗算加算を行うように設計されており、純粋に学術的な好奇心だけで終わらせず、大規模なデータセットであっても、合理的なコストで実世界での使用が可能である。

この論文では、コンピュータビジョンのための効率的なディープ・ニューラル・ネットワーク・アーキテクチャ(その名を「インセプション（Inception）」と呼ぶ)に焦点を当てる。まず第一に、「Inceptionモジュール」という形で新しいレベルの組織を導入するという意味と、より直接的な意味でネットワークの深みを増すという意味である。一般的に、インセプション・モデルは、Aroraら[2]の理論的な研究からインスピレーションを得て指導を受けながら、[12]の論理的な集大成と見ることができる。このアーキテクチャの利点は、ILSVRC 2014 の分類と検出の課題で実験的に検証されており、現状の技術を大幅に凌駕しています。

# 2.Related Work
LeNet-5 [10]以降、畳み込みニューラルネットワーク（CNN）は通常、標準的な構造を持っています。 この基本設計の派生形は、画像分類の文献で広く使用されており、MNIST、CIFAR、特にImageNet分類の課題でこれまでで最高の結果をもたらしています[9、21]。 Imagenetなどの大規模なデータセットの場合、最近の傾向は、ドロップアウト[7]を使用してオーバーフィッティングの問題に対処しながら、レイヤー数[12]とレイヤーサイズ[21、14]を増やすことです。

MaxPooling層では正確な空間情報が失われるという懸念があるものの、[9]と同じ畳み込みネットワークアーキテクチャは、定位[9, 14]、物体検出[6, 14, 18, 5]、人間のポーズ推定[19]にも成功している。

霊長類の視覚野の神経科学モデルに触発されて、Serreら[15]は、複数のスケールを扱うために異なるサイズの固定ガボールフィルタのシリーズを使用しています。我々はここでも同様の手法を用いている。 しかし、[15]の固定2層の深層モデルとは異なり、Inceptionアーキテクチャのフィルタはすべて学習されている。 さらに、Inception層は何度も繰り返され、GoogLeNetモデルの場合は22層のディープモデルになる。

Network-in-Networkは、ニューラルネットワークの表現力を高めるためにLinら[12]によって提案されたアプローチである。 彼らのモデルでは、ネットワークに 1 $\times$ 1 の畳み込み層が追加され、ネットワークの深さが増します。我々のアーキテクチャでは、このアプローチを多用している。しかし、我々の設定では、1 $\times$ 1畳み込みは二重の目的を持っています。最も決定的なのは、主に次元削減モジュールとして使用され、そうでなければネットワークのサイズを制限してしまう計算上のボトルネックを除去することです。 これにより、パフォーマンスを大幅に低下させることなく、深さだけでなく、ネットワークの幅も拡大することができます。

最後に、物体検出のための現在の最新技術は、GirshickらによるRegions with Convolutional Neural Networks (R-CNN)法である[6]。R-CNNは、全体的な検出問題を2つのサブ問題に分解する。すなわち、カテゴリにとらわれない方法で物体の位置提案を生成するために、色やテクスチャなどの低レベルの手がかりを利用することと、それらの位置で物体のカテゴリを識別するためにCNN分類器を使用することである。 このような2段階のアプローチは、低レベルの手がかりを用いたバウンディングボックスセグメンテーションの精度と、最先端のCNNの非常に強力な分類能力を活用しています。 我々は検出の提出物で同様のパイプラインを採用したが、より高い物体バウンディングボックスリコールのためのマルチボックス[5]予測や、バウンディングボックス提案のより良い分類のためのアンサンブルアプローチなど、両段階での強化を模索してきた。

# 3. Motivation and High Level Considerations

ディープニューラルネットワークの性能を向上させる最も簡単な方法は、そのサイズを大きくすることです。これには、深さ（ネットワークレベルの数）と幅（各レベルのユニット数）の両方を増やすことが含まれます。 これは、特にラベル付けされた大量の訓練データが利用可能であることを考えると、より高品質なモデルを訓練するための簡単で安全な方法です。しかし、このシンプルなソリューションには、2つの大きな欠点があります。