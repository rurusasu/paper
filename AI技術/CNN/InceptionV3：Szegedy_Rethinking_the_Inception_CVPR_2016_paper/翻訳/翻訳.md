# Rethinking the Inception Architecture for Computer Vision

# 備考
## 著者
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens

## 掲載
“Rethinking the Inception Architecture for Computer Vision,” Procs. of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2818–2826, 2016.

# Abstract
畳み込みネットワークは、さまざまなタスクに対応する最先端のコンピュータビジョンソリューションの中核をなしています。2014年以降、非常に深い畳み込みネットワークが主流となり、様々なベンチマークで大幅な改善が見られます。モデルサイズの増大と計算コストの増加は、ほとんどのタスクで品質の向上に直結する傾向にあるが（学習に十分なラベル付けデータが提供されている限り）、計算効率と低パラメータ数は、モバイルビジョンやビッグデータのシナリオなど、さまざまなユースケースで有効な要素であることに変わりはない。ここでは、適切に因子化された畳み込みと積極的な正則化により、追加された計算量を可能な限り効率的に利用することを目的とした方法でネットワークをスケールアップする方法を模索している。ILSVRC 2012の分類チャレンジの検証セットにおいて、我々の手法をベンチマークしたところ、1回の推論あたりの乗算コストが50億のネットワークを使用し、2,500万以下のパラメータを使用した場合、シングルフレーム評価において、トップ1エラーが21.2％、トップ5エラーが5.6％と、現状のものよりも大幅に向上したことがわかりました。4モデルのアンサンブルとマルチクロップ評価では、検証セットでは3.5%top-5エラー、17.3%top-1エラー、公式テストセットでは3.6%top-5エラーを報告した。

# Intro
Krizhevskyら[9]が2012年のImageNetコンペティション[16]で優勝して以来，彼らのネットワーク「AlexNet」は，物体検出[5]，セグメンテーション[12]，人物のポーズ推定[22]，映像分類[8]，物体追跡[23]，超解像[3]など，より多様な計算機ビジョンタスクへの応用に成功してきた．

これらの成功は、より高性能な畳み込みニューラルネットワークを見つけることを目的とした新しい研究に拍車をかけました。2014年からは、より深く、より広い範囲を利用することで、ネットワークアーキテクチャの品質が大幅に向上しました。

これらの成功は、より高性能な畳み込みニューラルネットワークを見つけることを目的とした新しい研究に拍車をかけました。2014年から、より深く、より広いネットワークを利用することで、ネットワークアーキテクチャの品質が大幅に向上しました。VGGNet [18]とGoogLeNet [20]は、2014年のILSVRC [16]の分類チャレンジで、非常に高い性能を発揮した。このことは、ディープコンボリューションアーキテクチャのアーキテクチャ改善が、高品質で学習された視覚的特徴に大きく依存する他のほとんどのコンピュータビジョンタスクのパフォーマンス改善に利用できることを意味しています。また、ネットワーク品質の向上により、AlexNet の特徴が手作業で設計されたソリューションでは太刀打ちできないような場合にも、畳み込みネットワークの新しい応用領域が生まれた[4]。

VGGNet [18]はアーキテクチャがシンプルであるという魅力的な特徴を持っていますが、その反面、ネットワークの評価には多くの計算量を必要とするという高いコストがかかります。 一方、GoogLeNet [20]のInceptionアーキテクチャもまた、メモリと計算予算に厳しい制約がある場合でも十分な性能を発揮するように設計されています。 例えば、GoogleNetは約700万個のパラメータを使用しており、前身のAlexNetが6,000万個のパラメータを使用していたのに対し、9倍の削減を実現しています。さらに，VGGNetはAlexNetの約3倍のパラメータを使用しています．

