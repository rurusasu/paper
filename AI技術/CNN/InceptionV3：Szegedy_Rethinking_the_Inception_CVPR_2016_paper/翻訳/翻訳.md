# Rethinking the Inception Architecture for Computer Vision

# 備考
## 著者
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens

## 掲載
“Rethinking the Inception Architecture for Computer Vision,” Procs. of the IEEE Conference on Computer Vision and Pattern Recognition, pp.2818–2826, 2016.

# Abstract
畳み込みネットワークは、さまざまなタスクに対応する最先端のコンピュータビジョンソリューションの中核をなしています。2014年以降、非常に深い畳み込みネットワークが主流となり、様々なベンチマークで大幅な改善が見られます。モデルサイズの増大と計算コストの増加は、ほとんどのタスクで品質の向上に直結する傾向にあるが（学習に十分なラベル付けデータが提供されている限り）、計算効率と低パラメータ数は、モバイルビジョンやビッグデータのシナリオなど、さまざまなユースケースで有効な要素であることに変わりはない。ここでは、適切に因子化された畳み込みと積極的な正則化により、追加された計算量を可能な限り効率的に利用することを目的としたネットワークのスケールアップ方法を模索している。ILSVRC 2012の分類チャレンジの検証セットにおいて、我々の手法をベンチマークしたところ、1回の推論あたりの乗算コストが50億のネットワークを使用し、2,500万以下のパラメータを使用した場合、シングルフレーム評価において、トップ1エラーが21.2％、トップ5エラーが5.6％と、現状のものよりも大幅に向上したことがわかりました。4モデルのアンサンブルとマルチクロップ評価では、検証セットでは3.5%top-5エラー、17.3%top-1エラー、公式テストセットでは3.6%top-5エラーを報告した。

# Intro
Krizhevskyら[9]が2012年のImageNetコンペティション[16]で優勝して以来，彼らのネットワーク「AlexNet」は，物体検出[5]，セグメンテーション[12]，人物のポーズ推定[22]，映像分類[8]，物体追跡[23]，超解像[3]など，より多様な計算機ビジョンタスクへの応用に成功してきた．

これらの成功は、より高性能な畳み込みニューラルネットワークを見つけることを目的とした新しい研究に拍車をかけました。2014年からは、より深く、より広い範囲を利用することで、ネットワークアーキテクチャの品質が大幅に向上しました。

これらの成功は、より高性能な畳み込みニューラルネットワークを見つけることを目的とした新しい研究に拍車をかけました。2014年から、より深く、より広いネットワークを利用することで、ネットワークアーキテクチャの品質が大幅に向上しました。VGGNet [18]とGoogLeNet [20]は、2014年のILSVRC [16]の分類チャレンジで、非常に高い性能を発揮した。このことは、ディープコンボリューションアーキテクチャのアーキテクチャ改善が、高品質で学習された視覚的特徴に大きく依存する他のほとんどのコンピュータビジョンタスクのパフォーマンス改善に利用できることを意味しています。また、ネットワーク品質の向上により、AlexNet の特徴が手作業で設計されたソリューションでは太刀打ちできないような場合にも、畳み込みネットワークの新しい応用領域が生まれた[4]。

VGGNet [18]はアーキテクチャがシンプルであるという魅力的な特徴を持っていますが、その反面、ネットワークの評価には多くの計算量を必要とするという高いコストがかかります。 一方、GoogLeNet [20]のInceptionアーキテクチャもまた、メモリと計算コストに厳しい制約がある場合でも十分な性能を発揮するように設計されています。 例えば、GoogleNetは約700万個のパラメータを使用しており、前身のAlexNetが6,000万個のパラメータを使用していたのに対し、9倍の削減を実現しています。さらに，VGGNetはAlexNetの約3倍のパラメータを使用しています．

Inceptionの計算コストは、VGGNetやその後継機に比べてはるかに低い[6]。これにより、膨大な量のデータを合理的なコストで処理する必要があるビッグデータシナリオ[17], [13]や、メモリや計算能力が本質的に制限されているシナリオ、例えばモバイルビジョンなどでInceptionネットワークを利用することが可能になりました。これらの問題の一部は、メモリ使用量に特化したソリューションを適用したり [2], [15]、または計算トリック[10]を使用して特定の演算の実行を最適化することで軽減することが可能です。しかし、これらの方法は余計に複雑さを増します。 さらに、これらの方法をInceptionアーキテクチャの最適化にも適用することで、効率性のギャップを再び広げることができる。

しかし、インセプション・アーキテクチャの複雑さは、ネットワークの変更をより困難にしている。アーキテクチャを安易にスケールアップすると、計算上の利益の大部分がすぐに失われてしまう可能性がある。また、[20]では、GoogLeNetアーキテクチャの様々な設計決定につながる要因について明確な記述がなされていない。このため、効率性を維持したまま新しいユースケースに適応させることがはるかに困難になっています。 例えば、Inceptionスタイルのモデルの容量を増やす必要があると判断された場合、すべてのフィルタバンクのサイズを2倍にするだけの単純な変換では、計算コストとパラメータ数の両方が4倍に増加します。これは、多くの実用的なシナリオにおいて、特に関連する利益がわずかである場合には、法外であったり、不合理であることが証明されるかもしれません。この論文では、まず、畳み込みネットワークを効率的にスケールアップするために有用であることが判明したいくつかの一般的な原理と最適化のアイデアを記述することから始める。我々の原則は、インセプション型ネットワークに限定されていないが、インセプション型のビルディングブロックの一般的な構造は、これらの制約を自然に組み込むのに十分な柔軟性を持っているため、その文脈では、これらの原則を観察するのが容易である。これは、インセプション・モジュールの次元削減と並列構造を惜しみなく使用することで、構造変更が近くのコンポーネントに与える影響を緩和することが可能になるからである。しかし、モデルの品質を維持するためには、いくつかの指針を守る必要があるため、慎重に行う必要があります。


# 2. General Design Principles

ここでは、畳み込みネットワークを用いた様々なアーキテクチャの選択に関する大規模な実験に基づいて、いくつかの設計原則を説明する。この時点では、以下の原則の有用性は推測的なものであり、それらの有効性の領域を評価するためには、将来の追加の実験的証拠が必要である。それでも、これらの原則からの重大な逸脱は、ネットワークの品質の低下を招く傾向があり、逸脱が検出された状況を修正することで、アーキテクチャを改善することができました。

1. 特にネットワークの初期段階では、表現のボトルネックを回避する。 フィードフォワードネットワークは、入力層から分類器やレグレッサーに至るまでの非周期グラフで表現することができます。これにより、情報の流れの方向が明確に定義されます。入力と出力を分離する任意の切り口については、その切り口を通過する情報量にアクセスすることができます。極端な圧縮によるボトルネックは避けるべきです。一般的に、表現サイズは入力から出力に向かって緩やかに減少してから、手元のタスクに使用される最終的な表現に到達する必要があります。理論的には，表現の次元性だけで情報量を評価することはできません．相関構造のような重要な要因を無視してしまうためです．

## Fully convolutional networks

我々の知る限りでは、CNNを任意のサイズの入力に拡張するというアイデアは、古典的なLeNet [21]を拡張して桁の文字列を認識するようにした Matanら[26]が最初に提案した。彼らのネットは一次元の入力文字列に限定されていたため、Matanetらは出力を得るために Viterbi 復号化を使用した。Wolf and Platt [37]は、 CNNの出力を、郵便物の住所ブロックの四隅の検出スコアの2次元マップに拡張している。これらの歴史的な研究はいずれも検出のために完全に畳み込みで推論と学習を行っている。 Ningら[27]は、完全畳み込み推論によるC.elegans組織の粗い多クラスセグメンテーションのための convnetを定義している。

完全畳み込み計算は、多層ネットの時代にも利用されている。  Sermanetら[29]によるスライディングウィンドウ検出、Pinheiro and Collobertら[28]による意味的セグメンテーション、Eigenら[4]による画像復元などが完全畳み込み推論を行っている。完全畳み込み学習は稀であるが，Tompsonら[35]は，ポーズ推定のためのエンドツーエンド部分検出器と空間モデルを学習するために効果的に使用しているが，この方法については公開していないし，分析もしていない．

また、Heら[17]は、分類ネットの非畳み込み部分を廃棄して特徴抽出器を作成しています。彼らは、提案と空間ピラミッドプーリングを組み合わせて、分類のための局所化された固定長の特徴を生成しています。このハイブリッドモデルは高速で効果的ですが、エンドツーエンドで学習することはできません。

## Dense prediction with convnets

最近の研究では、Ningら[27]、Farabetら[7]、Pinheiro and Collobertら[28]による意味的セグメンテーション、Ciresanら[2]による電子顕微鏡の境界予測、Ganin and Lempitskyら[9]による自然画像の境界予測、Eigenら[4, 5]による画像復元と深さ推定などがあります。これらのアプローチに共通する要素は以下の通りです。

# 10. Experimental Results and Comparisons

表 3. 様々な寄与因子に対する累積効果を比較したシングルクロップの実験結果。Ioffe at al [7]の発表した最良のシングルクロップ推論と比較しています。"Inception-v3-"の行では、変化は累積的なものであり、後続の各行には前のものに加えて新しい変化が含まれている。最後の行は、すべての変更を参照しているので、以下では「Inception-v3」と呼ぶことにする。残念ながら、He et al [6]は10クロップの評価結果のみを報告しており、シングルクロップの結果は報告していないので、以下の表4に報告する。

<img src=https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/InceptionV3%EF%BC%9ASzegedy_Rethinking_the_Inception_CVPR_2016_paper/%E7%94%BB%E5%83%8F/%E8%A1%A83.png>

表 4. 様々な要因に対する累積効果を比較した単一モデル、マルチクロップの実験結果。我々の数値を、ILSVRC 2012年の分類ベンチマークで発表された最良の単一モデル推論結果と比較する。

<img src=https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/InceptionV3%EF%BC%9ASzegedy_Rethinking_the_Inception_CVPR_2016_paper/%E7%94%BB%E5%83%8F/%E8%A1%A84.png>

表 5. マルチモデル、マルチクロップの報告結果を比較したアンサンブル評価結果。我々の数値は、ILSVRC 2012 の分類ベンチマークで公表されている最良のアンサンブル推論結果と比較しています。∗アンサンブル結果の上位 5 位までの結果はバリデーションセットでの結果です。アンサンブルでは、バリデーションセットで3.46%のトップ5の誤差が発生しています。

<img src=>

表3は、第6章で述べた提案アーキテクチャ(Inception-v2)の認識性能に関する実験結果である。Inception-v2の各行は、ハイライトされた新しい変更点とそれ以前の変更点を含めた累積的な変更点の結果を示している。ラベルスムージングは、セクション7で説明した方法を参照してください。因数分解7×7は、最初の7×7畳み込み層を3×3畳み込み層のシーケンスに因数分解する変更を含む。BN-auxiliaryとは、畳み込みだけでなく、補助分類器の完全連結層も一括正規化するバージョンを指す。表3の最後の行のモデルをInception-v3とし、マルチクロップとアンサンブルの設定で性能を評価します。

評価は、[16]で提案されているように、ILSVRC-2012の検証セットの48238個のブラックリストに載っていない例を対象に行っています。また、50000個の例についても同様に評価を行った結果、トップ5エラーでは約0.1％、トップ1エラーでは約0.2％の悪化が見られた。この論文の次のバージョンでは、我々のアンサンブル結果をテストセットで検証する予定であるが、春にBN-Inceptionを最後に評価した時点では[7]、テストセットと検証セットの誤差は非常によく相関する傾向があることが示されている。