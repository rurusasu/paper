# ImageNet Classification with Deep Convolutional Neural Networks

# 備考
## 著者
Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton

## 掲載
"ImageNet Classification with Deep Convolutional Neural Networks." In NIPS, 2012.

# Abstract
ImageNet LSVRC-2010コンテストの120万の高解像度画像を1000の異なるクラスに分類するために、大規模で深い畳み込みニューラルネットワークをトレーニングしました。テストデータでは、トップ1とトップ5のエラー率が37.5％と17.0％を達成しました。これは、従来の最新技術よりもかなり優れています。6,000万のパラメーターと650,000のニューロンを持つニューラルネットワークは、5つの畳み込み層で構成され、そのうちのいくつかは最大プール層、最後に1000カテゴリのソフトマックスを持つ3つの完全に接続された層が続きます。トレーニングを高速化するために、非飽和ニューロンと畳み込み演算の非常に効率的なGPU実装を使用しました。完全に接続された層の過剰適合を減らすために、非常に効果的であることが証明された「ドロップアウト」と呼ばれる最近開発された正則化方法を採用しました。また、ILSVRC-2012コンペティションでこのモデルのバリアントを入力し、2位のエントリで達成された26.2％と比較して、15.3％高いテストエラー率でトップ5に勝利しました。

# 1 Introduction
オブジェクト認識への現在のアプローチは、機械学習法を本質的に使用しています。パフォーマンスを向上させるために、より大きなデータセットを収集し、より強力なモデルを学習し、オーバーフィットを防ぐためのより良いテクニックを使用できます。最近まで、ラベル付き画像のデータセットは比較的小さく、数万枚の画像でした（たとえば、NORB [16]、Caltech-101 / 256 [8、9]、およびCIFAR-10 / 100 [12]）。単純な認識タスクは、このサイズのデータセットを使用して、特にラベル保存変換で強化されている場合、非常によく解決できます．例えば、MNIST数字認識タスクの現在の最高エラー率（<0.3％）は、人間のパフォーマンスに近づいています[4]。しかし、現実的な設定のオブジェクトにはかなりのばらつきがあるため、それらを認識することを学ぶには、はるかに大きなトレーニングセットを使用する必要があります。実際、小さな画像データセットの欠点は広く認識されていますが（たとえば、Pinto et al。[21]）、数百万の画像を含むラベル付きデータセットを収集できるようになったのはごく最近です。新しい大規模なデータセットには、数十万の完全にセグメント化された画像で構成されるLabelMe [23]、および22,000以上のカテゴリの1500万を超えるラベル付き高解像度画像で構成されるImageNet [6]が含まれます。

数百万の画像から数千のオブジェクトについて学習するには、大きな学習能力を持つモデルが必要です。ただし、オブジェクト認識タスクは非常に複雑であるため、ImageNetと同じ大きさのデータセットでもこの問題を特定することはできません。したがって、モデルには、私たちが持たないすべてのデータを補うための多くの事前知識が必要です。畳み込みニューラルネットワーク（CNN）は、そのようなモデルのクラスの1つを構成します[16、11、13、18、15、22、26]。それらの容量は、深さと幅を変えることによって制御でき、また、画像の性質（つまり、統計の定常性とピクセル依存の局所性）について強力でほとんど正しい仮定を行います。したがって、同様のサイズのレイヤーを持つ標準のフィードフォワードニューラルネットワークと比較して、CNNは接続とパラメーターがはるかに少ないため、トレーニングが容易であり、理論的に最高のパフォーマンスはわずかに劣るだけです。CNNの魅力的な品質にもかかわらず、ローカルアーキテクチャの相対的な効率にもかかわらず、高解像度の画像に大規模に適用することは依然として非常に高価でした。幸いにも、2D畳み込みの高度に最適化された実装と組み合わせた現在のGPUは、興味深い大きなCNNのトレーニングを促進するのに十分強力であり、ImageNetなどの最近のデータセットには、過度の適合なしにそのようなモデルをトレーニングするのに十分なラベル付きの例が含まれています。

このペーパーの具体的な貢献は次のとおりです。ILSVRC-2010およびILSVRC-2012コンテストで使用されるImageNetのサブセット[2]でこれまでに最大の畳み込みニューラルネットワークの1つをトレーニングし、これまでに報告された中で最高の結果を達成しました。これらのデータセット。 2D畳み込みの高度に最適化されたGPU実装と、畳み込みニューラルネットワークのトレーニングに固有のその他すべての操作を作成しました。ネットワークには、パフォーマンスを向上させ、トレーニング時間を短縮する新しい珍しい機能が多数含まれています。詳細については、セクション3で説明します。120万のラベル付きトレーニング例を使用しても、ネットワークのサイズが重要な問題を過度に適合させるため、いくつかの効果的なセクション4で説明するオーバーフィッティングを防止する手法。最終的なネットワークには、5つの畳み込み層と3つの完全に接続された層が含まれており、この深さは重要であると思われます。畳み込み層を削除すると、各層が1％以下になることがわかりました。モデルのパラメータ）のパフォーマンスが低下しました。

結局のところ、ネットワークのサイズは、主に現在のGPUで使用可能なメモリの量と、許容できるトレーニング時間の量によって制限されます。私たちのネットワークは、2つのGTX 580 3GB GPUでトレーニングするのに5〜6日かかります。すべての実験は、より高速なGPUとより大きなデータセットが利用可能になるのを待つだけで、結果を改善できることを示唆しています。

# 2. The Dataset
　ImageNetは、約22,000のカテゴリに属する1500万を超えるラベル付き高解像度画像のデータセットです。画像はウェブから収集され、AmazonのMechanical Turkクラウドソーシングツールを使用して人間のラベラーによってラベル付けされました。2010年から、Pascal Visual Object Challengeの一環として、ImageNet Large-Scale Visual Recognition Challenge（ILSVRC）と呼ばれる年次大会が開催されました。ILSVRCは、1000個のカテゴリごとに約1000個の画像を持つImageNetのサブセットを使用します。全体で、およそ120万のトレーニング画像、50,000の検証画像、および150,000のテスト画像があります。

ILSVRC-2010は、テストセットラベルが利用できるILSVRCの唯一のバージョンです。したがって、これは、ほとんどの実験を実行したバージョンです。ILSVRC-2012コンペティションでもモデルに参加したため、セクション6では、テストセットラベルが使用できないこのバージョンのデータセットに関する結果も報告します。ImageNetでは、トップ1とトップ5の2つのエラー率を報告するのが一般的です。トップ5エラー率は、正しいラベルがモデルによって最も可能性が高いと考えられる5つのラベルの中にないテスト画像の割合です。

ImageNetは可変解像度の画像で構成されていますが、システムには一定の入力次元が必要です。したがって、画像を256 x 256の固定解像度にダウンサンプリングしました。長方形の画像が与えられた場合、まず短辺の長さが256になるように画像を再スケーリングし、次に結果の画像から中央の256 x 256パッチを切り取りました。各ピクセルからトレーニングセットの平均アクティビティを減算することを除いて、他の方法で画像を前処理しませんでした。そのため、ピクセルの（中心にある）生のRGB値でネットワークをトレーニングしました。

# 3. The Architecture
　私たちのネットワークのアーキテクチャを図2に示します。これには、5つの畳み込み層と3つの完全に接続された8つの学習層が含まれています。以下では、ネットワークアーキテクチャの斬新な機能や珍しい特徴について説明します。セクション3.1〜3.4は、重要性の評価に従ってソートされています。
