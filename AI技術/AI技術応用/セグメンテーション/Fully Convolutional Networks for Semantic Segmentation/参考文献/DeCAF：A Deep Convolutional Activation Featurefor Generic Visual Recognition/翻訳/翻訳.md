# DeCAF A Deep Convolutional Activation Featurefor Generic Visual Recognition

# 備考
## 著者
Jeff Donahue, Yangqing Jia, Oriol Vinyals, Judy Hoffman, Ning Zhang, Eric Tzeng, Trevor Darrell

## 掲載
"Proceedings of the International Conference on International Conference on Machine Learning", Vol. 32, pp. 647-655, 2014.

# Abstract
我々は、大規模で固定された物体認識タスクのセットで完全に教師付きの方法で訓練された深層畳み込みネットワークの活性化から抽出された特徴が、新しい汎用タスクに再利用できるかどうかを評価している。対象とする汎用タスクは、元々訓練されていたタスクとは大きく異なる可能性があり、従来の訓練や新しいタスクにディープアーキテクチャを適応させるための十分なデータがない可能性がある。本研究では、シーン認識、領域適応、細分化認識などの様々なタスクについて、ディープ畳み込み特徴の意味的クラスタリングを調査し、可視化する。 本研究では、様々なレベルのネットワークに依存して固定的な形状を定義した場合の有効性を比較し、いくつかの重要な視覚課題において、最先端の手法を大きく上回る新しい結果を報告する。我々は、これらの深層解像度活性化特徴のオープンソース実装であるDeCAFをリリースし、関連するすべてのネットワークパラメータと共に、視覚研究者が様々な視覚概念学習パラダイムの中で深層表現の実験を行うことができるようにします。

# Intro
認知学習では、与えられたタスクに対して重要な意味を捉えた効果的な表現を発見することが重要な目標となっている。従来の視覚表現は、量子化された勾配フィルタを用いた平面的な特徴表現に基づいており、その性能は目覚ましいものでしたが、近年では停滞しているように思われます。

長い間、深層または層状の構成アーキテクチャは、顕著なクラスタ、部分、中間レベルの特徴、および/または隠れたユニットの発見を通じて、与えられたドメインの顕著な側面を捉えることができるべきであると主張されてきた(Hinton & Salakhutdinov, 2006; Fidler & Leonardis, 2007; Zhu et al., 2007; Singh et al., 2012; Krizhevsky et al., 2012)。このようなモデルは、多くの領域、特に優れた特徴がまだ設計されていない領域において、従来の手作業による表現よりも優れた性能を発揮することができる(Le et al., 2011)。  最近の結果では、部分ベースの検出モデルにおいて、中程度に深い教師なしモデルが最先端の勾配ヒストグラム特徴を上回る性能を発揮することが示されている(Ren & Ramanan, 2013)。

ディープモデルは最近大規模な視覚認識タスクに適用されており、畳み込みフィルタの層を介したバックプロパゲーションによって学習されている(LeCun et al., 1989)。これらのモデルは、大量の訓練データを持つ領域で非常に優れた性能を発揮し、デジタル分類タスクで初期の成功を収めています(LeCun et al., 1998)。  (Deng et al., 2009)のようなカテゴリレベルの大規模な訓練データ源の出現と、オンライン近似モデル平均化（「ドロップアウト」）を用いた効率的な実装（Krizhevsky et al., 2012）により、これらのモデルは最近、大規模な認識課題において既知のすべての手法を凌駕するようになった（Berg et al., 2012）。

しかし、限られた訓練データでは、(Krizhevsky et al., 2012)の表現能力を持つ完全教師付きディープアーキテクチャは、一般的に訓練データを劇的にオーバーフィットさせることができます。 実際、多くの従来型の視覚認識課題は、少ない訓練例を用いた課題を有している。例えば、ユーザが特定の例を用いて「その場で」カテゴリを定義する場合や、細かい粒度の認識課題(Welinder et al.,2010)、属性(Bourdev et al.,2011)、および/または領域適応(Saenko et al.,2010)の場合である。

この論文では、深層畳み込み表現の半教師付きマルチタスク学習を研究している。 我々のモデルは、教師付き事前学習段階に基づく転移学習のための深層学習アーキテクチャとして考えることもできるし、単に事前に定義された一連の物体認識タスクで学習された畳み込みネットワーク重みによって定義された新しい視覚特徴DeCAFとして考えることもできる。我々の研究は、関連するタスク上での分類器の学習に基づいて中間表現を形成するコンピュータビジョンにおける表現学習スキームにも関連している(Li et al., 2010; Torresani et al., 2010; Quattoni et al., 2008)。