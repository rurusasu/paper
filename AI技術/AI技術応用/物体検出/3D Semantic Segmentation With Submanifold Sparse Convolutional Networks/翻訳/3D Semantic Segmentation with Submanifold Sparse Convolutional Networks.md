# 3D Semantic Segmentation with Submanifold Sparse Convolutional Networks

# Abst
畳み込みネットワークは、画像、動画、3D形状などの時空間データを解析するためのデファクトスタンダードです。このようなデータの中には、写真のように自然に高密度になるものもありますが、他の多くのデータソースは本質的に疎です。例えば、LiDARスキャナーやRGB-Dカメラで取得された3D点群などです。標準的な「密な」畳み込みネットワークの実装は、このような疎なデータに適用すると非常に効率が悪い。本研究では，空間的に疎なデータをより効率的に処理するように設計された新しい疎な畳み込み演算を導入し，それを用いて空間的に疎な畳み込みネットワークを開発した．本研究では、3D点群の意味的なセグメンテーションを含む2つの課題において、「サブマニフォールド・スパース・コンボリューショナル・ネットワーク（SSCN）」と呼ばれるモデルの高い性能を実証した。特に、最近開催されたセマンティックセグメンテーションコンペティションのテストセットにおいて、我々のモデルはこれまでの最先端技術を上回る性能を示した。

# 1. Introduction

畳み込みネットワーク（ConvNets）は、写真、ビデオ、3Dサーフェースモデルなど、空間的および時間的構造を持つデータの分析を含む幅広いタスクに対応する最先端の手法です。このようなデータは、多くの場合、高密度に配置された（2Dまたは3D）グリッドで構成されていますが、他のデータセットは自然に疎になります。例えば、手書きの文字は2次元空間の1次元の線で構成され、RGB-Dカメラで撮影された写真は3次元の点群であり、ポリゴンメッシュモデルは3次元空間の2次元の面を形成しています。

特に、3次元以上のグリッド上にあるデータには、「次元の呪い」がかかります。このような状況では、データ処理に必要な計算資源を削減するために、可能な限りデータのスパース性を利用することがますます重要になります。例えば、RGB-Dビデオのように、4次元の構造を持つデータを解析する際には、スパース性を利用することが非常に重要です。

従来の畳み込みネットワークの実装は，密度の高いグリッド上のデータに最適化されており，疎なデータを効率的に処理することはできませんでした．最近では，疎なデータを効率的に処理できるように改良された畳み込みネットワークの実装が数多く発表されている[3, 4, 18]．これらの実装の中には，数学的には通常の畳み込みネットワークと同じですが，FLOPsやメモリなどの計算資源が少なくて済むものもあります[3, 4]．先行研究では，im2col演算のスパースバージョンを用いて，計算と記憶を「アクティブな」サイトに制限したり[4]，[22]のvotingアルゴリズムを用いて不要なゼロによる乗算を削減したり[3]しています．OctNets [18]は、関心領域の外側にあるグリッドの部分に「平均化された」隠れた状態を生成するように畳み込み演算子を修正しています。

これまでに開発されたスパース型の畳み込みネットワークでは、各層のスパースデータを "フル "の畳み込みで "ダイレーション "してしまうという欠点がありました。本研究では、ネットワーク全体で同じレベルのスパース性を維持する畳み込みネットワークを作成できることを示しています。そのため、ResNets [7]やDenseNets [9]のように、大幅に層数の多いネットワークを学習することが実用的になります。

この目的のために，我々はスパース・コンボリューション（SC）を実行するための新しい実装を開発し，サブマニフォールド・スパース・コンボリューション（SSC）と呼ばれる新しい畳み込み演算子を導入した。これらの演算子を，例えば図1に示す例のように，3D点群の効率的なセマンティック・セグメンテーションに最適化されたサブマニフォールド・スパース・コンボリューション・ネットワーク（SSCN）の基礎として使用する。

---

![fig 1](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/AI%E6%8A%80%E8%A1%93%E5%BF%9C%E7%94%A8/%E7%89%A9%E4%BD%93%E6%A4%9C%E5%87%BA/3D%20Semantic%20Segmentation%20With%20Submanifold%20Sparse%20Convolutional%20Networks/%E7%94%BB%E5%83%8F/%E5%9B%B31.png)

図1: ShapeNet part -segmentation challenge [23]で得られたオブジェクトの3D点群の例。点の色はパーツ・ラベルを表している

---

表1では、最近開催されたパート・ベース・セグメンテーション・コンペ[23]のテスト・セットにおけるSSCNの性能を示し、コンペで上位に入賞したいくつかのエントリーと比較している。SSCNは、これらのエントリーのすべてを上回っている。本ライブラリのソースコードは，オンラインで公開されている．

# 3. Spatial Sparsity for Convolutional Networks

ここでは，d次元畳み込みネットワークを，(d+1)次元のテンソルを入力とするネットワークと定義する．入力テンソルには，d個の時空間次元（長さ，幅，高さ，時間など）と，さらに1個の特徴空間次元（RGBカラーチャンネルや表面法線ベクトルなど）が含まれる．入力は，サイトのd次元グリッドに対応し，各サイトは特徴ベクトルに関連付けられている．入力されたサイトは，特徴ベクトルのいずれかの要素が基底状態でない場合，すなわち非ゼロである場合にアクティブであると定義する．データが自然にスパースにならない場合は、特徴ベクトルが基底状態からわずかな距離しか離れていない入力サイトを排除するために、閾値を使用することができる。入力テンソルは(d+1)次元であるが、活動はd次元の現象であり、特徴次元に沿った線全体がアクティブまたは非アクティブであることに留意されたい。

同様に，d次元の畳み込みネットワークの隠れ層は，特徴空間ベクトルのd次元グリッドで表される．入力データをネットワークに伝達する際、入力となる層のサイトのいずれかがアクティブであれば、隠れた層のサイトはアクティブになる。(サイズ3の畳み込みを使用する場合、各サイトは下の隠れ層の3dサイトに接続されていることに注意してください)。隠れ層の活動は、各層が次の層の活動状態のセットを決定するという帰納的な定義に従っている。各隠れ層では、非アクティブなサイトはすべて同じ特徴ベクトルを持っています。基底状態の値は，トレーニング時にはフォワードパスごとに1回，テスト時にはすべてのフォワードパスについて1回だけ計算すればよい。これにより、計算量とメモリ使用量を大幅に削減することができます。

特に、入力データのスパース性に対応するために畳み込み演算が修正されていないため、上述のフレームワークは過度に制限されていると主張している。入力データに1つの活性サイトが含まれている場合、3dの畳み込みを適用すると、3dの活性サイトが存在することになります。同じ大きさのコンボリューションを2回目に適用すると 5dの活性サイトが得られる、というように。VGGネットワーク、ResNets、DenseNets[8, 9, 20]など、数十から数百の畳み込み層からなる最新の畳み込みネットワーク・アーキテクチャを実装する場合、このようなアクティブ・サイトの数の急激な増加は見通しが悪い。

もちろん、単一の活性部位しかない入力に畳み込みネットワークが適用されることはあまりないが、入力データが2次元以上の空間における1次元の曲線や、3次元以上の空間における2次元の曲面で構成されている場合も、前述のダイレーション問題は同様に問題となる。この問題を「サブマニホールド拡張問題」と呼んでいる。図2に示すように、この格子に3×3の小さな畳み込みをかけても、格子のスパース性が急速に失われてしまう。

---

!

図2：「サブマニホールド」ダイレーションの例。左：元の曲線。真ん中。重み1/9の通常の3×3畳み込みを行った結果。右図 同じ畳み込みを再度行った結果。通常の畳み込みでは、畳み込み層ごとに特徴のスパース性が大幅に減少する。

---

# 4. Submanifold Convolutional Networks

