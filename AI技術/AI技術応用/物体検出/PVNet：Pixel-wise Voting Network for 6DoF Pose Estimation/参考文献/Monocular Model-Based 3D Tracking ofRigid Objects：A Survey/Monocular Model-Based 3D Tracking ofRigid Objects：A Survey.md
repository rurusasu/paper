# Monocular Model-Based 3D Tracking ofRigid Objects：A Survey

# 備考

## 著者

Vincent Lepetit, Pascal Fua

## 掲載

"Monocular Model-Based 3D Tracking ofRigid Objects：A Survey," Foundations and Trends in Computer Graphics and Vision, Vol. 1, No. 1, pp. 1–89, 2005.

# Abstract

多くのアプリケーションでは、複雑な3Dオブジェクトのトラッキングが必要です。 このようなアプリケーションには、特定の対象物にロボットアームを視覚的にサーボしたり、拡張対象物のリアルタイム登録を必要とする拡張現実システムや、洗練されたインターフェイスが使用できるヘッドトラッキングシステムなどがあります。コンピュータビジョンは、安価で実用的、かつ非侵襲的なソリューションを提供します。

この調査では、産業界や研究によって開発されてきたさまざまな手法やアプローチをレビューします。まず、重要な数学的ツール (カメラ表現、ロバスト推定、不確実性推定) について紹介する。次に、拡張現実とロボティクスのコミュニティによって開発された数多くのアプローチについて包括的な研究が行われています。それは、点や平面のフィデューシャルマークに基づくものから始まり、エッジやテクスチャ、関心などの自然な特徴に依存することで環境を設計する必要性を回避するものへと移行していきます。また、手動による初期化や高速運動による失敗を回避する最近の進歩についても紹介しています。最後に、3Dトラッキングシステムを実装する際になされるべき様々な可能性のある選択と、ビジョンベースの3Dトラッキングの将来についての議論で締めくくられています。

本書は、低レベルビジョンから3Dジオメトリまで、多くのコンピュータビジョン技術を網羅しており、このテーマに関する膨大な文献の包括的な研究を含んでいるため、3Dトラッキングシステムを実装しようとする学生、研究者、エンジニアのためのハンドブックとなるはずです。

# Introduction

ビデオシーケンス中の物体を追跡することは、物体やカメラが動いているときに、その位置を連続的に特定することを意味します。対象物の種類、対象物とカメラの自由度、対象アプリケーションによって様々なアプローチがあります。

2Dトラッキングは、一般的にオブジェクトの画像投影を追いかけることを目的としており、その3D変位の結果、2D変換としてモデル化することができます。その後、遠近法効果や変形による外観の変化を処理するために、適応モデルが必要とされます。適応モデルは、そのセントロイドとスケール、またはアフィン変換[141, 26, 62]の観点から、オブジェクトの画像位置を提供することができます。また、スプライン[16]、変形可能なテンプレート[142]、2D変形可能なメッシュ[112]、または2D多関節モデル[20]のような、より洗練されたモデルを使用することができる。しかし、これらの方法のいずれも、空間内の実際の位置を回復することを伴わない。

対照的に、3Dトラッキングは、シーンに対するカメラの位置と向きを定義する6つの自由度すべてを連続的に回復することを目的としています。

## Focus and Organization of the Survey

3Dトラッキングの文献は、ターゲットアプリケーションとほぼ同じくらい多くのアプローチがあり、同じ問題を解決するために多くの異なるアプローチが可能であるため、特に大規模なものとなっています。ここでは、単一のカメラを使用したオンラインモデルベースの3Dトラッキングに焦点を当てます。カメラ、シーン、オブジェクトの3Dトラッキングのためのマーカーベースの技術とマーカーレス自然特徴ベースのアプローチの両方を説明します。

特に、カメラの軌跡回復のためのバッチ法については調査を行わない。なぜなら、これらの手法は画像シーケンスを全体として考えることができるため、オンラインカメラ追跡には適していない非因果戦略に頼ることができる。さらに、このトピックに関する優れた参考文献が既に存在する[54]。マルチカメラシステムはステレオリグのキャリブレーションを必要とするため、あまり一般的ではないので、我々はシングルカメラアプローチに限定することにします。変形可能な [25, 89] や人体 [43, 121] のような多関節の物体とは対照的に、我々は剛体の物体やシーンのみを考慮します。

最初に3Dトラッキングに必要な数学的ツールを紹介します。次に、トラッキング作業を容易にするために点フィデューシャルや平面マーカーを使用するマーカーベースの技術を紹介します。次に、自然な特徴に依存する技術に焦点を当てます。最後に、フレーム間のトラッキングをフレームごとに個別に検出することで置き換えることで、ターゲットオブジェクトの消失や再出現に対するトラッキングのロバスト性を向上させようとする最近の進歩について議論します。

## Different Approaches for Different Applications

3Dトラッキングは様々な分野で非常に便利なツールです。

### Visual Servoing

ビジュアルサーボは、1台以上のカメラとコンピュータビジョンシステムを使用して、ロボットアームのようなデバイスの位置を検出し、追跡し、サーボし、把持することを必要とする、操作しなければならない部分に対する相対的な位置を制御することを含んでいます。したがって、コンピュータビジョン、ロボット工学、運動学、力学、制御、リアルタイムシステムにまたがり、車のための車線追跡、移動プラットフォームのためのナビゲーション、および一般的なオブジェクト操作のようなアプリケーションの幅広い分野で使用されています。

トラッキング情報は、ロボットの現在位置とアイインハンドカメラからの基準位置または希望の位置との間の誤差を測定するために必要です。その結果、トラッキングアルゴリズムは、ロバストで、正確で、高速で、一般的なものでなければならない。

## Computer Vision-Based 3D Tracking

3Dトラッキングを実現するために、ビジョン以外の多くの技術が試みられてきましたが、いずれも弱点があります。機械的なトラッカーは、限られた作業量にユーザーを縛り付けているものの、十分な精度を持っています。磁気式トラッカーは、よくある環境中の金属による歪みに弱く、変位の範囲も限られています。超音波トラッカーはノイズに苦しみ、周囲温度の変動のために長い範囲で正確である傾向があります。慣性トラッカーは時間とともにドリフトします。

対照的に、ビジョンは、十分にロバストなアルゴリズムを開発するために必要な努力を惜しまなければ、この問題を非侵襲的、正確かつ低コストで解決できる可能性を秘めています。場合によっては、セクション３で説明するように、登録作業を容易にするために、LED や特殊なマーカーのようなフィデューシャルをシーンや対象物に追加しても構わない。もちろん、これは1つ以上のフィデューシャルが常に表示されていることを前提としています。そうでなければ、登録はバラバラになってしまう。さらに言えば、基準を配置できるとは限らない。 例えば、拡張現実（Augmented Reality）のエンドユーザーは、シーン内に表示されていて、アプリケーションが実行される前に環境を修正できるとは限らないため、基準を好まない。

したがって、エッジ、コーナー、テクスチャなど、自然に存在する特徴に頼る方がはるかに望ましいです。もちろん、これはトラッキングをはるかに困難にします。多くの典型的なオブジェクトにそれらの数が少なすぎるため、特徴点やエッジを見つけて追いかけることは困難です。カメラの動きが速すぎて画像がぼやけてしまったり、ショット中の照明が大きく変化してしまったり、反射や鏡面性がトラッカーを混乱させてしまうことがあります。さらに重要なことは、物体が変位することで、そのアスペクトが急激に変化してしまうことです。例えば、カメラが建物を撮影して角を曲がると、壁が消えて新しい壁が現れることがあります。このような場合、追跡すべき特徴は常に変化し、トラッカーは画像の中に入ってきたり出てきたりする特徴に対処しなければなりません。セクション4と5では、このような問題を解決することに焦点を当てています。

# Mathematical Tools

このセクションでは、3Dトラッキングの目的で一般的に使用されている数学ツールを紹介します。これらは多くの論文で似たような用語で説明されていますが、ここではそれらをすべて紹介することがより効果的だと考えました。まず、カメラの表現とポーズのパラメータ化から始めます。特に、カメラの向きは3D空間内での回転として定式化することができ、その多くの可能な表現について議論します。次に、画像データからポーズを推定するために必要な数値最適化技術に目を向け、データがノイズの多い場合にロバスト性を高める方法について議論します。最後に、運動モデルを強制するフィルタリングツールを紹介し、複数の手掛かりを組み合わせてポーズの空間上の確率分布を推定することを可能にする。

ここでは、現在トラッキング目的で使用されているほとんどのカメラに適している標準的なピンホールカメラのモデルに焦点を当て、それからの潜在的な偏差も含めて説明します。 しかし、双曲面ミラーや放物線ミラーを使用して非常に広い視野を実現する、いわゆる全方位カメラのような新しいカメラの設計が、ますます普及していることに注意してください。このようなカメラを完全に扱うことは本調査の範囲を超えている。 しかし、以下に示す [46, 126] に非常に似た数学的処理が可能な領域である。

### The Perspective Project Model

フォトグラメトリストは、コンピュータビジョン研究者よりもずっと前から、画像からカメラのポーズや、より一般的なカメラパラメータを推定することを広く研究してきました。この調査では、このような推定技術を、推定そのものよりも、3Dトラッキングのための画像特徴の自動抽出と組み合わせることに焦点を当てています。したがって、ここでは、この統合を実行するために必要なことだけを提供します。カメラモデルの詳細とカメラキャリブレーションの数値的・幾何学的特性の詳細な研究については、写真測量のテキスト[48, 88]を参照してください。

画像形成は、数学的には、図 2.1 に示すように、3 次元空間から画像平面への投影として定義することができる。ユークリッド世界座標系で押し出された 3 次元点 $M=[X, Y, Z]$の座標と画像上の対応する 2 次元点 $T=[u, v]^T$ は次式で表される。

$$
s\bar{\bf{m}} = \bf{P}\bar{\bf{M}}
$$

ここで $s$ はスケールファクタ、$\bar{\bf{m}} = [u,v,1]^T$ および $\bar{\bf{M}} = [X,Y,Z,1]^T$ は点 $\bf{m}$ および $\bf{M}$ の同質座標、$\bf{P}$ は $3 × 4$ の射影行列である。$\bf{P}$ はスケールファクタまで定義されており、11個のパラメータに依存する。これは、比較的単純でありながら、合理的に優れた品質のカメラの動作を現実的に記述するため、通常、透視投影行列であると考えられています。このような透視投影行列は次のように分解することができます。

$$
\bf{P} = \bf{K}\left[\bf{R}|\bf{t} \right]
$$

ここで、

* $\bf{Ｋ}$ は、焦点距離などのカメラの内部パラメータに依存する $３×３$ カメラキャリブレーションマトリクスである。
* $\left[\bf{R}|\bf{t} \right]$ は $3 × 4$ の外部パラメータ行列であり、ワールド座標系からカメラ座標系へのユークリッド変換に相関します。以下、両者について詳しく説明する。

### The Cammera Calibration Matrix

$\bf{K}$ カメラキャリブレーション行列には，内部パラメータとも呼ばれるカメラ固有のパラメータが含まれています．ここでは，次のように書きます．

$$
\bf{K} = \left[
    \begin{array}{ccc}
        \alpha_u & s & u_0 \\
        0 & \alpha_v & v_0 \\
        0 & 0 & 1
    \end{array}
    \right]
$$

ここで、

$α_u$、$α_v$ はそれぞれ $u$ 座標方向、$v$ 座標方向のスケールファクタであり、カメラの焦点距離に比例する。$α_u = k_u f$、$α_v = k_v f$ であり、ここで $k_u$ と $k_v$ はそれぞれ $u$ 方向と $v$ 方向の単位距離あたりの画素数である。

* $\bf{c}=[u0,v0]^T$ は、光軸と像面の交点の画像座標を表し、主点とも呼ばれる。
* $s$ はスキューと呼ばれ、$u$ と $v$ の方向が直角でない場合に限り、ゼロではありません。

主点 $\bf{c}$ を画像の中心とすると、非常に合理的な近似値が得られることが多い。同様に、ピクセルが正方形であると仮定した場合、$α_u$ と $α_v$ は等しいとみなすことができます。これからは、カメラの内部パラメータがわかっていれば、カメラは校正されていると言われます。

### The External Parameters Matrix

3×4の外部パラメータ $\left[\bf{R}|\bf{t} \right]$ 行列は、カメラの向きと位置を定義します。これは回転行列 $\bf{R}$と並進ベクトル $\bf{t}$ で構成されており、カメラポーズと呼ぶことが多いです。トラッキングアプリケーションでは、通常、キャリブレーション行列 $\bf{K}$ が既知であることを前提とし、Rとt、または同等に、カメラに対する対象物の位置と向きを推定することに焦点を当てます。

より正式には、ワールド座標系からカメラ座標系へのユークリッド変換に対応します。ワールド座標系でベクトル $\bf{M}_w$ で表される 3 次元点は、カメラ座標系ではベクトル $\bf{M}_c = \bf{RM}_w + \bf{t}$ で表される。この関係から、ワールド座標系におけるカメラ中心、すなわち光学中心 $\bf{C}$ の式を容易に復元することができる。これは $\bf{0} = \bf{RC} + \bf{t}$ を満足しなければならず、これは $\bf{C} = -\bf{R}^{-1} \bf{t} = -\bf{R}^T \bf{t}$ を意味する。

### Estimating the Camera Calibration Matrix