# Viewpoints and Keypoints

# Abst

本研究では，剛体の姿勢推定の問題を，粗い姿勢を説明するための視点の決定と，より詳細な姿勢を捉えるためのキーポイントの予測という観点から特徴づけている．この2つの課題を、既知のバウンディングボックスを用いた制約条件付きの設定と、物体の検出と正しい姿勢の推定を同時に行うことを目的とした、より困難な検出条件付きの設定の2つの異なる設定で取り上げます。 これらの課題に対して、畳み込みニューラルネットワークベースのアーキテクチャを提示し、視点推定を活用することで、ローカルアピアランスに基づくキーポイント予測を大幅に改善できることを実証しました。  また、上記の課題において最先端の技術を大幅に上回る成果を得ただけでなく、エラーモードや物体の特性が性能に与える影響を分析し、この目標に向けた今後の取り組みの指針とします。

# 1. Introduction

図1の車のポーズを記述するには、その視点から記述する方法と、固定されたキーポイントの位置を指定して記述する方法がある。 前者は対象物の全体的な視点を提供し、後者はより局所的な視点を提供するものである。  本研究では、これら2つの表現方法を用いて、物体の姿勢を確実に予測することを目的としています。

我々の全体的なアプローチは、人間は細かいレベルの 局所的な細部よりも全体的な構造を知覚するという大域的 な優先順位の理論に基づいている[27]。また、Koenderink and van Doorn [22]は、視点が見た目を決定することを指摘しており、大きな全体が部分の識別性能を向上させることを示すいくつかの研究がある[31, 26, 29]。このような考え方に基づき、本研究では、まず対象物の視点を推定し、予測された視点を利用して、局所的な外観 に基づくキーポイント予測を改善するアルゴリズムを提案する。

視点は、2D画像において、対象物のさまざまな特徴の間の空間的な関係によって示されます。畳み込みニューラルネットワーク（CNN）[9, 24]を用いた手法は，このような関係を暗黙的に捉え，階層的に構築することができるため，視点予測に適している．

コップの存在を知っていても、その取っ手を見つけられないロボットは、コップをつかむことができません。物体をより深く理解するために、私たちは複数のスケールで外観をモデル化することで、キーポイントを予測するという課題に取り組んでいます。ただ、局所的な外観を推論するだけでは、キーポイントの予測という課題を解決するには不十分であることに注意してください。例えば、「前輪」という概念は、自転車全体の文脈の中でその意味を想定しています。パッチの局所的な外観は「後輪」にも対応しているかもしれませんが、自転車が正面を向いていることがわかっているからこそ、区別することができるのです。 そこで、このシステムで予測された視点を利用して、局所的な外見に基づくキーポイント予測を改善しています。

我々の提案するアルゴリズムは、図2に示すように、次のような構成になっています。

**視点予測** : 視点予測の問題を、インスタンスに対応する3つのオイラー角（方位角、仰角、サイクロローテーション）を予測することとして定式化します。 この問題を解決するために、オイラー角を予測するための局所的な証拠を暗黙的に収集し、集約することができるCNNベースのアーキテクチャを学習し、視点推定値を得る。

**局所的な外観に基づくキーポイント・アクティベーション** : 局所的なパーツの外観をモデル化するために、完全な畳み込み型CNNベースのアーキテクチャを提案します。複数のスケールで外観を捉え、スケール間でCNNの応答を組み合わせることで、各キーポイントの空間的な対数尤度分布に対応するヒートマップを得ます。

**視点条件付きキーポイント尤度** : 視点予測が与えられたときのキーポイントの確率分布をモデル化するために、ガウスのノンパラメトリック混合物として実装された視点条件付きキーポイント尤度を提案する。視点条件付きキーポイント尤度は、ノンパラメトリックな混合ガウスとして実装されており、上述の外観ベースの尤度と組み合わせることで、キーポイントの予測値を得ることができる。

キーポイント予測手法は、従来、グランドトゥルース・ボックスを入力として評価されてきました[1, 21, 25]。これは、これらの手法が、不正確にローカライズされた物体検出と組み合わせて使用される条件とは、評価の設定がかなり異なることを意味する。Yang and Ramanan [38]は，人間の姿勢推定におけるこのタスクの重要性を主張し，我々が一般的な物体カテゴリに適応させる評価基準を導入した．我々の知る限り、特定のオブジェクト・カテゴリに限定されないキーポイント予測アルゴリズムの適用性を、この困難な設定において経験的に評価したのは我々が初めてである。

さらに，Hoeimetら[18]が発表した検出方法の分析にヒントを得て，我々のアルゴリズムの故障モードや，物体の特性がアルゴリズムの性能に与える影響についても分析しています．

# 3. Viewpoint Estimation
## 3.1. Formulation

我々は、剛体カテゴリのグローバル・ポーズ推定を、正準ポーズに対する視点の予測として定式化した。 これは、方位角($\phi$)、仰角($\varphi$)、サイクロローテーション($\psi$) に対応する3つのオイラー角を求めることと等価である。ここでは、オイラー角を予測するという課題を、クラス ${1, \dots N_\theta}$ が $N_\theta$ 個の分離した角度ビンに対応する分類問題として設定します。ここで、オイラー角、ひいてはすべての視点は、回転行列によって等価に記述できることに留意する。 ここでは、視点、オイラー角、回転行列という概念を互換的に使用します。

## 3.2.  Network Architecture and Training

オブジェクトクラスの数を $N_c$、インスタンスごとに予測される角度を $N_a$ とします。 クラスごとの出力ユニット数は $N_a \ast N_\theta$ で、合計 $N_c \ast N_a \ast N_\theta$ の出力が得られます。我々は、Girshickら[11]と同様のアプローチを採用し、Imagenet[5]の分類タスクで事前学習したモデルから重みを初期化したCNNモデルを微調整しました。 我々はKrizhevskyら[23]のアーキテクチャ（TNetと表記）とSimonyanら[33]のアーキテクチャ（ONetと表記）で実験しました。我々のネットワークのアーキテクチャは、対応する事前学習済みのネットワークに、$N_c \ast N_a \ast N_\theta$ 出力ユニットを持つ完全連結層を追加したものと同じです。補足資料として、ネットワーク・アーキテクチャの詳細な可視化図を掲載しています。

クラスごとに個別のCNNを学習する代わりに、学習インスタンスのクラスに対応する $N_a∗N_\theta$ 出力を選択的に考慮する損失層を実装し、角度予測のそれぞれに対してロジスティック損失を計算します。これにより、すべてのクラスの視点を共同で予測できるCNNを学習することができ、すべてのカテゴリーで共通の特徴表現を学習することが可能になりました。Caffeフレームワーク[20]を使用して、上述のCNNを学習し、特徴を抽出します。学習データには，$IoU>0.7$ で表記されたバウンディングボックスと重なるジッター付きのグランドトゥルースバウンディングボックスを追加した． Xiangら[37]は、PASCAL VOC 2012の検出トレーニング、検証セット、およびImageNet画像のすべてのインスタンスに対応する $(\phi, \varphi, \psi)$ のアノテーションを提供しています。  我々は、PASCALの学習セットとImageNetのアノテーションを使用して上述のネットワークを学習し、PASCAL VOC 2012の検証セットのアノテーションを使用して性能を評価します。

# 4. Viewpoint Informed Keypoint Prediction

先に述べたように、部分は全体の文脈の中でその意味を発揮します。従って、局所的な外観に加えて、グローバルな文脈を考慮する必要があります。この観察を実用化するために、我々はキーポイント予測のための2つの要素からなるアプローチを提案する。