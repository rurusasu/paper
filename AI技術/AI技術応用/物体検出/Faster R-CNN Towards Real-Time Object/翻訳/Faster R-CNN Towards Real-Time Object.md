# Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks

# 備考
## 著者
Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun

## 掲載
"Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks," In Neural Information Processing Systems (NIPS), 2015.

# Abstract
最先端のオブジェクト検出ネットワークは、領域提案アルゴリズムに依存してオブジェクトの場所を仮定します。 SPPnet [1]やFast R-CNN [2]などの進歩により、これらの検出ネットワークの実行時間が短縮され、領域提案の計算がボトルネックになっています。この作業では、検出ネットワークとフルイメージのたたみ込み機能を共有するリージョン提案ネットワーク（RPN）を導入し、ほぼ無料のリージョン提案を可能にします。 RPNは完全にたたみ込みネットワークであり、各位置でオブジェクトの境界とオブジェクトネススコアを同時に予測します。 RPNはエンドツーエンドでトレーニングされ、高速R-CNNが検出に使用する高品質の地域提案を生成します。さらに、RPNとFast R-CNNを畳み込み機能を共有することで単一のネットワークにマージします。最近注目を集めているニューラルネットワークの用語である「注意」メカニズムを使用して、RPNコンポーネントは統合ネットワークに参照先を通知します。非常に深いVGG-16モデル[3]の場合、検出システムのフレームレートはGPUで5fps（すべてのステップを含む）であり、PASCAL VOC 2007、2012、および画像あたり300の提案のみを含むMS COCOデータセット。 ILSVRCおよびCOCO 2015のコンテストでは、Faster R-CNNおよびRPNは、いくつかのトラックで1位入賞エントリの基礎となります。コードは公開されています。

# 1. INTRODUCTION
オブジェクト検出における最近の進歩は、領域提案手法（[4]など）と領域ベースの畳み込みニューラルネットワーク（RCNN）[5]の成功によって推進されています。地域ベースのCNNは[5]で最初に開発されたように計算コストが高くなりましたが、提案間で畳み込みを共有することにより、コストが大幅に削減されました[1]、[2]。最新の具体化であるFast R-CNN [2]は、地域の提案に費やされた時間を無視すると、非常に深いネットワーク[3]を使用してほぼリアルタイムのレートを実現します。現在、提案は、最先端の検出システムにおけるテスト時の計算上のボトルネックとなっています。

領域提案手法は、通常、安価な機能と経済的な推論スキームに依存しています。最も一般的な方法の1つである選択的検索[4]は、設計された低レベル機能に基づいてスーパーピクセルを貪欲にマージします。しかし、効率的な検出ネットワーク[2]と比較すると、選択的検索は1桁遅く、CPU実装では画像あたり2秒です。 EdgeBoxes [6]は現在、プロポーザルの品質と速度の間の最良のトレードオフを画像あたり0.2秒で提供しています。それにもかかわらず、領域提案ステップは、検出ネットワークと同じくらいの実行時間を消費します。

高速領域ベースのCNNはGPUを利用しているが、研究で使用される領域提案手法はCPUに実装されているため、このようなランタイム比較は不公平になっていることに注意してください。プロポーザルの計算を加速する明白な方法は、GPUに再実装することです。これは効果的なエンジニアリングソリューションかもしれませんが、再実装は下流の検出ネットワークを無視するため、計算を共有するための重要な機会を逃します。

この論文では、アルゴリズムの変更（深い畳み込みニューラルネットワークを使用したコンピューティングの提案）により、検出ネットワークの計算が与えられれば、提案の計算がほぼ無料のエレガントで効果的なソリューションにつながることを示します。この目的を達成するために、最新のオブジェクト検出ネットワークと畳み込み層を共有する新しい領域提案ネットワーク（RPN）を紹介します[1]、[2]。テスト時に畳み込みを共有することで、提案を計算するための限界コストは小さくなります（たとえば、画像あたり10ミリ秒）。

私たちの観察は、Fast RCNNのような領域ベースの検出器で使用される畳み込み特徴マップは、領域提案の生成にも使用できることです。これらの畳み込み機能に加えて、通常のグリッドの各位置で領域の境界とオブジェクトネススコアを同時に後退させるいくつかの追加のたたみ込み層を追加して、RPNを構築します。したがって、RPNは一種の完全たたみ込みネットワーク（FCN）[7]であり、特に検出提案を生成するタスクのためにエンドツーエンドでトレーニングできます。

![Fig1](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/Faster%20R-CNN%20Towards%20Real-Time%20Object/%E7%94%BB%E5%83%8F/%E5%9B%B31.png)\
**図1：複数のスケールとサイズに対応するためのさまざまなスキーム。**<br>
（a）画像と特徴マップのピラミッドが構築され、分類器はすべてのスケールで実行されます。<br>
（b）複数の縮尺/サイズのフィルターのピラミッドが機能マップで実行されます。<br>
（c）回帰関数では、参照ボックスのピラミッドを使用します。

RPNは、さまざまなスケールとアスペクト比で領域提案を効率的に予測するように設計されています。画像のピラミッド（図1、a）またはフィルターのピラミッド（図1、b）を使用する一般的な方法[8]、[9]、[1]、[2]とは対照的に、新しい**「アンカー」ボックスを導入します**。アンカーボックスは、複数のスケールとアスペクト比での参照として機能します。私たちのスキームは、回帰参照のピラミッド（図1、c）と考えることができます。これにより、複数のスケールまたはアスペクト比の画像またはフィルターの列挙が回避されます。このモデルは、単一スケールのイメージを使用してトレーニングおよびテストを行うとうまく機能するため、実行速度が向上します。

RPNをFast R-CNN [2]オブジェクト検出ネットワークと統合するために、提案を固定したまま、領域提案タスクの微調整とオブジェクト検出の微調整を交互に行うトレーニングスキームを提案します。このスキームは迅速に収束し、両方のタスク間で共有される畳み込み機能を備えた統合ネットワークを生成します。

PASCAL VOC検出ベンチマーク[11]でこの手法を包括的に評価します。高速R-CNNを使用したRPNは、高速R-CNNを使用した選択的検索の強力なベースラインよりも優れた検出精度を実現します。一方、私たちの方法では、テスト時に選択検索のほとんどすべての計算負荷がなくなります。提案の有効な実行時間はわずか10ミリ秒です。高価な[3]の非常に深いモデルを使用した場合でも、GPUでのフレームレートは5fps（すべてのステップを含む）であり、速度と精度の両方の点で実用的なオブジェクト検出システムです。 MS COCOデータセット[12]の結果も報告し、COCOデータを使用してPASCAL VOCの改善を調査します。コードはhttps://github.com/shaoqingren/faster_rcnn（MATLAB）およびhttps://github.com/rbgirshick/py-faster-rcnn（Python）で公開されています。

この原稿の暫定版は以前に発行されました[10]。それ以来、RPNおよびFaster R-CNNのフレームワークが採用され、3Dオブジェクト検出[13]、パーツベースの検出[14]、インスタンスセグメンテーション[15]、画像キャプション[16]などの他の方法に一般化されました。当社の高速で効果的なオブジェクト検出システムは、com-1にも組み込まれています。このペーパーの会議バージョン[10]の公開以降、RPNはFast R-CNNネットワークと共同でトレーニングできるため、トレーニング時間を短縮できることもわかりました。 Pinterestなどの商用システム[17]、ユーザーエンゲージメントの改善が報告されています。

ILSVRCおよびCOCO 2015コンテストでは、Faster R-CNNおよびRPNは、ImageNet detection, ImageNet localization, COCO detection, COCO segmentation のトラックにおけるいくつかの1位エントリー[18]の基礎です。 RPNはデータから領域を提案することを完全に学習するため、より深くより表現力のある機能（[18]で採用されている101層の残差ネットなど）から容易に恩恵を受けることができます。より高速なR-CNNおよびRPNは、これらのコンペティションのいくつかの他の主要エントリーでも使用されています2。これらの結果は、私たちの方法が実際の使用のためのコスト効率の高いソリューションであるだけでなく、オブジェクト検出の精度を向上させる効果的な方法であることを示唆しています。

# 3. FASTER R-CNN

![Fig2](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/Faster%20R-CNN%20Towards%20Real-Time%20Object/%E7%94%BB%E5%83%8F/%E5%9B%B32.png)\
**図2：Faster R-CNNは、オブジェクト検出のための単一の統合ネットワークです。**<br>RPNモジュールは、この統合ネットワークの「注意」として機能します。

Faster R-CNNと呼ばれる私たちの物体検出システムは、2つのモジュールで構成されています。最初のモジュールは、領域を提案する深い完全たたみ込みネットワークで、2番目のモジュールは、提案された領域を使用するFast R-CNN検出器[2]です。システム全体は、オブジェクト検出のための単一の統合ネットワークです（図2）。 RPNモジュールは、最近注目されている「注意」メカニズムを備えたニューラルネットワークの用語[31]を使用して、Fast R-CNNモジュールに参照先を指示します。セクション3.1では、地域提案のためのネットワークの設計と特性を紹介します。セクション3.2では、機能を共有して両方のモジュールをトレーニングするためのアルゴリズムを開発します。

## 3.1. Region Proposal Networks
領域提案ネットワーク（RPN）は、（任意のサイズの）画像を入力として受け取り、それぞれがオブジェクトネススコアを持つ長方形のオブジェクト提案のセットを出力します。このセクションでは、3個のプロセスを以下で説明する完全たたみ込みネットワーク[7]によってモデル化します。私たちの最終的な目標は、高速R-CNNオブジェクト検出ネットワーク[2]と計算を共有することなので、両方のネットが共通の畳み込み層のセットを共有すると想定します。私たちの実験では、共有可能な畳み込み層が5つあるZeiler and Fergusモデル[32]（ZF）と、共有可能な畳み込み層が13個あるSimonyan and Zissermanモデル[3]（VGG-16）を調べます。

領域提案を生成するために、最後の共有畳み込み層によって出力された畳み込み特徴マップ上に小さなネットワークをスライドさせます。この小さなネットワークは、入力として、入力たたみ込みフィーチャマップの$n \times n$空間ウィンドウを受け取ります。各スライディングウィンドウは、低次元の機能にマッピングされます（ZFの場合は256-d、VGGの場合は512-d、ReLU [33]を使用）。この機能は、2つの兄弟の完全に接続されたレイヤー（ボックス回帰レイヤー（reg）とボックス分類レイヤー（cls））に供給されます。この論文では、$n = 3$を使用していますが、入力画像の有効受容野が大きい（ZFとVGGでそれぞれ171ピクセルと228ピクセル）ことに注意してください。このミニネットワークは、図3（左）の1つの位置に示されています。ミニネットワークはスライディングウィンドウ方式で動作するため、完全に接続されたレイヤーはすべての空間位置で共有されます。このアーキテクチャは、$n \times n$畳み込み層に続いて2つの兄弟畳み込み層$(1 \times 1)$（それぞれregおよびcls）が自然に実装されます。

### 3.1.1. Anchors

![Fig3](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/CNN/Faster%20R-CNN%20Towards%20Real-Time%20Object/%E7%94%BB%E5%83%8F/%E5%9B%B33.png)\
図3：<br>
左：地域提案ネットワーク（RPN）<br>
右：PASCAL VOC 2007テストでRPNプロポーザルを使用した検出例<br>
私たちの方法は、幅広いスケールとアスペクト比でオブジェクトを検出します。

各スライディングウィンドウの場所で、複数の領域の提案を同時に予測します。各場所の最大可能提案の数は$k$で示されます。したがって、regレイヤーには$k$個のボックスの座標をエンコードする$4k$出力があり、clsレイヤーには各提案のオブジェクトの確率またはオブジェクトでない確率を推定する$2k$のスコアが出力されます。 $k$個の提案は、アンカーと呼ばれる$k$個の参照ボックスに対してパラメーター化されます。アンカーは問題のスライディングウィンドウの中央にあり、スケールとアスペクト比に関連付けられています（図3、左）。デフォルトでは、3つのスケールと3つのアスペクト比を使用し、各スライド位置で$k=9$個のアンカーを生成します。サイズ$W \times H$（通常 ~2,400）のたたみ込みマップの場合、合計で$WHk$アンカーがあります。

#### Translation-Invariant Anchors
私たちのアプローチの重要な特性は、アンカーと、アンカーに関連する提案を計算する関数の両方の点で、それが変換不変であることです。画像内のオブジェクトを翻訳する場合、提案が翻訳され、同じ機能がどちらの場所でも提案を予測できるはずです。この変換不変のプロパティは、メソッド5によって保証されています。比較として、MultiBoxメソッド[27]はk平均を使用して800のアンカーを生成しますが、これらは変換に影響されません。したがって、MultiBoxは、オブジェクトが翻訳された場合に同じ提案が生成されることを保証しません。

並進不変プロパティは、モデルサイズも縮小します。 MultiBoxには$(4 + 1) \times 800$次元の完全に接続された出力層がありますが、$k=9$アンカーの場合、この方法には$(4 + 2) \times 9$次元の畳み込み出力層があります。結果として、出力レイヤーには$2.8 \times 104$パラメーター（VGG-16では$512 times (4 + 2) \times 9$）があり、$6.1 \times 10^6$パラメーター（$1536 \times (4 + 1) \times 800$（マルチボックス[27]のGoogleNet [34]）。フィーチャプロジェクションレイヤーを検討する場合、提案レイヤーのパラメーターはMultiBox6よりも桁違いに少なくなります。この方法では、PASCAL VOCのような小さなデータセットにオーバーフィットするリスクが少ないと予想されます。

#### Multi-Scale Anchors as Regression References
アンカーのデザインは、複数のスケール（およびアスペクト比）に対処するための新しいスキームを示しています。図1に示すように、マルチスケール予測には2つの一般的な方法があります。最初の方法は、たとえばDPM [8]およびCNNベースの方法[9]、[1]、[2]の画像/機能ピラミッドに基づいています。画像は複数のスケールでサイズ変更され、特徴マップ(HOG [8]または深い畳み込みフィーチャ[9]、[1]、[2]) が各スケールに対して計算されます(図1(a))。この方法は便利ですが、時間がかかります。 2番目の方法は、特徴マップで複数の縮尺(および/またはアスペクト比)のスライディングウィンドウを使用することです。たとえば、DPM [8]では、異なるアスペクト比のモデルは、異なるフィルターサイズ($5 \times 7$や$7 \times 5$など)を使用して個別にトレーニングされます。この方法を使用して複数のスケールに対処する場合、「フィルターのピラミッド」と考えることができます(図1(b))。 2番目の方法は通常、最初の方法と組み合わせて採用されます[8]。

比較として、アンカーベースの方法は、アンカーのピラミッドに基づいて構築されています。この方法では、複数のスケールとアスペクト比のアンカーボックスを参照して、境界ボックスを分類および回帰します。単一の縮尺の画像と特徴マップのみに依存し、単一のサイズのフィルター（特徴マップ上のスライドウィンドウ）を使用します。複数のスケールとサイズに対処するためのこのスキームの効果を実験で示します（表8）。

アンカーに基づくこのマルチスケール設計のため、Fast R-CNN検出器でも行われているように、シングルスケール画像で計算された畳み込み特徴を単純に使用できます[2]。マルチスケールアンカーの設計は、スケールに対処するための追加コストなしで機能を共有するための重要なコンポーネントです。

### 3.1.3. Training RPNs