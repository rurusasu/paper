# Multimodal templates for real-time detection of texture-less objects in heavily cluttered scenes

# Abst

本論文では、マルチモダリティを用いて3Dオブジェクトを検出する手法を紹介する。  この手法は一般的なものであるが、我々は、補完的なオブジェクト情報を与える画像と高密度のデプスマップの組み合わせで実証する。 この手法は、リアルタイムで動作し、激しいクラッタの中でも動作し、時間のかかるトレーニングステージを必要とせず、テクスチャのないオブジェクトを扱うことができます。この手法は、異なるモダリティを捉えるテンプレートの効率的な表現に基づいており、コモディティハードウェアを用いた多くの実験で、我々の手法が単一のモダリティに対する最先端の手法を大幅に上回ることを示しています。

# 1. Introduction

リアルタイムでの物体の学習と検出は、コンピュータビジョンの重要かつ挑戦的な課題です。この分野の開発を推進している応用分野の中でも、特にロボット工学では、自律システムが常に変化する未知の環境に適応し、新しいオブジェクトを学習・認識しなければならないため、計算効率の高いアプローチが強く求められています。

このようなタイムクリティカルなアプリケーションにとって，テンプレートマッチングは魅力的なソリューションである．なぜなら，多くのトレーニングサンプルを必要とする統計的学習技術とは対照的に，新しいオブジェクトをオンラインで簡単に学習できるからである．我々のアプローチは、最近の効率的なテンプレート・マッチング手法[12, 20]に関連しており、特に[11]では、画像とそのグラデーションのみを考慮してオブジェクトを検出している。そのため、これらの手法は、特徴点技術を使用するのに十分なテクスチャーがオブジェクトにない場合でも動作し、オブジェクトの姿勢の粗い推定を直接行うことができる。しかし，これまでのテンプレートマッチング手法[1, 14, 9, 21]と同様に，図1に示すような強い背景クラッタがある場合には，性能が著しく低下し，失敗することさえある．そこで，奥行き情報のような他のモダリティを追加することが，魅力的なソリューションとなります．

![fig1](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/AI%E6%8A%80%E8%A1%93%E5%BF%9C%E7%94%A8/%E7%89%A9%E4%BD%93%E6%A4%9C%E5%87%BA/LineMod/Multimodal%20templates%20for%20real-time%20detection%20of%20texture-less%20objects%20in%20heavily%20cluttered%20scenes/%E7%94%BB%E5%83%8F/fig1.png)

図1: 本手法は、画像とその深度マップを用いて、テクスチャーのない3次元物体を、乱雑な背景の上で様々な姿勢でリアルタイムに検出することができます。

本研究では，複数の撮影モダリティの情報を同時に利用してテンプレートを定義し，困難な環境下でも既知の物体をロバストに検出する効率的な手法を提案する．本手法では，各モダリティからのデータをビンに分割し，[11]で紹介された「線形化応答マップ」を利用することで，キャッシュミスを最小限に抑え，強力な並列化を実現している．本論文では、カラー画像と高密度のデプスマップの組み合わせに注目しています。 しかし、我々のアプローチは非常に汎用的であり、量子化可能な画像に沿った測定値を提供する限り、他のモダリティを容易に統合することができる。

画像の統合では、グレーバリュー画像で計算されたグラデーションよりも、背景に対してよりロバストなカラー画像からのグラデーションの抽出方法を示します。深度統合では，密な深度マップから3次元表面法線をリアルタイムでロバストに計算する方法を提案しています．

本稿の残りの部分では，我々のアプローチについて説明する前に，まず関連する研究について述べます．次に，難易度の高いシーンを対象とした定量的な評価を行い，我々のマルチモーダル・テンプレートが最先端のアプローチよりも優れていることを示した．

# 4. Experiments

我々は、LINE-MOD（multimodal-LINEの略）と呼ぶアプローチを、いくつかの手法と比較した。LINE-MOD（マルチモーダル・ライン）は、画像の強度のみを利用するLINE（LINE-2D）、深度マップのみを利用するLINE-3D、DOT[12]、そしてHOG[3]と比較しました。HOGでは、独自に最適化した実装を用いており、HOGの原著にあるサポートベクターマシンを最近傍探索に置き換えています。これにより，他の手法と同様に，ロバストな表現として使用し，新しいテンプレートを素早く学習することができます．実験は，Intel Centrino Processor Core2Duo（2.4GHz）と3GBのRAMを搭載した標準的なノートブックのプロセッサ1台で行いました。画像と深度データの取得には、Primesense(tm)PSDK 5.0デバイスを使用しました。

## 4.1. Robustness

本研究では、2000枚の実写画像からなる6つのシーケンスを使用しました。各シーケンスでは、乱雑な背景の上に照明と大きな視点の変化があります。また、各シーンにはキャリブレーション用のパターンが添付されており、物体の実際の位置を知ることができます。テンプレートは、均質な背景の上で学習されました。



# 5. Conclusion

本研究では、異なるモダリティを利用してリアルタイムに物体を検出する手法を提案しています。我々の新しい手法は、背景の乱れや照明の変化、ノイズがある状況下でも、3Dテクスチャのない物体を誤検出することなくリアルタイムで正しく検出することができます。我々は、画像と深度データを効率的に前処理して、両方のキューを我々のアプローチにロバストに統合する方法を示しました。さらに、私たちのアプローチは、認識率と速度の組み合わせに関して、特にクラッタの多い環境で、最先端の手法を上回ることを示しました。