# A Survey on Deep Transfer Learning

# 備考

## 著者

Chuanqi Tan, Fuchun Sun, Tao Kong,Wenchang Zhang, Chao Yang, and Chunfang Liu

## 掲載

International Conference on Artificial Neural Networks, Springer, pp. 270-279, 2018.

# Deep Transfer Learning

転移学習は、機械学習の基本的な問題である学習データの不足を解決するための重要なツールです。これは、学習データとテストデータが等値でなければならないという前提を緩和することで、学習元の領域から学習対象の領域へ知識を転移しようとするもので、学習データが不足しているために改善が困難な多くの領域に大きな効果をもたらします。図１に示す転送学習の学習過程を説明する。

<img src=https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92/A_survey_on_Deep_Transfer_Learning/%E7%94%BB%E5%83%8F/%E5%9B%B31.png>

Fig. 1. 転送学習の学習過程

本調査では、いくつかの表記法を明確に定義する必要がある。まず、ドメインとタスクをそれぞれ定義する。ドメインは $D = \{ \chi,P(X) \}$で表現され、特徴空間 $\chi$ とエッジ確率分布 $P(X)$ の2つの部分を含み、$X = \{x_1,\dots,x_n \} \in \chi$ で表される。タスクは $T = {y,f(x)}$ で表されます。$f(x)$ は条件付き確率関数 $P(y|x)$ とみなすこともできる。そうすると、転移学習は次のように正式に定義することができる。

> 定義１. (転移学習) <br>
> $D_t$ に基づいて学習タスク $T_t$ が与えられ、その学習タスク $T_s$ に対して $D_s$ からの助けを得ることができる。転送学習は、$D_s \neq D_t$ および/または $T_s \neq T_t$ の $D_s$ と $T_s$ から潜在知識を発見して転移することで、学習タスク $T_t$ に対する予測関数 $f_T(.)$ の性能を向上させることを目的としている。また、多くの場合、$D_s$ の大きさは $D_t$ の大きさよりもはるかに大きい。 $N_s \gg N_t$。

調査[19]や[25]では、転移学習の手法を大きく3つに分類しており、その中でも特にソースドメインとターゲットドメインの関係については、広く受け入れられている。これらの調査結果は，これまでの転移学習に関する研究をまとめたものであり，多くの古典的な転移学習手法が紹介されている．さらに、最近では、より新しく、より優れた方法が数多く提案されています。近年の転移学習の研究コミュニティでは，主に領域適応と多元領域転移の2つの側面に焦点が当てられています．

現在、深層学習は近年多くの研究分野で一世を風靡しています。そのためには、以下のように定義された深層学習と呼ばれる深層ニューラルネットワークを用いて、効率的に知識を転移する方法を見つけることが重要である。

> 定義2, (深層転移学習) <br>
> 伝達学習タスクが $<D_s,T_s,D_t,T_t,f_T(.)>$ で定義されているとする。 $f_T(.)$が深層ニューラルネットワークを反映した非線形関数である深層転移学習課題である。