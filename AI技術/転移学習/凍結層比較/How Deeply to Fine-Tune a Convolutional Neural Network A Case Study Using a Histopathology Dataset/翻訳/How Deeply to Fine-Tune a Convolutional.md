# How Deeply to Fine-Tune a Convolutional Neural Network: A Case Study Using a Histopathology Dataset

# 備考
## 著者
Ibrahem Kandel, Mauro Castelli

# Abstract
医用画像の正確な分類は、正しい疾患診断のために非常に重要です。経験豊富な医療スタッフが不足している場合には、セカンドオピニオンを提供したり、より良い分類を行うことができるため、医用画像の分類の自動化は非常に必要です。畳み込みニューラルネットワーク(CNN)は、画像の分類に使用する特徴量を手動で選択する必要がなく、画像分類の領域を改善するために導入されました。 ゼロからCNNを学習するには、医療分野では不足している非常に大規模な注釈付きデータセットを必要とする。CNNの重みを別の大規模な非医療用データセットから転送学習することで、医療用画像の希少性の問題を克服することができる。 転写学習は、新しいデータセットに合わせてCNN層を微調整することからなる。 転移学習を利用する際の主な問題は、ネットワークをどの程度深く微調整するか、そしてそれによって一般化にどのような違いが生じるかということである。本論文では、CNNのブロック単位での微調整の効果を系統的に研究するために、3つの最先端アーキテクチャを用いて2つの組織病理学データセットを用いてすべての実験を行った。結果は、ネットワーク全体を微調整することが必ずしも最良の選択肢とは限らないことを示している。特に浅いネットワークでは、トップブロックを微調整することで、時間と計算パワーの両方を節約し、よりロバストな分類器を生成することができる。

# Introduction
医用画像は患者さんの治療に非常に重要な役割を果たしていますが、通常、人手不足や判断に要する時間、セカンドオピニオンの必要性などが大きく影響しています。 病理学のような特定の医療画像分野では、画像を正確かつ迅速に分類することが絶対的なニーズとなっています。組織病理学の画像は、癌のような特定の種類の病気を検出するために、あるいは癌の種類やその程度を判断するために非常に重要です。組織病理学とは、生検で採取した組織サンプルを顕微鏡で検査し、特定の疾患を診断することと定義されています[1]。疾患の発見において非常に重要な役割を果たしており、医師は慎重に治療計画を立てることができます。組織病理検査画像の分類を担当する医師は病理医と呼ばれています。 画像の検査は非常に難しく、長年の経験を持つ病理医が必要とされます。米国では、過去10年間で現役の病理医の数は17.5%減少し、作業量は41%増加している[2]が、組織病理画像を高精度に分類できる自律型分類器を提供することで、病理医の作業を支援することが求められている。

最近、人工知能の分野でブレークスルーされているのが機械学習で、画像の特徴を自動的に抽出するアルゴリズムを開発することができます。使用されるアルゴリズムが複数の隠れ層を持つニューラルネットワークである場合、それは深層学習と呼ばれています。ディープラーニングは、フィードフォワード畳み込みニューラルネットワーク（CNN）[3]を用いて画像を自動的に分類する画像分類の領域に実装することができる。 CNNを画像を分類できるようにすることをトレーニングといい，トレーニングでは，研究対象の画像データセットに合わせてCNNの重みを調整する．CNNの最大のポイントは、CNNが明示的にプログラムされていなくても、画像の重要な特徴をマッピングして画像を分類することができることである。CNNは，糖尿病網膜症の検出と分類 [4,5]，アルツハイマー病の検出 [6,7]，皮膚病変の検出 [8,9]など，多くの医療分野の分類において高い精度で機能することが証明されている．

画像の分類は、画像を事前に定義されたラベルに連続してグループ化することで定義され、医療分野のような多くの分野で非常に重要な役割を果たしています。 ディープラーニングアルゴリズムは、人手を介さずに画像の重要な特徴を検出することができますが、これは、画像のクラスを区別する方法を自ら学習する自律的なアルゴリズムを使用していると考えることができます。クラス間の区別方法を学習する自動分類器を構築しようとした最初の試みは、福島ら[10]やHubel and Wiesel[11]の研究に触発されたLeCun[3]によって紹介され、畳み込みニューラルネットワーク（CNN）と名付けられたが、この試みはデータセットの大きさや当時利用可能な計算能力の問題から制限されたものであった。 2012年にはKrizhevskyら[12]がAlexNetと名付けたCNNアーキテクチャを発表し，ILSVRCコンテスト[13]で1位を獲得したが，2位の25%の誤差率に対して16%であった．CNNは，少なくとも1つの畳み込み層を持つフィードフォワード型の人工ニューラルネットワークと考えられている．CNNの図を図1に示す．

CNNを正確に訓練し、フィードフォワード・ニューラルネットワークに関連する過学習の問題を克服するためには、通常、数十万から数百万枚の画像が必要とされ[14]、CNNの利用は自然画像のような特定の領域に限定されてしまう。移転学習は、CNN訓練における前述の問題を克服するために導入された新しい領域であり、ネットワークの重みをゼロから初期化するのではなく、別の大規模なデータセットで訓練された以前のネットワークの重みを使うことができる。医療分野では画像分類にCNNを利用することで多くの恩恵を受けることができますが、最大の欠点は訓練に利用できる画像の数が少ないことであり、そこで転移学習を利用することができます。医療画像に転移学習を用いることは，文献[4,6,8]で成功している．Chollet [15]が指摘しているように、転移学習には主に2つの手法があります：元の重みを新しいデータセットに合わせて再調整するファインチューニングと、元の重みを固定し、元のレイヤーを特徴抽出にのみ使用する特徴抽出です。どちらの手法も，Yosinskiら[16]が指摘しているように，データセットの大きさに応じて大きな助けになる．データセットが十分に大きければ元のレイヤーを微調整することができ、データセットが小さければ元のレイヤーを特徴抽出に利用することができる。 また，元のデータセットと対象のデータセットの類似度も非常に重要な役割を果たすことがある． 本研究では，以下の理由から，特徴抽出ではなく微調整を行うことにした．
1. 使用するデータセットに含まれる画像数が多いこと
2. ImageNetデータセットとヒストパソロジーデータセットとの間に大きな差（画像の領域に関して）があること
などの理由から、特徴抽出ではなく微調整を行うことにました。

CNNアーキテクチャ全体の微調整には何時間もかかり、特定のハードウェアを必要とし、各ブロックの効果は非常に重要な役割を果たします。ネットワーク全体を微調整しても，必ずしも最高の性能が得られるとは限らない． 本研究の主な目的は，CNNをブロック単位で微調整することの効果を決定し，各ブロックを学習することで得られる性能を評価することである． 本研究では3つの学習率を持つ3つの最先端のCNNアーキテクチャを用いた。使用した性能指標はROC曲線のAUCである。 CNNアーキテクチャの性能を評価するために，別のラベルなしのテストセットを用いる．本論文の残りの部分は以下のように構成されている。第2節では、組織病理学における転移学習の利用に関する簡単な文献レビューを行う。第3節では、提案された方法論について議論する。第4節では、得られた結果を述べる。第5節では、所見の概要を述べている。第6章では、結論を述べている。

# 3.2. Transfer Learning

通常，元データセットは，ImageNetデータセット[32]のように，数千のクラスを持つ数百万の画像を含む．文献では，以下の4つの転移学習手法が紹介されている．
1. 最初の手法は，元のCNNの重み (ImageNetの重みのようなもの) を凍結し，元の完全に接続されたレイヤーを削除して，別の分類器を追加することです．
2. 第二の手法は、底層が非常に汎用的で、どんな種類の画像データセットにも使えるという前提のもと、非常に小さな学習率で元のCNNの上層を微調整し、下層を凍結するというものである[16]。
3. 第三の手法は、元の重みを失わないように非常に小さな学習率を使ってネットワーク全体の重みを微調整し、最後に完全に接続された層を削除し、ターゲットのデータセットに合わせて別の層を追加するというものです。
4. 第四の手法は、重みを一切インポートせずにCNN独自のアーキテクチャを使う、つまりゼロから重みを初期化するというものです。この手法のポイントは、挑戦的なデータセットで実験され、良いことが証明されているよく知られたアーキテクチャを使うことです。異なる転移学習手法を図4に示す。

この図は，異なる転移学習手法を示している．
(a)ImageNetデータセット上で学習された汎用CNN
(b) 最初の手法では，元の重みが固定され，元の分類器レイヤがターゲットデータセットに適合するように新しいレイヤに置き換えられる．
(c) 第2の手法では，最上層を微調整し，最下層の重みを固定し，最後に完全に連結された層を入れ替え，ソースの重みを固定し，元の分類器層をターゲットのデータセットに合わせて新しい層に入れ替える．
(d) 第3の手法では，元の分類器層を配置し，ネットワーク全体を微調整する．
(e)第4の手法では，重みを使わずにオリジナルアーキテクチャを使用する．
緑はImageNetデータセットから学習した重み，青はターゲットデータセットを用いてImageNetの重みを微調整したもの，白は重みをゼロから初期化することを意味する．

# 3.3. CNN Architectires

AlexNetアーキテクチャは2012年のImageNetチャレンジでエラー率16%で1位を獲得したことから，画像の分類にCNNを用いたアーキテクチャが多く導入された． 2014年にはAlexNetアーキテクチャ[12]よりもかなり深いVGG[24]アーキテクチャが導入され、同年にはAlexNetよりも深く広いとされるGoogLeNetアーキテクチャ[28]も導入された。 その後、2015年にはResNetアーキテクチャ[29]が導入され、より深く、残余接続を含んだものとなり、2016年にはDenseNet[26]が導入されました。 これらの最先端のCNNはすべてImageNetデータセットで学習され、その重みは公開されている。本研究では，VGG16，VGG19，InceptionV3アーキテクチャの3つのCNNを考慮に入れることにした．この選択は、これら3つのネットワークがこのデータセットに関連したKaggle競争で一般的に使われているものであり、さらに重要なことに、他の競争相手よりも優れた性能を発揮していたという事実に関連している。 さらに、考慮すべきアーキテクチャの選択は、微調整が手元の組織病理学データセットを分析するのに適したアプローチであるかどうかを理解することに焦点を当てた研究を展開するための基本的なものではありません。以下、本論文で使用したCNNについて簡単に説明する。

## 3.3.1. VGG Architectures

VGGアーキテクチャ[24]は、オックスフォードのVisual Geometry Groupによって2014年に導入され、ILSVRCコンペティションに参加し、7.3%というトップ5のエラー率を達成しました。 VGG16とVGG19の2つのネットワークが導入されたが、2つのネットワークの違いは使用されている畳み込み層の数だけである。VGG16は13の畳み込み層で構成されており、VGG19は16の畳み込み層で構成されているため、VGG16よりも深いと考えられる。著者らは、フィルタサイズの大きい畳み込み層を用いる代わりに、フィルタサイズの小さい2つの層を連結することで、パラメータ数を28%削減した。VGGネットワークは5つの畳み込みブロックで構成されており、最初の2つのブロックはそれぞれ3×3のフィルタサイズを持つ2つの畳み込み層で構成され、最初のブロックの畳み込み層はそれぞれ64個のフィルタを持ち、2番目のブロックの畳み込み層はそれぞれ128個のフィルタを持つ。ＶＧＧ１６の第３のブロックは３つの畳み込み層からなり、ＶＧＧ１９では４つの畳み込み層からなり、全ての層が３×３のサイズの２５６個のフィルタを有している。第４及び第５の畳み込みブロックは、ＶＧＧ１６では３つの畳み込み層からなり、ＶＧＧ１９では４つの畳み込み層からなり、全ての層がサイズ３×３の５１２個のフィルタを有している。5つのブロックは最大プーリング層で区切られている。完全に接続された2つの層は、4096個のニューロンを持つネットワークの分類器として使用されている。VGG16は23層の深さを持つ1億3800万個のパラメータを持ち、VGG19は26層の深さを持つ1億4300万個のパラメータを持つ。ＶＧＧのアーキテクチャを図５に示す。

## 3.3.2. Inception V3 Architecture

インセプションアーキテクチャ[28]は、2014年にReference[34]の著者らによって初めて導入され、ImageNetコンペティションに参加し、6.65%のトップ5エラー率で第1位を獲得した。これらは、同じオブジェクトの異なるスケールでも、正しく観測するためには異なるフィルタサイズが必要であるという仮説のもとに設計されました。インセプションモジュールは、同じ入力から始まり、それをカーネルサイズの異なる異なる畳み込みレイヤーと、1つの最大プーリングレイヤーに分割します。VGGモデルのように後続ではなく、これらのレイヤーを並列に配置することで、多くのメモリを節約し、深さを増すことなくモデルの容量を増加させることができます。図6にインセプションモジュールを示す。 本論文で使用したバージョンは3番目である。 インセプションアーキテクチャは、順次配置された9つのインセプションモジュールで構成されています。  InceptionV3アーキテクチャは、159層の深さを持つ2380万個のパラメータを持つ。1×1、3×3、5×5の3つのフィルタサイズが1つのインセプションモジュールで使用されているが、更新版では、Reference[24]の影響を受けて、5×5を2つの3×3畳み込みレイヤーに置き換えている。インセプションのアーキテクチャを図 7 に示す。


## 3.6.4. Image Augumentation

オーバーフィッティングを減らすための主な方法の1つは、可能な限りすべての画像でモデルを訓練するために膨大な訓練データセットを持つことですが、現実的にはそれは不可能であり、そこで画像拡張が導入されました。そこで、学習データセットを増やすために、画像オーグメンテーションを適用することができます。画像オーギュメンテーションとは、元の画像を変形、回転、明るさの変更などの一連の変更を行うことで、人工的な画像を作成するために使用できるアルゴリズムと定義されています。