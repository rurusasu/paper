# A survey on Transfer Learning

# 備考

## 著者
Sinno Jialin Pan, Qiang Yang

## 掲載
"IEEE Transactions on Knowledge and Data Engineering," Vol. 22, No. 10, pp. 1345-1359, 2010.

# Abstract

多くの機械学習やデータマイニングのアルゴリズムでは、学習データと将来のデータが同じ特徴空間にあり、同じ分布を持っていなければならないというのが大きな前提となっています。しかし、多くの実世界のアプリケーションでは、この仮定が成り立たない場合があります。例えば、ある興味のある分野の分類タスクがあるのに、別の興味のある分野の十分な学習データしか持っていない場合、後者のデータは異なる特徴空間にあるかもしれないし、異なるデータ分布に従うかもしれません。このような場合、知識の転移が成功すれば、費用のかかるデータのラベリング作業を回避して学習のパフォーマンスを大幅に向上させることができます。近年、この問題を解決するための新しい学習フレームワークとして、知識転移学習が登場しています。本調査では、分類、回帰、クラスタリング問題に対する転移学習の現在の進展を分類し、レビューすることに焦点を当てている。本調査では、領域適応、マルチタスク学習、サンプル選択バイアス、共変量シフトなどの他の関連する機械学習技術と転移学習との関係について議論する。また、転移学習研究における将来的な課題についても考察する。

# Introduction

データマイニングと機械学習技術は、分類、回帰、クラスタリングを含む多くの知識工学分野ですでに大きな成功を収めている（例：[1], [2]）。しかし、多くの機械学習手法は共通の仮定の下でのみうまく機能します：訓練データとテストデータは同じ特徴空間と同じ分布から引き出されます。分布が変化すると、ほとんどの統計モデルは新たに収集した訓練データを使ってゼロから再構築する必要があります。多くの実世界のアプリケーションでは、必要な訓練データを再収集してモデルを再構築するのはコストがかかるか、不可能です。**訓練データの再収集の必要性と労力を軽減できれば良いのですが、そのような場合には、知識の転移やモデルの再構築が必要になります。** このような場合には、**タスク-ドメイン間での知識転移や転移学習が望ましい。**

知識工学の分野では、転移学習が真に有益であると考えられる多くの例を見つけることができます。 その一例として、Web 文書の分類 [3], [4], [5] がありますが、ここでは、与えられた Web 文書をいくつかの定義済みのカテゴリに分類することを目的としています。 Web文書分類の分野での例として（例えば、[6]を参照）、ラベル付けされた例は、以前の手動によるラベル付けの努力によって得られたカテゴリ情報に関連付けられた大学のWebページであるかもしれません。新たに作成されたWebサイトの分類タスクでは，データの特徴やデータ分布が異なる場合，ラベル付けされた学習データが不足している可能性があります．その結果，大学のWebサイトで学習したWebページ分類器を直接新しいWebサイトに適用できない可能性があります．そのような場合には，分類知識を新しいドメインに移すことができれば便利です．

**データが古くなりやすい場合には、転移学習の必要性が生じることがある。** この場合、ある時間帯に得られたラベル付けされたデータが、後の時間帯になっても同じ分布をたどるとは限らない。 例えば、過去に収集したWiFiデータに基づいてユーザの現在地を検出することを目的とする屋内 WiFi 定位問題では、ユーザが各場所で大量の WiFi 信号データをラベル付けする必要があるため、大規模な環境で定位モデルを構築するための WiFi データの較正には非常にコストがかかる。しかし、WiFi 信号強度の値は、時間、デバイス、または他の動的要因の関数である可能性がある。ある時間帯またはあるデバイスで訓練されたモデルは、別の時間帯または別のデバイスでの位置推定のための性能を低下させる可能性がある。再校正の労力を減らすためには、[7]で行われているように、ある期間（ソース領域）で訓練された定位モデルを新しい期間（ターゲット領域）に適応させるか、またはモバイルデバイス（ソース領域）で訓練された定位モデルを新しいモバイルデバイス（ターゲット領域）に適応させることが望ましいかもしれない。

# 2. 
## 2.2. Notations and Definitions (記法と定義)

本節では、本調査で使用する表記法と定義を紹介する。まず、「ドメイン」と「タスク」の定義を示す。

本調査では、ドメイン $D$は、特徴空間 $\chi$ と限界確率分布 $P(X)$ の2つの要素から構成される。 例えば、学習課題が文書分類であり、各項を２値特徴量とすると、$\chi$ は全ての項ベクトルの空間であり、$ｘ_i$ はいくつかの文書に対応する$ｉ$番目の項ベクトルであり、$Ｘ$ は特定の学習サンプルであるとすると、$Ｘ ＝\{ x_1, \dots, x_n\} \in \chi$である。一般的に、2つの領域が異なる場合、それらは異なる特徴空間、または異なる限界確率分布を持つかもしれません。

タスクは、特定の領域 $D = \{\chi, P(X)\}$が与えられると、2つの要素から構成される：ラベル空間 $Y$ と、観測されないがペア $\{x_i, y_I\}$ で構成される学習データから学習可能な客観的予測関数 $f(.)$ ( $T = \{Y,f(.)\}$ と表記される）である。ここで、$x_i \in X$ そして $y_i \in Y$ である。
関数 $f(.)$ は、新しいインスタンス $x$ の対応するラベル $f(.)$ を予測するために使用することができます。文書分類の例では、$y$ はすべてのラベルの集合であり、二値分類タスクの場合、$y_i$ は *True* または *False* である。

本調査では、簡単のために、ソースドメイン $D_S$ とターゲットドメイン $D_T$ が1つの場合のみを考慮している。具体的には、ソースドメインデータを $D_S = \{(x_{S1}, y_{S1}),\dots,(x_{Sn_S},y_{Sn_S})\}$ とし、$x_{Si} \in \chi_S$ はデータインスタンス、$y_{Si} \in Y_S$ は対応するクラスラベルである。ここで、文書分類の例では、$D_S$ は、用語ベクトルの集合であり、それらに関連付けられた真または偽のクラスラベルを表すことができる。同様に、対象領域データを $D_T = \{(x_{T1},y_{T1}),\dots,(x_{Tn_T},y_{Tn_T})\}$ と定義し、入力 $x_{Ti}$ は $\chi_T$ であり、$y_{T_i} \in Y_T$ は対応する出力である。ほとんどの場合、$0 \leqq n_T \ll n_S$ である。

これで、転移学習の統一的な定義ができました。

転移学習とは、
> ソースドメイン $D_S$ とその学習タスク $T_S$、ターゲットドメイン $D_T$ とその学習タスク $T_T$ が与えられた場合、転移学習は、$D_S$ と$T_S$ の知識（$D_S \neq D_T$、$T_S \neq T_T$）を用いて、$D_T$におけるターゲット予測関数 $f_T(.)$ の学習を改善することを目的とする。

上記の定義では、ドメインは $D={\chi,P(X)}$ の組である。したがって、$D_S \neq D_T$という条件は、$\chi_S \neq \chi_T$ または $P_S(X) \neq P_T(X)$ のいずれかであることを意味します。例えば、文書分類の例では、これは、ソース文書集合とターゲット文書集合の間で、用語特徴が異なる (例えば、異なる言語を使用している) か、またはそれらの限界分布が異なることを意味します。

同様に、タスクは $T={Y,P(Y|X)}$ のペアとして定義される。したがって、$T_S=T_T$ という条件は、$Y_S = Y_T$か$P(Y_S|X_S)=P(Y_T|X_T)$ のいずれかであることを意味する。学習対象領域と学習元領域が同じ、すなわち $D_S=D_T$ で、学習タスクが同じ、すなわち $T_S=T_T$ の場合、学習問題は従来の機械学習問題となる。ドメインが異なる場合、

1. ドメイン間の特徴空間が異なる、すなわち、$\chi_Ｓ＝\chi_Ｔ$であるか、
2. ドメイン間の特徴空間は同じであるが、ドメインデータ間の限界確率分布が異なる、

すなわち、$P(X_S)=P(X_T)$ であり、ここで、$X_{S_i} \in \chi_S, X_{T_i} \in \chi_T$である。例えば、本実施例の文書分類例では、ケース(1)は、２組の文書が異なる言語で記述されている場合に対応し、ケース(2)は、ソースドメインの文書とターゲットドメインの文書が異なるトピックに焦点を当てている場合に対応してもよい。

特定のドメイン $D_S$ と $D_T$ が与えられ、学習タスク $T_S$ と $T_T$ が異なる場合、
1. ドメイン間のラベル空間が異なる、すなわち $Y_S=Y_T$となるか、
2. ドメイン間の条件付き確率分布が異なる、すなわち$P(Y_S|X_S)=P(Y_T|X_T)$となる。

私たちの文書分類の例では、ケース(1)は、ソースドメインがバイナリ文書クラスを持っている状況に対応しており、ターゲットドメインは、文書を分類するために10のクラスを持っているように。ケース(2)は、ユーザが定義したクラスの点でソース文書とターゲット文書が非常にアンバランスな状況に対応します。

また、2つのドメインの特徴空間の間に明示的または暗黙的に何らかの関係が存在する場合、ソースドメインとターゲットドメインが関連していると言います。