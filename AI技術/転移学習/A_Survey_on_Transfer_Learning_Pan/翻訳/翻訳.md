# A survey on Transfer Learning

# 備考

## 著者
Sinno Jialin Pan, Qiang Yang

## 掲載
"IEEE Transactions on Knowledge and Data Engineering," Vol. 22, No. 10, pp. 1345-1359, 2010.

# Abstract

多くの機械学習やデータマイニングのアルゴリズムでは、学習データと将来のデータが同じ特徴空間にあり、同じ分布を持っていなければならないというのが大きな前提となっています。しかし、多くの実世界のアプリケーションでは、この仮定が成り立たない場合があります。例えば、ある興味のある分野の分類タスクがあるのに、別の興味のある分野の十分な学習データしか持っていない場合、後者のデータは異なる特徴空間にあるかもしれないし、異なるデータ分布に従うかもしれません。このような場合、知識の転移が成功すれば、費用のかかるデータのラベリング作業を回避して学習のパフォーマンスを大幅に向上させることができます。近年、この問題を解決するための新しい学習フレームワークとして、知識転移学習が登場しています。本調査では、分類、回帰、クラスタリング問題に対する転移学習の現在の進展を分類し、レビューすることに焦点を当てている。本調査では、領域適応、マルチタスク学習、サンプル選択バイアス、共変量シフトなどの他の関連する機械学習技術と転移学習との関係について議論する。また、転移学習研究における将来的な課題についても考察する。

# Introduction

データマイニングと機械学習技術は、分類、回帰、クラスタリングを含む多くの知識工学分野ですでに大きな成功を収めている（例：[1], [2]）。しかし、多くの機械学習手法は共通の仮定の下でのみうまく機能します：訓練データとテストデータは同じ特徴空間と同じ分布から引き出されます。分布が変化すると、ほとんどの統計モデルは新たに収集した訓練データを使ってゼロから再構築する必要があります。多くの実世界のアプリケーションでは、必要な訓練データを再収集してモデルを再構築するのはコストがかかるか、不可能です。**訓練データの再収集の必要性と労力を軽減できれば良いのですが、そのような場合には、知識の転移やモデルの再構築が必要になります。** このような場合には、**タスク-ドメイン間での知識転移や転移学習が望ましい。**

知識工学の分野では、転移学習が真に有益であると考えられる多くの例を見つけることができます。 その一例として、Web 文書の分類 [3], [4], [5] がありますが、ここでは、与えられた Web 文書をいくつかの定義済みのカテゴリに分類することを目的としています。 Web文書分類の分野での例として（例えば、[6]を参照）、ラベル付けされた例は、以前の手動によるラベル付けの努力によって得られたカテゴリ情報に関連付けられた大学のWebページであるかもしれません。新たに作成されたWebサイトの分類タスクでは，データの特徴やデータ分布が異なる場合，ラベル付けされた学習データが不足している可能性があります．その結果，大学のWebサイトで学習したWebページ分類器を直接新しいWebサイトに適用できない可能性があります．そのような場合には，分類知識を新しいドメインに移すことができれば便利です．

**データが古くなりやすい場合には、転移学習の必要性が生じることがある。** この場合、ある時間帯に得られたラベル付けされたデータが、後の時間帯になっても同じ分布をたどるとは限らない。 例えば、過去に収集したWiFiデータに基づいてユーザの現在地を検出することを目的とする屋内 WiFi 定位問題では、ユーザが各場所で大量の WiFi 信号データをラベル付けする必要があるため、大規模な環境で定位モデルを構築するための WiFi データの較正には非常にコストがかかる。しかし、WiFi 信号強度の値は、時間、デバイス、または他の動的要因の関数である可能性がある。ある時間帯またはあるデバイスで訓練されたモデルは、別の時間帯または別のデバイスでの位置推定のための性能を低下させる可能性がある。再校正の労力を減らすためには、[7]で行われているように、ある期間（ソース領域）で訓練された定位モデルを新しい期間（ターゲット領域）に適応させるか、またはモバイルデバイス（ソース領域）で訓練された定位モデルを新しいモバイルデバイス（ターゲット領域）に適応させることが望ましいかもしれない。

# 2. OVERVIEW
## 2.1. A Brief History of Transfer Learning
従来のデータマイニングや機械学習アルゴリズムは、以前に収集されたラベル付きまたはラベルなしの訓練データで訓練された統計モデルを使用して、将来のデータに関する予測を行います[11], [12], [13]。半教師付き分類 [14], [15], [16], [17] は、ラベル付けされたデータが少なすぎて良い分類器を構築できないという問題に対処するために、大量のラベル付けされていないデータと少量のラベル付けされたデータを利用しています。不完全なデータセットに対する教師付き学習や半教師付き学習のバリエーションが研究されてきた；例えば， Zhu and Wu [18] は，ノイズの多いクラスラベル の問題を解決することができる。Yangらは，将来のサンプルに対して追加のテストを行うことができる場合のコスト感応型学習[19]を考えている．それにもかかわらず，それらのほとんどはラベル付きデータとラベルなしデータの分布が同じであることを前提としている．対照的に、転移学習では、訓練とテストで使用されるドメイン、タスク、および分布が異なることを可能にします。現実の世界では、伝達学習の多くの例を見ることができます。例えば、リンゴを認識することを学習すると、梨を認識するのに役立つかもしれないことに気づくかもしれません。同様に、電子オルガンを弾くことを学ぶことは、ピアノの学習を容易にするのに役立つかもしれません。転送学習の研究は、人々がインテリジェントに新しい問題をより速くまたはよりよい解決策と解決するために前に学んだ知識を適用することができるという事実によって動機づけられている。機械学習の分野における伝達学習の基本的な動機は、NIPS-95のワークショップ「Learning to Learn」1で議論され、以前に学習した知識を保持して再利用する生涯機械学習手法の必要性に焦点を当てた。

伝達学習に関する研究は、1995年以降、学習するための学習、生涯学習、知識の伝達、帰納的伝達、マルチタスク学習、知識統合、文脈依存型学習、知識ベースの帰納的バイアス、メタ学習、インクリメンタル/累積学習[20]など、さまざまな名称で注目を集めている。 これらの中で、知識伝達学習と密接に関連する学習手法として、異なるタスクであっても同時に複数のタスクを学習しようとするマルチタスク学習フレームワーク[21]がある。

2005年、国防高等研究計画庁(DARPA)の情報処理技術局(IPTO)2のBroad Agency Announcement(BAA)05-29 では、伝達学習の新たなミッションとして、「システムが以前のタスクで学んだ知識やスキルを認識し、新しいタスクに適用する能力」を与えました。この定義では、伝達学習とは、1つ以上のタスクから知識を抽出し、その知識を目的のタスクに適用することである。マルチタスク学習とは対照的に、伝達学習はソースタスクとターゲットタスクを同時に学習するのではなく、ターゲットタスクを最も重要視する学習である。 転移学習では、ソースタスクとターゲットタスクの役割が左右対称ではない。

図1に従来の機械学習技術と転移学習技術の学習プロセスの違いを示す。 このように，伝統的な機械学習技術ではタスクをゼロから学習しようとするのに対し，伝達学習技術では，学習データの質が低い場合に，過去のタスクの知識を対象タスクに伝達しようとする。

今日では、転送学習の方法は、データマイニング(ACM KDD、IEEE ICDMとPKDD、例えば)、機械学習(ICML、NIPS、ECML、AAAIとIJCAI、例えば)と機械学習とデータマイニング(ACM SIGIR、WWWとACL、例えば)3のアプリケーションで最も顕著に、いくつかのトップの会場に表示されます。転送学習の異なる分類を示す前に、まず、本稿で使用する表記法を説明する。

## .2. Notations and Definitions (記法と定義)

本節では、本調査で使用する表記法と定義を紹介する。まず、「ドメイン」と「タスク」の定義を示す。

本調査では、ドメイン $D$は、特徴空間 $\chi$ と限界確率分布 $P(X)$ の2つの要素から構成される。 例えば、学習課題が文書分類であり、各項を２値特徴量とすると、$\chi$ は全ての項ベクトルの空間であり、$ｘ_i$ はいくつかの文書に対応する$ｉ$番目の項ベクトルであり、$Ｘ$ は特定の学習サンプルであるとすると、$Ｘ ＝\{ x_1, \dots, x_n\} \in \chi$である。一般的に、2つの領域が異なる場合、それらは異なる特徴空間、または異なる限界確率分布を持つかもしれません。

タスクは、特定の領域 $D = \{\chi, P(X)\}$が与えられると、2つの要素から構成される：ラベル空間 $Y$ と、観測されないがペア $\{x_i, y_I\}$ で構成される学習データから学習可能な客観的予測関数 $f(.)$ ( $T = \{Y,f(.)\}$ と表記される）である。ここで、$x_i \in X$ そして $y_i \in Y$ である。
関数 $f(.)$ は、新しいインスタンス $x$ の対応するラベル $f(.)$ を予測するために使用することができます。文書分類の例では、$y$ はすべてのラベルの集合であり、二値分類タスクの場合、$y_i$ は *True* または *False* である。

本調査では、簡単のために、ソースドメイン $D_S$ とターゲットドメイン $D_T$ が1つの場合のみを考慮している。具体的には、ソースドメインデータを $D_S = \{(x_{S1}, y_{S1}),\dots,(x_{Sn_S},y_{Sn_S})\}$ とし、$x_{Si} \in \chi_S$ はデータインスタンス、$y_{Si} \in Y_S$ は対応するクラスラベルである。ここで、文書分類の例では、$D_S$ は、用語ベクトルの集合であり、それらに関連付けられた真または偽のクラスラベルを表すことができる。同様に、対象領域データを $D_T = \{(x_{T1},y_{T1}),\dots,(x_{Tn_T},y_{Tn_T})\}$ と定義し、入力 $x_{Ti}$ は $\chi_T$ であり、$y_{T_i} \in Y_T$ は対応する出力である。ほとんどの場合、$0 \leqq n_T \ll n_S$ である。

これで、転移学習の統一的な定義ができました。

転移学習とは、
> ソースドメイン $D_S$ とその学習タスク $T_S$、ターゲットドメイン $D_T$ とその学習タスク $T_T$ が与えられた場合、転移学習は、$D_S$ と$T_S$ の知識（$D_S \neq D_T$、$T_S \neq T_T$）を用いて、$D_T$におけるターゲット予測関数 $f_T(.)$ の学習を改善することを目的とする。

上記の定義では、ドメインは $D={\chi,P(X)}$ の組である。したがって、$D_S \neq D_T$という条件は、$\chi_S \neq \chi_T$ または $P_S(X) \neq P_T(X)$ のいずれかであることを意味します。例えば、文書分類の例では、これは、ソース文書集合とターゲット文書集合の間で、用語特徴が異なる (例えば、異なる言語を使用している) か、またはそれらの限界分布が異なることを意味します。

同様に、タスクは $T={Y,P(Y|X)}$ のペアとして定義される。したがって、$T_S=T_T$ という条件は、$Y_S = Y_T$か$P(Y_S|X_S)=P(Y_T|X_T)$ のいずれかであることを意味する。学習対象領域と学習元領域が同じ、すなわち $D_S=D_T$ で、学習タスクが同じ、すなわち $T_S=T_T$ の場合、学習問題は従来の機械学習問題となる。ドメインが異なる場合、

1. ドメイン間の特徴空間が異なる、すなわち、$\chi_Ｓ＝\chi_Ｔ$であるか、
2. ドメイン間の特徴空間は同じであるが、ドメインデータ間の限界確率分布が異なる、

すなわち、$P(X_S)=P(X_T)$ であり、ここで、$X_{S_i} \in \chi_S, X_{T_i} \in \chi_T$である。例えば、本実施例の文書分類例では、ケース(1)は、２組の文書が異なる言語で記述されている場合に対応し、ケース(2)は、ソースドメインの文書とターゲットドメインの文書が異なるトピックに焦点を当てている場合に対応してもよい。

特定のドメイン $D_S$ と $D_T$ が与えられ、学習タスク $T_S$ と $T_T$ が異なる場合、
1. ドメイン間のラベル空間が異なる、すなわち $Y_S=Y_T$となるか、
2. ドメイン間の条件付き確率分布が異なる、すなわち$P(Y_S|X_S)=P(Y_T|X_T)$となる。

私たちの文書分類の例では、ケース(1)は、ソースドメインがバイナリ文書クラスを持っている状況に対応しており、ターゲットドメインは、文書を分類するために10のクラスを持っているように。ケース(2)は、ユーザが定義したクラスの点でソース文書とターゲット文書が非常にアンバランスな状況に対応します。

また、2つのドメインの特徴空間の間に明示的または暗黙的に何らかの関係が存在する場合、ソースドメインとターゲットドメインが関連していると言います。