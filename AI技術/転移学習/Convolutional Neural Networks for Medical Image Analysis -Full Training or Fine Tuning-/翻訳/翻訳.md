# Convolutional Neural Networks for Medical ImageAnalysis: Full Training or Fine Tuning?

# 備考

## 著者
Nima Tajbakhsh, Jae Y. Shin, Suryakanth R. Gurudu, R. Todd Hurst, Christopher B. Kendall, Michael B. Gotway, Jianming Liang

## 掲載


# Abstract
深層畳み込みニューラルネットワーク(CNN)をゼロから訓練するのは、ラベル付けされた大量の訓練データと、適切な収束を確実にするための膨大な専門知識が必要となるため困難である。 有望な代替手段としては、例えば、ラベル付けされた自然画像の大集合を用いて事前に訓練されたCNNを微調整することが挙げられる。 しかし、自然画像と医用画像の間には大きな違いがあるため、そのような知識転移は推奨されないかもしれない。この論文では，医用画像解析の文脈において，次のような中心的な疑問に答えようとしている．事前に学習したディープCNNを十分に微調整した上で使用することで、ディープCNNを一から学習する必要がなくなるのではないか？この疑問を解決するために、我々は3つの専門分野（放射線学、心臓病学、消化器病学）の4つの異なる医用画像アプリケーションを考慮し、3つの異なる画像モダリティからの分類、検出、セグメンテーションを行い、スクラッチから学習したディープCNNの性能が、レイヤーごとに微調整した事前学習CNNと比較してどのようになるかを調査した。我々の実験では，
(1)事前に学習したCNNを十分に微調整したものを用いた場合，スクラッチから学習したCNNと同等の性能を発揮するか，最悪の場合には同等の性能を発揮すること，
(2)微調整したCNNの方がスクラッチから学習したCNNよりも学習セットの大きさに対してロバストであることが一貫して示された．
(3) 浅いチューニングも深いチューニングも特定のアプリケーションには最適な選択ではなかった
(4) 我々のレイヤー単位の微調整スキームは，利用可能なデータの量に基づいて，そのアプリケーションに最適な性能を得るための実用的な方法を提供することができた．

# 1. Introduction

畳み込みニューラルネットワーク（CNN）は，数十年前からコンピュータビジョンの分野で利用されている[1]-[3]． しかし，その真価が明らかにされたのは2012年のImageNetコンペティションが成功してからであり，グラフィックス処理装置（GPU）の効率的な利用，線形整流化された線形単位，新しいドロップアウト正則化，効果的なデータ増強によって革命をもたらしました[3]． 2013年のブレークスルートップ10の1つとして認められているCNN [4] は，再び人気のある学習機械となり，現在ではコンピュータビジョンのコミュニティ内だけでなく，自然言語処理からハイパースペクトル画像処理，医用画像解析に至るまで，さまざまなアプリケーションで利用されている．CNNの主な力は，その深いアーキテクチャ[5]-[8]にあり，複数の抽象度で識別特徴を抽出することができる．

しかし、ディープCNNをゼロから（あるいは完全に）学習するには複雑な問題がないわけではない [9]。 第一に，CNNは大量のラベル付き訓練データを必要とするが，専門家によるアノテーションに費用がかかり，データセットに含まれる疾患（病変など）が少ない医療分野では，この要件を満たすのは難しいかもしれない．第二に，ディープCNNの学習には膨大な計算資源とメモリ資源が必要であり，それがなければ学習プロセスは非常に時間のかかるものになってしまう．第三に、ディープCNNの学習はオーバーフィットと収束の問題によって複雑になることが多く、その解決には、すべての層が同等の速度で学習するように、ネットワークのアーキテクチャや学習パラメータを繰り返し調整する必要がある。したがって、ゼロから深層学習を行うのは面倒で時間がかかり、多くの勤勉さ、忍耐力、専門知識を必要とする。

# 5. Fine Tuning

式2の反復的重み更新は、ランダムに初期化された重みのセットから始まる。具体的には，訓練段階の開始前に，CNNの各畳み込み層の重みは，平均値が0で標準偏差が小さい正規分布からランダムにサンプリングされた値で初期化される．しかし，CNNの重みの数が多く，ラベル付きデータの利用可能性が限られていることを考えると，ランダムな重みの初期化から始まる反復的な重み更新は，コスト関数の望ましくない局所的な最小値をもたらす可能性がある． あるいは，畳み込み層の重みを，同じアーキテクチャの事前学習済みCNNの重みで初期化することもできる． 事前訓練されたネットは，別のアプリケーションからラベル付けされたデータの大規模なセットで生成される．事前に学習した重みのセットからCNNを学習することを微調整と呼び，いくつかのアプリケーションで成功裏に利用されている[10]-[12]．

微調整は，事前に学習したネットワークから学習したいネットワークに重みをコピー（転送）することから始まります．例外は，最後の完全接続層であり，そのノード数はデータセットのクラス数に依存する． 一般的には，事前学習したCNNの最後の完全接続層を，新しいターゲット・アプリケーションのクラス数と同じ数のニューロンを持つ新しい完全接続層で置き換えるのが一般的である． 我々の研究では、2クラスと3クラスの分類タスクを扱うので、新しい完全接続層は、研究対象のアプリケーションに応じて、2個または3個のニューロンを持つ。 最後の完全に接続された層の重みが初期化された後、新しいネットワークは層ごとに微調整することができ、最初は最後の層のみを調整し、次にCNNの全層を調整する。

最後の3層が完全に接続された層である$L$層を持つCNNを考える。また，$α_l$ をネットワークの $l$ 番目の層の学習率とする． $l\neq L$のとき$α_l=0$とすることで、ネットワークの最後の（新しい）層だけを微調整することができる。このレベルの微調整は、$L-1$層で生成された特徴量を用いて線形分類器を学習することに相当します。同様に、ネットワークの最後の2つの層は、$l\neq L$, $L-1$に対して$α_l=0$を設定することで、微調整することができます。このレベルの微調整は、1つの隠れ層を持つ人工ニューラルネットワークを訓練することに相当し、これは、$L-2$層で生成された特徴を用いて非線形分類器を訓練していると見ることができます。同様に、微調整層$L$,$L-1$,$L-2$は、本質的には2つの隠れ層を持つ人工ニューラルネットワークを訓練することに相当する。 前の畳み込み層を更新プロセスに含めることで、事前に学習したCNNをさらにアプリケーションに適応させることができますが、オーバーフィットを避けるために、より多くのラベル付き学習データが必要になるかもしれません。

一般的に、CNNの初期の層は低レベルの画像特徴を学習し、ほとんどのビジョンタスクに適用できるが、後期の層は高レベルの特徴を学習する。したがって，通常は，最後の数層を微調整するだけで十分な伝達学習が可能である．しかし、ソースアプリケーションとターゲットアプリケーションの間の距離が大きい場合には、初期のレイヤーも微調整する必要があるかもしれません。したがって、効果的な微調整技術は、最後の層から始めて、所望の性能に到達するまで、更新プロセスに段階的により多くの層を含めることである。 我々は、最後の数層の畳み込み層をチューニングすることを「浅いチューニング」と呼び、全ての畳み込み層をチューニングすることを「深いチューニング」と考える。提案する微調整スキームは、ネットワークをそのまま特徴量生成器として利用する[10]や[12]とは異なり、また、ネットワーク全体を一度に微調整する[11]とは異なる点に注意が必要である。

# 6. APPLICATIONS AND RESULTS

本研究では、3つのイメージングモダリティシステムから4つの異なる医用画像アプリケーションを検討した。自由応答動作特性（FROC）解析によるポリープ検出とPE検出の性能、ROC解析によるフレーム分類の性能、ボックスプロット解析による境界細分化の性能を評価した。統計的な比較を行うために、[38]で提案された方法に従って、ROC曲線とFROC曲線の95%信頼区間に対応するエラーバーを計算しました。 エラーバーにより、統計的観点から複数の動作点での性能曲線の各ペアを比較することができます。具体的には、ペアの曲線のエラーバーが一定の偽陽性率で重ならない場合、2つの曲線は所定の操作点で統計的に異なる(p<.05)。 この統計的分析の魅力的な特徴は私達が全体としてカーブを比較するよりもむしろ臨床的に受諾可能な作動ポイントで性能のカーブを比較してもいいことである。 論文全体で統計的比較を議論してきたが、補足資料の中のいくつかの表にさらに要約したもので、補足ファイル/マルチメディアタブにある。

CNNの学習と微調整にはCaffeライブラリ[39]を使用した． 一貫性と比較を容易にするために，研究対象の4つのアプリケーションにはAlexNetアーキテクチャを用いた．各AlexNetの訓練と微調整には，訓練セットのサイズにもよるが，約2-3時間かかった．各CNNの適切な収束を保証するために，受信機の動作特性曲線の下の領域をモニターした．具体的には，各実験において，訓練セットを訓練データの８０％の小さな訓練セットと，残りの２０％の訓練データの検証セットに分割し，検証セットの曲線下面積を計算した． 検証セットで最高の精度が観測されたときに、トレーニングプロセスを終了しました。すべての訓練は、NVIDIA GeForce GTX 980TI (6GBオンボードメモリ)を使用して行われた。完全に訓練されたCNNは、ガウス分布から抽出したランダムな重みで初期化した。[40]や[41]で提案されているような他の初期化手法も実験したが、これらの初期化手法を用いて収束の速度に差があることに気づいたにもかかわらず、収束後の性能の有意な向上は観察されなかった。

フルトレーニングと微調整シナリオの両方について、我々は、ポジティブクラスとネガティブクラスが等しく存在する画像パッチの層別トレーニングセットを使用しました。 この目的のために、少数クラス（ポジティブ）は変更せずに、多数派（ネガティブ）クラスをランダムにダウンサンプリングしました。微調整シナリオでは、Caffeライブラリで提供されている事前学習済みのAlexNetモデルを使用しました。事前学習されたAlexNetは、畳み込み層の約500万個のパラメータと完全に接続された層の約5500万個のパラメータから構成されており、1000の意味クラスでラベル付けされた120万枚の画像を用いて学習されています。 本研究で使用したモデルは、36万回の繰り返し学習を行った後のスナップショットである。 [表1]に示すように、AlexNetは、227x227の入力画像を13x13の特徴マップにマッピングした2組の畳み込み層とプーリング層から始まります。 このアーキテクチャは、次に、９×９カーネルを有する畳み込み層を効率的に実装しながらも、より大きな非線形性を有する３つの畳み込み層のシーケンスで進行する。 畳み込み層のシーケンスは、次に、プーリング層と3つの完全に接続された層が続く。最初の完全に接続された層は、６×６カーネルを有する畳み込み層として見ることができ、他の２つの完全に接続された層は、１×１カーネルを有する畳み込み層として見ることができる。

---
表I：実験で使用したAlexNetアーキテクチャ。注目すべきは、Cはクラス数であり、内膜-メディアインターフェースのセグメンテーションでは3、大腸内視鏡のフレーム分類、ポリープ検出、肺塞栓症検出では2である。

![表1](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92/Convolutional%20Neural%20Networks%20for%20Medical%20Image%20Analysis%20-Full%20Training%20or%20Fine%20Tuning-/%E7%94%BB%E5%83%8F/%E8%A1%A81.png)

---
---
表2：AlexNetの学習と微調整に使用された学習パラメータ \muは運動量，\alphaは各畳み込み層の重みの学習率であり，エポック毎にどのように減少するかを決定する．バイアス項の学習率は，対応する重みの学習率の2倍に設定されています．なお，"fine-tuned AlexNet: layer1-layer2 "は，この2つの層の間とそれを含むすべての層が微調整を受けていることを示している．

![表2](https://raw.githubusercontent.com/rurusasu/paper/master/AI%E6%8A%80%E8%A1%93/%E8%BB%A2%E7%A7%BB%E5%AD%A6%E7%BF%92/Convolutional%20Neural%20Networks%20for%20Medical%20Image%20Analysis%20-Full%20Training%20or%20Fine%20Tuning-/%E7%94%BB%E5%83%8F/%E8%A1%A82.png)

---

[表2] は，我々の実験で AlexNet の学習と微調整に使用した学習パラメータをまとめたものである．これらのパラメータは，広範な試行錯誤を経て調整された．探索的実験によると，学習率とスケジューリング率はCNNの収束に大きく影響することがわかった． しかし、学習率が0.001であれば、4つのアプリケーションのすべてで適切な収束が保証された。 学習率を小さくすると収束が遅くなり、学習率を大きくすると収束に失敗することが多い。 また、探索的な実験から、 $\gamma$ の値は収束の速度に依存することがわかった。高速収束時には、数エポック後に学習率を安全に下げることができ、スケジューリング率を小さくすることができます。 しかし、収束が遅い場合には、比較的大きな学習率を維持するために、より大きなスケジューリング率が必要となります。4つのアプリケーションすべてにおいて、 $\gamma=0.95$ が妥当な選択であることがわかりました。

## A. Polyp detection

---
図1：大腸内視鏡検査ビデオにおけるポリープの形状と外観のばらつき。



---
大腸内視鏡検査は、大腸がん検診や予防のために好まれる検査法です。大腸内視鏡検査の目的は、大腸がんの前兆である大腸ポリープを発見し、除去することである。ポリープは、図1に示すように、色、形、大きさに大きな違いがあります。ポリープの出現が困難であることから、しばしば誤検出につながることがあります。

# 7. Discussion

本研究では、本研究で得られた知見の汎用性を確保するために、3種類の画像モダリティシステムから4つの一般的な医用画像問題を検討した。具体的には、3次元画像におけるコンピュータ支援病変検出の代表としてPE検出、2次元画像におけるコンピュータ支援病変検出の代表としてポリープ検出、機械学習を用いた医用画像分割の代表として内膜境界分割、医用画像分類の代表として大腸内視鏡検査画像の品質評価を選んだ。これらのアプリケーションは、異なる画像スケールで問題を解決する必要があるために異なる。例えば、内膜境界のセグメンテーションやPEの検出では、画像内の小さな領域の検査が必要となるが、ポリープの検出やフレームの分類では、はるかに大きな受容領域が必要となる。したがって、我々は、選択されたアプリケーションは、医療画像の分野に関連する様々なアプリケーションを包含していると信じています。

医用画像解析の文脈において、一からディープCNNを訓練する代わりに、微調整されたCNNの可能性を徹底的に調査した。 大規模なトレーニングセットと縮小されたトレーニングセットの両方を用いて解析を行った。完全なデータセットを用いた場合，事前に学習したCNNを浅くチューニングした場合には，スクラッチから学習したCNNよりも劣る性能になることが多かったが，より深くチューニングした場合には，スクラッチから学習したCNNに匹敵する，あるいはそれ以上の性能を得ることができた．深く微調整したCNNとスクラッチから学習したCNNとの性能の差は，学習セットのサイズを小さくすると拡大し，利用可能な学習セットのサイズにかかわらず，常に微調整したCNNが望ましい選択肢であると結論づけた．

微調整されたCNNのもう一つの利点は、収束の速さである。この利点を実証するために、図10では、深く微調整されたCNNとスクラッチから学習されたCNNの収束速度を比較している。 完全に比較するために，完全に訓練されたCNNの重みを初期化するために3つの異なる手法を用いた． 1) [40]で提案された一般的に知られているXavierと呼ばれる手法，2) [41]で提案されたMSRAと呼ばれるXavierの改訂版，そしてガウス分布に基づく基本的なランダム初期化手法である．今回の解析では、収束の指標として検証データのAUCを計算した。 具体的には、モデルの各スナップショットをバリデーションセットのパッチに適用し、ROC分析を用いて分類性能を評価した。 私たちは、intimia-media境界セグメンテーションの質問に対して3クラスの分類問題を扱ったので、2つのインターフェースクラスを1つの正のクラスにマージして、結果として得られた2値分類（インターフェース対バックグラウンド）のAUCを計算しました。 示されているように，微調整されたCNNはすぐに最大性能に達するが，ゼロから学習されたCNNは最高性能に達するまでに長い学習時間が必要である． さらに、異なる初期化手法を用いることで、収束の傾向は異なるが、完全な収束後にはPE検出を除いて有意な性能向上は見られなかった。

我々は、高精度な画像分類器を実現するためには、微調整の深さが重要であることを明らかにした。コンピュータビジョン分野の多くのアプリケーションでは、浅いチューニングや最後の数層の畳み込み層を更新するだけで十分な性能が得られるが、医療画像アプリケーションでは、より深いレベルのチューニングが不可欠であることを発見した。 例えば，特にポリープの検出や内膜境界のセグメンテーションでは，深くチューニングされたCNNを用いた場合に顕著な性能向上が見られたが，これは，これらのアプリケーションと事前に学習されたCNNが構築されたデータベースとの間に大きな違いがあるためであろう． しかし、大腸内視鏡のフレーム分類では、これほど大きな性能向上は見られなかったが、これはImageNetと我々のデータベースの大腸内視鏡フレームの相対的な類似性に起因するものである。具体的には、どちらのデータベースも同様の低レベルの画像情報を持つ高解像度画像を使用しているため、アプリケーション固有の特徴を持つ後期畳み込み層を微調整することで、大腸内視鏡フレーム分類の高レベルの性能を達成するのに十分である。

我々の実験はAlexNetアーキテクチャに基づいて行われたが，これはCaffeライブラリで事前に学習されたAlexNetモデルが利用可能であったことと，このアーキテクチャが十分に深く，微調整の深さが事前に学習されたCNNの性能に与える影響を調べることができたからである． あるいは、VGGNetやGoogleNetのようなより深いアーキテクチャを使うことも可能であった。より深いアーキテクチャは最近、困難なコンピュータビジョンタスクに対して比較的高い性能を示しているが、医用画像アプリケーションでより深いアーキテクチャを使用しても大きな性能向上は期待できない。我々は、この作業の目的が、多くの異なる医用画像処理タスクに対して最高の性能を達成することではなく、ゼロからの訓練スキームと比較して微調整の能力を検討することであったことを強調している。これらの目的のために、AlexNetは合理的なアーキテクチャの選択です。

異なるモデルやアプリケーションについて報告された性能曲線は，それぞれの実験で達成できた最高のものではないかもしれないことを認めたい． この最適でない性能は、モデルの収束速度や最終的な精度に影響を与えるCNNのハイパーパラメータの選択に関係している。これらのパラメータの動作値を見つけようとしたが，論文で研究したCNNの数が多いことと，ハイエンドGPUでも各CNNの学習に時間がかかることを考えると，最適な値を見つけることは不可能であった． とはいえ，比較に用いたCNNの大部分は事前に学習したモデルであり，ゼロから学習したCNNよりもハイパーパラメータの選択の影響が少ないかもしれないので，この問題は全体的な結論を変えるものではないかもしれない．

本研究では、スペースの都合上、すべての医用画像モダリティをカバーすることはできませんでした。例えば、ゼロからCNNを完全に訓練することで有望な性能を示したMR画像や病理組織画像の微調整性能については研究していない。しかし，自然画像からCT，超音波，内視鏡などへの知識転移に成功していることを考えると，微調整は他の医療分野でも成功するのではないかと推測される．さらに、本研究では、事前に訓練された教師付きモデルの微調整に焦点を当てている。しかし、1000の意味クラスからの数百万のラベル付き画像を持つImageNetデータベースが利用可能であるため、事前学習済み教師付きモデルの使用が微調整のための自然な選択となるかもしれないが、制限付きボルツマンマシン（RBM）や畳み込みRBM [74]によって得られたような事前学習済み教師なしモデルも考慮することができた。それでも、教師なしモデルは、ラベル付けされた1次元信号の大規模なデータベースがないため、1次元信号処理に有用であることに変わりはない。 例えば、教師なしモデルの微調整は、[75]では音響音声認識に、[76]では脳波記録におけるてんかんの検出に使用されている。

# 8. Conclusion

本論文では、医用画像解析の文脈において、次のような中心的な問題に取り組むことを目的とした。事前に訓練されたディープCNNを十分に微調整した上で使うことで、ディープCNNを一から訓練する必要がなくなるのではないか？3つの異なる画像モダリティシステムからの4つの異なる医用画像アプリケーションに基づいた我々の広範な実験により、微調整されたCNNが医用画像解析に有用であり、完全に訓練されたCNNと同等の性能を発揮し、訓練データが限られている場合には後者よりも優れた性能を発揮することが実証された。 この結果は、自然画像から医用画像への知識転移が可能であることを示している点で重要であるが、元のデータベースと対象のデータベースの間に比較的大きな差があるため、そのような応用は不可能である可能性がある。 また、**アプリケーションによって必要とされる微調整のレベルが異なることも観察された。** 具体的には、PE検出では、完全に接続された後期の層を微調整することで性能が飽和し、大腸内視鏡のフレーム分類では、後期と中期の層を微調整することで最高の性能を達成し、インターフェースのセグメンテーションとポリープ検出では、事前学習されたCNNの全層を微調整することで最高の性能を観測した。この結果は，特定のアプリケーションに対しては，浅いチューニングも深いチューニングも最適な選択ではないことを示唆している． **レイヤー単位の微調整を行うことで，効果的なチューニングの深さを知ることができる．** 層別微調整は、利用可能なデータ量に応じて、そのアプリケーションに最適な性能を実現するための実用的な方法を提供することができます。 我々の実験は、深く微調整されたCNNと完全に訓練されたCNNの両方が、対応する手作業で作られた代替品よりも優れた性能を示したことから、医用画像アプリケーションにおけるCNNの可能性をさらに確認するものである。